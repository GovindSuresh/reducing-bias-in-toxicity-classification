{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling - ML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal for our work is to not only train a model to identify toxic comments, but to do so while reducing bias.\n",
    "Bias in this task can be viewed as the situation where certain identies such as 'Black', 'Muslim', 'Gay' e.t.c, begin triggering toxic classification for comments they are in, even when the comment is actually positive. This is a key issue in toxic comment classification. \n",
    "\n",
    "The goal of the [jigsaw unintended Bias in Toxicity Classification](https://www.kaggle.com/c/jigsaw-unintended-bias-in-toxicity-classification/data) Kaggle challenge was to reduce this bias via a newly developed submetric which we have defined below.\n",
    "\n",
    "**Note: The goal of the model is simply to predict the toxicity score of a model.** \n",
    "\n",
    "The bias weighted ROC metric below is calulated by taking segmenting the the dataset into identity subgroups by using the provided identity labels and then calculating the subgroup metrics. \n",
    "\n",
    "### Metrics:\n",
    "\n",
    "In addition to accuracy we will observe the below metrics for our models\n",
    "\n",
    "#### Overall ROC-AUC:\n",
    "\n",
    "This is the standard ROC-AUC for the full evaluation set. In other words this is the area under the Reciever Operating Characteristic curve. It compares the true positive and false positive rates of a binary model.\n",
    "\n",
    "#### Subgroup ROC-AUC:\n",
    "\n",
    "Here, we restrict the data set to only the examples that mention the specific identity subgroup. A low value in this metric means the model does a poor job of distinguishing between toxic and non-toxic comments that mention the identity.\n",
    "\n",
    "#### BPSN AUC:\n",
    "\n",
    "BPSN (Background Positive, Subgroup Negative) AUC: Here, we restrict the test set to the non-toxic examples that mention the identity and the toxic examples that do not. A low value in this metric means that the model confuses non-toxic examples that mention the identity with toxic examples that do not, likely meaning that the model predicts higher toxicity scores than it should for non-toxic examples mentioning the identity.\n",
    "\n",
    "#### BNSP AUC:\n",
    "\n",
    "BNSP (Background Negative, Subgroup Positive) AUC: Here, we restrict the test set to the toxic examples that mention the identity and the non-toxic examples that do not. A low value here means that the model confuses toxic examples that mention the identity with non-toxic examples that do not, likely meaning that the model predicts lower toxicity scores than it should for toxic examples mentioning the identity.\n",
    "\n",
    "\n",
    "#### Generalized Mean of Bias AUCs\n",
    "To combine the per-identity Bias AUCs into one overall measure, we calculate their generalized mean as defined below:\n",
    "\n",
    "$M_p(m_s) = \\left(\\frac{1}{N} \\sum_{s=1}^{N} m_s^p\\right)^\\frac{1}{p}$\n",
    "\n",
    "Where:\n",
    "\n",
    "$M_p$ = the $p$th power-mean function\n",
    "\n",
    "$m_s$ = the bias metric $m$ calulated for subgroup $s$\n",
    "\n",
    "$N$ = number of identity subgroups\n",
    "\n",
    "For this competition, JigsawAI use a p value of -5 to encourage competitors to improve the model for the identity subgroups with the lowest model performance.\n",
    "\n",
    "### Final Metric\n",
    "We combine the overall AUC with the generalized mean of the Bias AUCs to calculate the final model score:\n",
    "\n",
    "$score = w_0 AUC_{overall} + \\sum_{a=1}^{A} w_a M_p(m_{s,a})$\n",
    "\n",
    "$A$ = number of submetrics (3)\n",
    "\n",
    "$m_{s,a}$ = bias metric for identity subgroup $s$ using submetric $a$\n",
    "\n",
    "$w_a$ = $a$ weighting for the relative importance of each submetric; all four $w$ values set to 0.25\n",
    "\n",
    "\n",
    "### Process:\n",
    "\n",
    "#### Classical ML models\n",
    "This is primarily an NLP task, our X feature matrix will be based off the text from online comments. We have defined a pre-processing pipeline in the 'preprocessing.ipynb' notebook to use for our our ML classifiers and a seperate pre-processing pipeline for the neural network models we are planning on training.\n",
    "\n",
    "From the classic ML classifer models, we intend to use the following models - our base word embedding technique will be TF-IDF: \n",
    "\n",
    "   * Logistic Regression\n",
    "   * SVM\n",
    "   * Random Forest\n",
    " \n",
    "   \n",
    "We will carry out hyperparameter optimization for each model and calculate the metrics for each.\n",
    "\n",
    "#### Neural Networks\n",
    "\n",
    "We will also train a neural network to answer this problem. We will start with a basic LSTM model which will be made of:\n",
    "    \n",
    "   * Two LSTM layers to read through the data\n",
    "   * Two Dense layers w/ 4 nodes\n",
    "   * Output layer using sigmoid for the classes\n",
    "   \n",
    "We will then seek to improve this LSTM by creating a Bidrectional LSTM (BiLSTM) which we believe will improve accuracy by reading input sequences in both directions. If time allows we will also attempt to include a simple attention mechanism.\n",
    "\n",
    "The NN models will use Glove 840B 300d word embeddings. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gov/anaconda3/envs/capstone/lib/python3.7/site-packages/tqdm/std.py:651: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  from pandas import Panel\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import string\n",
    "import contractions\n",
    "import tqdm\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "import gc\n",
    "import operator\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 1: Apply pre-processing to text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load train_data\n",
    "train_df = pd.read_csv('data/train_clean.csv')\n",
    "\n",
    "# Load in test data\n",
    "test_df = pd.read_csv('data/test_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.rename({'toxicity':'target'}, axis=1, inplace=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the unneeded columns\n",
    "train_df = train_df.iloc[:,1:]\n",
    "test_df = test_df.iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this cell we define the function that pre-processes our text\n",
    "\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
    "import contractions\n",
    "import string\n",
    "\n",
    "def text_cleaner(df, col_name, clean_col_name):\n",
    "    '''\n",
    "    Text pre-processing pipeline, we lemmatize words, expand contractions, remove common stop words, apply lower case,\n",
    "    tokenize, and delete punctuation. All functions use apply and list comprehension for speed benefit.\n",
    "   \n",
    "    INPUT:\n",
    "    df = name of dataframe\n",
    "    col_name = name of column to pre-process\n",
    "    clean_col_name = name of new cleaned_column\n",
    "   \n",
    "    OUTPUT:\n",
    "    None - changes are made directly to dataframe\n",
    "    \n",
    "    '''\n",
    "\n",
    "    # Lemmatize helper functions\n",
    "    # Lemmatize nouns\n",
    "    def lemmatize_text_noun(text):\n",
    "        return [lemmatizer.lemmatize(w, pos='n') for w in text]\n",
    "    \n",
    "    # Lemmatize verbs\n",
    "    def lemmatize_text_verb(text):\n",
    "        return [lemmatizer.lemmatize(w, pos='v') for w in text]\n",
    "    # Lemmatize adjectives\n",
    "    def lemmatize_text_adj(text):\n",
    "        return [lemmatizer.lemmatize(w, pos='a') for w in text]\n",
    "\n",
    "    # Lemmatize adverbs\n",
    "    def lemmatize_text_adv(text):\n",
    "        return [lemmatizer.lemmatize(w, pos='r') for w in text]\n",
    "    \n",
    "    # Expand contraction method\n",
    "    def contraction_expand(text):\n",
    "        return contractions.fix(text)\n",
    "    \n",
    "    # To lower case.\n",
    "    df[clean_col_name] = df[col_name].apply(lambda x: x.lower())\n",
    "    \n",
    "    # Expand contractions\n",
    "    df[clean_col_name] = df[clean_col_name].apply(lambda x: contraction_expand(x))\n",
    "    \n",
    "    #Tokenize:\n",
    "    tokenizer = TweetTokenizer(reduce_len=True)\n",
    "    df[clean_col_name] = df[clean_col_name].apply(lambda x: tokenizer.tokenize(x))\n",
    "   \n",
    "    \n",
    "    #Remove Stop words\n",
    "    stop_words = stopwords.words('english')\n",
    "    df[clean_col_name] = df[clean_col_name].apply(lambda x: [item for item in x if item not in stop_words])\n",
    "    \n",
    "    #Delete punctuation\n",
    "    punc_table = str.maketrans('', '', string.punctuation)\n",
    "    df[clean_col_name] = df[clean_col_name].apply(lambda x: [item.translate(punc_table) for item in x])\n",
    "    \n",
    "    # LEMMATIZATION\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    \n",
    "    df[clean_col_name] = df[clean_col_name].apply(lemmatize_text_noun)\n",
    "    df[clean_col_name] = df[clean_col_name].apply(lemmatize_text_verb)\n",
    "    df[clean_col_name] = df[clean_col_name].apply(lemmatize_text_adj)\n",
    "    df[clean_col_name] = df[clean_col_name].apply(lemmatize_text_adv)\n",
    "    \n",
    "    \n",
    "    return None\n",
    "\n",
    "\n",
    "def detokenizer(df, col_name):\n",
    "    detokenizer = TreebankWordDetokenizer()\n",
    "    df[col_name+'_detokenize'] = df[col_name].apply(lambda x: detokenizer.detokenize(x))\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 19min 18s, sys: 8.28 s, total: 19min 26s\n",
      "Wall time: 19min 30s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Run the cleaner func on train data\n",
    "text_cleaner(train_df, 'comment_text', 'comment_text_clean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "# Run the same cleaner on the training data\n",
    "text_cleaner(test_df, 'comment_text', 'comment_text_clean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 34s, sys: 803 ms, total: 3min 35s\n",
      "Wall time: 3min 37s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "detokenizer(train_df,'comment_text_clean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 23.9 s, sys: 194 ms, total: 24.1 s\n",
      "Wall time: 24.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# detokenize the test data\n",
    "detokenizer(test_df, 'comment_text_clean')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 2: Modelling\n",
    "\n",
    "The data has been pre-processed for our models. We can now begin model training.\n",
    "\n",
    "We have a seperate test dataset that will be kept aside for testing only once we have an ideal model. For hyperparameter optimizing we will use Scikit-learn's GridSearchCV. \n",
    "\n",
    "After we have fitted a model and predicted results, we can then append the predictions to the dataframe and calculate the subgroup AUCs and the final weighted metric . \n",
    "\n",
    "#### Defining subgroup AUC metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "SUBGROUP_AUC = 'subgroup_auc'\n",
    "BPSN_AUC = 'bpsn_auc'  # stands for background positive, subgroup negative\n",
    "BNSP_AUC = 'bnsp_auc'  # stands for background negative, subgroup positive\n",
    "\n",
    "\n",
    "# These calculations have been provided by Jigsaw AI for scoring based on the metrics of the kaggle competition\n",
    "# https://www.kaggle.com/c/jigsaw-unintended-bias-in-toxicity-classification/overview/evaluation\n",
    "\n",
    "# They work by filtering the relevant dataframe into specific subgroups and using the roc_auc_score metric from sklearn.\n",
    "\n",
    "def compute_auc(y_true, y_pred):\n",
    "    try:\n",
    "        return metrics.roc_auc_score(y_true, y_pred)\n",
    "    except ValueError:\n",
    "        return np.nan\n",
    "\n",
    "def compute_subgroup_auc(df, subgroup, label, model_name):\n",
    "    subgroup_examples = df[df[subgroup]]\n",
    "    return compute_auc(subgroup_examples[label], subgroup_examples[model_name])\n",
    "\n",
    "def compute_bpsn_auc(df, subgroup, label, model_name):\n",
    "    \"\"\"Computes the AUC of the within-subgroup negative examples and the background positive examples.\"\"\"\n",
    "    subgroup_negative_examples = df.loc[df[subgroup] & ~df[label]]\n",
    "    non_subgroup_positive_examples = df.loc[~df[subgroup] & df[label]]\n",
    "    examples = subgroup_negative_examples.append(non_subgroup_positive_examples)\n",
    "    return compute_auc(examples[label], examples[model_name])\n",
    "\n",
    "def compute_bnsp_auc(df, subgroup, label, model_name):\n",
    "    \"\"\"Computes the AUC of the within-subgroup positive examples and the background negative examples.\"\"\"\n",
    "    subgroup_positive_examples = df.loc[df[subgroup] & df[label]]\n",
    "    non_subgroup_negative_examples = df.loc[~df[subgroup] & ~df[label]]\n",
    "    examples = subgroup_positive_examples.append(non_subgroup_negative_examples)\n",
    "    return compute_auc(examples[label], examples[model_name])\n",
    "\n",
    "def compute_bias_metrics_for_model(dataset,\n",
    "                                   subgroups,\n",
    "                                   model,\n",
    "                                   label_col,\n",
    "                                   include_asegs=False):\n",
    "    \"\"\"Computes per-subgroup metrics for all subgroups and one model.\"\"\"\n",
    "    records = []\n",
    "    for subgroup in subgroups:\n",
    "        record = {\n",
    "            'subgroup': subgroup,\n",
    "            'subgroup_size': len(dataset.loc[dataset[subgroup]])\n",
    "        }\n",
    "        record[SUBGROUP_AUC] = compute_subgroup_auc(dataset, subgroup, label_col, model)\n",
    "        record[BPSN_AUC] = compute_bpsn_auc(dataset, subgroup, label_col, model)\n",
    "        record[BNSP_AUC] = compute_bnsp_auc(dataset, subgroup, label_col, model)\n",
    "        records.append(record)\n",
    "    return pd.DataFrame(records).sort_values('subgroup_auc', ascending=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These calculations have been provided by Jigsaw AI for scoring based on the metrics of the kaggle competition\n",
    "# https://www.kaggle.com/c/jigsaw-unintended-bias-in-toxicity-classification/overview/evaluation\n",
    "\n",
    "# They work by filtering the relevant dataframe into specific subgroups and using the roc_auc_score metric from sklearn.\n",
    "\n",
    "def calculate_overall_auc(df, model_name):\n",
    "    true_labels = df[TOXICITY_COLUMN]\n",
    "    predicted_labels = df[model_name]\n",
    "    return metrics.roc_auc_score(true_labels, predicted_labels)\n",
    "\n",
    "def power_mean(series, p):\n",
    "    total = sum(np.power(series, p))\n",
    "    return np.power(total / len(series), 1 / p)\n",
    "\n",
    "def get_final_metric(bias_df, overall_auc, POWER=-5, OVERALL_MODEL_WEIGHT=0.25):\n",
    "    bias_score = np.average([\n",
    "        power_mean(bias_df[SUBGROUP_AUC], POWER),\n",
    "        power_mean(bias_df[BPSN_AUC], POWER),\n",
    "        power_mean(bias_df[BNSP_AUC], POWER)\n",
    "    ])\n",
    "    return (OVERALL_MODEL_WEIGHT * overall_auc) + ((1 - OVERALL_MODEL_WEIGHT) * bias_score)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train shape: (1804874,)\n",
      "y_test shape: (194640,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression\n",
    "\n",
    "We will use Grid Search Cross validation to optimize our hyperparameters on the training set. We will then fit the best estimator and then predict on the test set and calculate relevent metrics.\n",
    "\n",
    "Because the subgroup ROCs are calculated post prediction and require predictions to be appended to a dataframe, we cannot actually pass the metrics into the scoring function of scikit-learn's gridsearchCV(). Instead we will just test the models on accuracy and total ROC-AUC and then refitting the grid-search on the model with the best ROC-AUC as a proxy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.65 ms, sys: 3.6 ms, total: 5.25 ms\n",
      "Wall time: 8.3 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVC\n",
    "#no scaling data is already transformed\n",
    "\n",
    "# Instantiate the tokenizer to use in the vectorizer\n",
    "tweet_tokenizer = TweetTokenizer(reduce_len=True)\n",
    "\n",
    "# Instantiate the vectorizer, we will pass in the TweetTokenizer() from nltk \n",
    "tfid_vec_2 = TfidfVectorizer(lowercase=False, tokenizer = tweet_tokenizer.tokenize)\n",
    "\n",
    "# define pipeline\n",
    "pipeline = Pipeline([#('tf-idf', tfid_vec_2), \n",
    "                     ('model', SVC())])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "# Define scoring functions\n",
    "scorers = {'AUC': 'roc_auc', 'Accuracy': make_scorer(accuracy_score)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define parameters\n",
    "param_grid_log = [{'model': [LogisticRegression()], 'tf-idf': [tfid_vec_2], \n",
    "                   'model__penalty': ['l1', 'l2'],\n",
    "                   'model__C': [.001, 0.01, 0.1, 1, 10, 100]}]\n",
    "\n",
    "# Setting refit='AUC', refits an estimator on the whole dataset with the\n",
    "# parameter setting that has the best cross-validated AUC score, i.e it finds the params that gives the best scores\n",
    "# then refits using the ones that give the best AUC. \n",
    "grid_log = GridSearchCV(pipeline, param_grid_log, cv=5, scoring=scorers, refit='AUC', \n",
    "                        return_train_score=True, n_jobs=-1)\n",
    "\n",
    "fittedgrid_log = grid_log.fit(train_df['comment_text_clean_detokenize'], train_df['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib\n",
    "# Save best estimator to file\n",
    "joblib.dump(fittedgrid.best_estimator_, 'saved_models/best_log_reg.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run this to load the model if required\n",
    "from sklearn.externals import joblib\n",
    "from joblib import load\n",
    "fittedgrid_log = load('saved_models/best_log_reg.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get scores\n",
    "train_accuracy = fittedgrid_log.score(train_df['comment_text_clean_detokenize'], y_train)\n",
    "test_accuracy = fittedgrid_log.score(test_df['comment_text_clean_detokenize'], y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict train and test values\n",
    "y_train_pred = fittedgrid_log.predict(train_df['comment_text_clean_detokenize'])\n",
    "y_test_pred = fittedgrid_log.predict(test_df['comment_text_clean_detokenize'])\n",
    "\n",
    "y_train_pred_prob = fittedgrid_log.predict_proba(train_df['comment_text_clean_detokenize'])\n",
    "y_test_pred_prob = fittedgrid_log.predict_proba(test_df['comment_text_clean_detokenize'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.97    179192\n",
      "           1       0.76      0.50      0.60     15448\n",
      "\n",
      "    accuracy                           0.95    194640\n",
      "   macro avg       0.86      0.74      0.79    194640\n",
      "weighted avg       0.94      0.95      0.94    194640\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Confusion Matrix and Classification Report, we want to store the F1 Score.\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# store the precision, recall, and f1 score for later and print the classification report\n",
    "log_precision = precision_score(y_test, y_test_pred)\n",
    "log_recall = recall_score(y_test, y_test_pred)\n",
    "log_f1 = f1_score(y_test, y_test_pred)\n",
    "\n",
    "print(classification_report(y_test, y_test_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append preds and probabilities to train and valid dfs\n",
    "train_df['Prediction_log'] = y_train_pred\n",
    "train_df['Prediction_probability_log'] = y_train_pred_prob[:, 1]\n",
    "test_df['Prediction_log'] = y_test_pred\n",
    "test_df['Prediction_probability_log'] = y_test_pred_prob[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identity columns used to calculate subgroup AUC\n",
    "identity_columns = [\n",
    "    'male', 'female', 'homosexual_gay_or_lesbian', 'christian', 'jewish',\n",
    "    'muslim', 'black', 'white', 'psychiatric_or_mental_illness']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in identity_columns + ['target']:\n",
    "    train_df[col] = np.where(train_df[col] >= 0.5, True, False)\n",
    "    test_df[col] = np.where(test_df[col] >= 0.5, True, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the AUC metrics \n",
    "\n",
    "SUBGROUP_AUC = 'subgroup_auc'\n",
    "BPSN_AUC = 'bpsn_auc'  # stands for background positive, subgroup negative\n",
    "BNSP_AUC = 'bnsp_auc'\n",
    "\n",
    "MODEL_NAME = 'Prediction_log'\n",
    "TOXICITY_COLUMN = 'target'\n",
    "\n",
    "log_bias_metrics_df_train = compute_bias_metrics_for_model(train_df, identity_columns, MODEL_NAME, TOXICITY_COLUMN)\n",
    "log_final_metric_train = get_final_metric(log_bias_metrics_df_train, calculate_overall_auc(train_df, MODEL_NAME))\n",
    "\n",
    "log_bias_metrics_df_test = compute_bias_metrics_for_model(test_df, identity_columns, MODEL_NAME, TOXICITY_COLUMN)\n",
    "log_final_metric_test = get_final_metric(log_bias_metrics_df_test, calculate_overall_auc(test_df, MODEL_NAME))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_bias_metrics_df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'train_accuracy:{train_accuracy}')\n",
    "print(f'train weighted subgroup AUC:{get_final_metric(bias_metrics_df_train, calculate_overall_auc(train_df, MODEL_NAME))}')\n",
    "print(f'test_accuracy:{test_accuracy}')\n",
    "print(f'test weighted subgroup AUC::{get_final_metric(bias_metrics_df_val, calculate_overall_auc(test_df, MODEL_NAME))}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Evaluation:\n",
    "\n",
    "The logistic regression performed well on pure accuracy, with a train accuracy of 95.38% and 94.96% test accuracy. What is also positive to see is that our hyperparameter optimization has led to a model which does not overfit excessively. \n",
    "\n",
    "However when we look at the weighted subgroup AUC metric, the 71.9% train score and 71.5% test score show that the model did have a tendency towards biased predictions for certain subgroup. In comparison, the benchmark CNN that was provided had a weighted AUC score of 88.35% albeit just on a validation set \n",
    "\n",
    "\n",
    "For example we can see that for the 'black' identity BPSN AUC was relatively low, suggesting the model is likely overweighting mentions of the 'black' identity with toxicity. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM\n",
    "\n",
    "We will now carry out a similar process with SVM to see if this performs appreciably different to logistic regression. \n",
    "\n",
    "#### Grid searching on a subset of data\n",
    "\n",
    "Given the length of time taken to grid search using SVM, we will run a gridsearch on a subset of our dataset by taking a new train test split. We will then use the results there as a proxy for the optimal parameters for our full dataset.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# Create a new split of the training dataframe to use for this reduced test. \n",
    "# we will not need the remainder. We will take 1/4 of the total data set\n",
    "remainder, reduced_df = train_test_split(train_df, test_size=0.25, stratify=train_df['target'], random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tfid_vec_2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tfid_vec_2' is not defined"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Grid search applies tfid_vec_2 to all models. We try combinations of model loss function penalty strength and\n",
    "# model gamma  is a parameter for non linear hyperplanes. \n",
    "# The higher the gamma value it tries to exactly fit the training data set\n",
    "\n",
    "param_grid_svc = [{'model__kernel': ['rbf'],'tf-idf': [tfid_vec_2],\n",
    "              'model__C': [0.1, 1, 10,], 'model__gamma': [1, 10, 'scale'], 'model__probability': [True]}]\n",
    "\n",
    "reduced_grid_svm = GridSearchCV(pipeline, param_grid_svc, scoring=scorers, cv=3, refit='AUC',\n",
    "                       return_train_score=True, n_jobs=-1, verbose=10)\n",
    "\n",
    "reduced_grid_svm = reduced_grid_svm.fit(reduced_df['comment_text_clean_detokenize'], reduced_df['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to file \n",
    "import joblib\n",
    "joblib.dump(reduced_grid_svm.best_estimator_, 'saved_models/reduced_svm.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gives the model with the best AUC score\n",
    "reduced_grid_svm.best_estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gives the model with the best AUC score\n",
    "reduced_grid_svm.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Full dataset grid search\n",
    "\n",
    "param_grid_svc = [{'model__kernel': ['rbf'],'tf-idf': [tfid_vec_2],\n",
    "              'model__C': [0.1, 1, 10], 'model__probability': [True]}]\n",
    "\n",
    "grid_svc = GridSearchCV(pipeline, param_grid_svc, scoring=scorers, cv=5, refit='AUC',\n",
    "                       return_train_score=True, n_jobs=-1, verbose=10)\n",
    "\n",
    "fittedgrid_svc = grid_svc.fit(train_df['comment_text_clean_detokenize'], train_df['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save best estimator to file\n",
    "joblib.dump(fittedgrid_svc.best_estimator_, 'saved_models/best_svm.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get scores\n",
    "train_accuracy = fittedgrid_svc.score(train_df['comment_text_clean_detokenize'], y_train)\n",
    "test_accuracy = fittedgrid_svc.score(test_df['comment_text_clean_detokenize'], y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict train and test values\n",
    "y_train_pred = fittedgrid_svc.predict(train_df['comment_text_clean_detokenize'])\n",
    "y_test_pred = fittedgrid_svc.predict(test_df['comment_text_clean_detokenize'])\n",
    "\n",
    "y_train_pred_prob = fittedgrid_svc.predict_proba(train_df['comment_text_clean_detokenize'])\n",
    "y_test_pred_prob = fittedgrid_svc.predict_proba(test_df['comment_text_clean_detokenize'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store the precision, recall, and f1 score for later and print the classification report\n",
    "svm_precision = precision_score(y_test, y_test_pred)\n",
    "svm_recall = recall_score(y_test, y_test_pred)\n",
    "svm_f1 = f1_score(y_test, y_test_pred)\n",
    "\n",
    "display(classification_report(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append preds and probabilities to train and valid dfs\n",
    "train_df['Prediction_svc'] = y_train_pred\n",
    "train_df['Prediction_probability_svc'] = y_train_pred_prob[:, 1]\n",
    "test_df['Prediction_svc'] = y_test_pred\n",
    "test_df['Prediction_probability_svc'] = y_test_pred_prob[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the AUC metrics \n",
    "\n",
    "SUBGROUP_AUC = 'subgroup_auc'\n",
    "BPSN_AUC = 'bpsn_auc'  # stands for background positive, subgroup negative\n",
    "BNSP_AUC = 'bnsp_auc'\n",
    "\n",
    "MODEL_NAME = 'Prediction_svc'\n",
    "TOXICITY_COLUMN = 'target'\n",
    "\n",
    "svm_bias_metrics_df_train = compute_bias_metrics_for_model(train_df, identity_columns, MODEL_NAME, TOXICITY_COLUMN)\n",
    "svm_final_metric_train = get_final_metric(svm_bias_metrics_df_train, calculate_overall_auc(train_df, MODEL_NAME))\n",
    "\n",
    "svm_bias_metrics_df_test = compute_bias_metrics_for_model(test_df, identity_columns, MODEL_NAME, TOXICITY_COLUMN)\n",
    "svm_final_metric_test get_final_metric(svm_bias_metrics_df_test, calculate_overall_auc(test_df, MODEL_NAME))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest -- Put in code for single run rf model \n",
    "\n",
    "For our final model we will try the Random Forest Classifier which is an ensemble method. It is based on the Decision Tree model, only the Random Forest works by fitting on random sub samples of the data (with replacement), which is known as 'bagging'. A voting algorithm is then applied on the results of each of the trees to determine the final class of the data point. The aim of Random Forest is to train a series of overfit models and then average out the results via voting to get better results. The main hyperparemeter we will optimize for is the number of decision trees to use. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grid Search on a subset of data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the length of time taken to grid search on the Random Forest Classifier, we will run a gridsearch on a subset of our dataset by taking a new train test split. We will then use the results there as a proxy for the optimal parameters for our full dataset. We will use the same train_test split as used for the SVM subset search. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:  5.4min\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed: 13.1min\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed: 35.6min\n",
      "[Parallel(n_jobs=-1)]: Done  25 out of  36 | elapsed: 78.8min remaining: 34.7min\n",
      "[Parallel(n_jobs=-1)]: Done  29 out of  36 | elapsed: 113.6min remaining: 27.4min\n",
      "[Parallel(n_jobs=-1)]: Done  33 out of  36 | elapsed: 132.4min remaining: 12.0min\n",
      "[Parallel(n_jobs=-1)]: Done  36 out of  36 | elapsed: 165.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 50min 44s, sys: 12.9 s, total: 50min 57s\n",
      "Wall time: 3h 35min 49s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Note, most of the time here actually comes from the application of the tfid vectorizer to each fold of the data\n",
    "# Random forest itself takes ~5minutes to run on the vectorized data.\n",
    "\n",
    "# We control the model max depth \n",
    "param_grid_RF = {'model': [RandomForestClassifier()], 'tf-idf': [tfid_vec_2], \n",
    "                 'model__n_estimators': [10,50,100],\n",
    "                 'model__max_depth': [100, 500, 1000, 5000],\n",
    "             }\n",
    "reduced_grid_RF = GridSearchCV(pipeline, param_grid_RF, scoring=scorers, cv=3, refit='AUC',\n",
    "                       return_train_score=True, n_jobs=-1, verbose = 10)\n",
    "\n",
    "reduced_grid_RF = reduced_grid_RF.fit(reduced_df['comment_text_clean_detokenize'], reduced_df['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('tf-idf',\n",
       "                 TfidfVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.float64'>,\n",
       "                                 encoding='utf-8', input='content',\n",
       "                                 lowercase=False, max_df=1.0, max_features=None,\n",
       "                                 min_df=1, ngram_range=(1, 1), norm='l2',\n",
       "                                 preprocessor=None, smooth_idf=True,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 sublinear_tf=False,\n",
       "                                 token_pattern...\n",
       "                 RandomForestClassifier(bootstrap=True, class_weight=None,\n",
       "                                        criterion='gini', max_depth=1000,\n",
       "                                        max_features='auto',\n",
       "                                        max_leaf_nodes=None,\n",
       "                                        min_impurity_decrease=0.0,\n",
       "                                        min_impurity_split=None,\n",
       "                                        min_samples_leaf=1, min_samples_split=2,\n",
       "                                        min_weight_fraction_leaf=0.0,\n",
       "                                        n_estimators=100, n_jobs=None,\n",
       "                                        oob_score=False, random_state=None,\n",
       "                                        verbose=0, warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the best estimator parameters\n",
    "reduced_grid_RF.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9230210872062684"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# gives the best AUC score\n",
    "reduced_grid_RF.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reduced_grid_RF.cv_results_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above test has suggested that in terms of hyperparameters, we should look at a model that has n_estimators around 100 or above, and max_depth of around 1000. We will use this as a guide for our grid search. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grid Search in the full dataset\n",
    "Now that we have a good idea of optimal parameters, we will run another grid search on a few parameters around the optimal figures provided by our test on the subset of data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running a grid-search on the full set of data\n",
    "param_grid_RF = {'model': [RandomForestClassifier()], 'tf-idf': [tfid_vec_2], \n",
    "                 'model__n_estimators': [100,150,200],\n",
    "                 'model__max_depth': [1000, 2000, 3000, 4000],\n",
    "             }\n",
    "grid_RF = GridSearchCV(pipeline, param_grid_RF, scoring=scorers, cv=3, refit='AUC',\n",
    "                       return_train_score=True, n_jobs=-1, verbose = 10)\n",
    "\n",
    "fittedgrid_RF = grid_RF.fit(train_df['comment_text_clean_detokenize'], train_df['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['saved_models/best_RF.pkl']"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save best estimator to file\n",
    "joblib.dump(RF_model, 'saved_models/best_gridRF.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict train and test values\n",
    "y_train_pred = fittedgrid_RF.predict(train_df['comment_text_clean_detokenize'])\n",
    "y_test_pred = fittedgrid_RF.predict(test_df['comment_text_clean_detokenize'])\n",
    "\n",
    "# predict probabilities\n",
    "y_train_pred_prob = fittedgrid_RF.predict_proba(train_df['comment_text_clean_detokenize'])\n",
    "y_test_pred_prob = fittedgrid_RF.predict_proba(test_df['comment_text_clean_detokenize'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store the precision, recall, and f1 score for later and print the classification report\n",
    "rf_precision = precision_score(y_test, y_test_pred)\n",
    "rf_recall = recall_score(y_test, y_test_pred)\n",
    "rf_f1 = f1_score(y_test, y_test_pred)\n",
    "\n",
    "display(classification_report(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identity columns used to calculate subgroup AUC\n",
    "identity_columns = [\n",
    "    'male', 'female', 'homosexual_gay_or_lesbian', 'christian', 'jewish',\n",
    "    'muslim', 'black', 'white', 'psychiatric_or_mental_illness']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in identity_columns + ['target']:\n",
    "    train_df[col] = np.where(train_df[col] >= 0.5, True, False)\n",
    "    test_df[col] = np.where(test_df[col] >= 0.5, True, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append preds and probabilities to train and valid dfs\n",
    "train_df['Prediction_RF'] = y_train_pred\n",
    "train_df['Prediction_probability_RF'] = y_train_pred_prob[:, 1]\n",
    "test_df['Prediction_RF'] = y_test_pred\n",
    "test_df['Prediction_probability_RF'] = y_test_pred_prob[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the AUC metrics \n",
    "\n",
    "SUBGROUP_AUC = 'subgroup_auc'\n",
    "BPSN_AUC = 'bpsn_auc'  # stands for background positive, subgroup negative\n",
    "BNSP_AUC = 'bnsp_auc'\n",
    "\n",
    "MODEL_NAME = 'Prediction_RF'\n",
    "TOXICITY_COLUMN = 'target'\n",
    "\n",
    "rf_bias_metrics_df_train = compute_bias_metrics_for_model(train_df, identity_columns, MODEL_NAME, TOXICITY_COLUMN)\n",
    "rf_final_metric_train = get_final_metric(rf_bias_metrics_df_train, calculate_overall_auc(train_df, MODEL_NAME))\n",
    "\n",
    "rf_bias_metrics_df_test = compute_bias_metrics_for_model(test_df, identity_columns, MODEL_NAME, TOXICITY_COLUMN)\n",
    "rf_final_metric_test = get_final_metric(rf_bias_metrics_df_test, calculate_overall_auc(test_df, MODEL_NAME))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_bias_metrics_df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_final_metric_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'train_accuracy:{train_accuracy}')\n",
    "print(f'train weighted AUC:{rf_final_metric_train}')\n",
    "print(f'test_accuracy:{test_accuracy}')\n",
    "print(f'test weighted AUC::{rf_final_metric_test}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "We can see that the best estimator was selected with no bound on the max tree depth. THis has caused the model to significantly overfit on "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model performance\n",
    "\n",
    "Now that we have trained three seperate models which have been shown to deliver strong performance in text classification tasks in the past let us take the time to compare them side-by-side and also discuss their short-comings in terms of reducing bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Display the subgroup bias metrics tables for each model and then the final metrics for each model for test only\n",
    "display(log_bias_metrics_df_test)\n",
    "display(svm_bias_metrics_df_test)\n",
    "display(rf_bias_metrics_df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display final metrics for each model for test only.\n",
    "print(f' Final metric for Logistic Regression: {log_final_metric_test}')\n",
    "print(f' Final metric for SVM: {svm_final_metric_test}')\n",
    "print(f' Final metric for Random Forest: {rf_final_metric_test}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'Accuracy': [log_accuracy, svm_accuracy, rf_accuracy], 'Precision': [log_precision, svm_precision, rf_precision],\n",
    "       'Recall': [log_recall, svm_recall, rf_recall], 'F1': [log_f1, svm_f1, rf_f1],\n",
    "       'Final Bias Metric': [log_bias_metrics_df_test, svm_bias_metrics_df_test, rf_bias_metrics_df_test ]}\n",
    "\n",
    "results_df = pd.DataFrame(data, index=['Logistic', 'Precision', 'Recall', 'Final Bias Metric'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the results of our ML models with LIME\n",
    "\n",
    "Below we use the eli5 implementation of [LIME](https://github.com/marcotcr/lime) to help interpret how our models are coming to their classifications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import eli5\n",
    "from eli5.lime import TextExplainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in log model\n",
    "joblib.dump(fittedgrid.best_estimator_, 'saved_models/best_log_reg.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "    table.eli5-weights tr:hover {\n",
       "        filter: brightness(85%);\n",
       "    }\n",
       "</style>\n",
       "\n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "        \n",
       "\n",
       "    \n",
       "\n",
       "        \n",
       "\n",
       "        \n",
       "    \n",
       "        \n",
       "        \n",
       "    \n",
       "        <p style=\"margin-bottom: 0.5em; margin-top: 0em\">\n",
       "            <b>\n",
       "    \n",
       "        y=1\n",
       "    \n",
       "</b>\n",
       "\n",
       "    \n",
       "    (probability <b>0.736</b>, score <b>1.024</b>)\n",
       "\n",
       "top features\n",
       "        </p>\n",
       "    \n",
       "    <table class=\"eli5-weights\"\n",
       "           style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto; margin-bottom: 2em;\">\n",
       "        <thead>\n",
       "        <tr style=\"border: none;\">\n",
       "            \n",
       "                <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\" title=\"Feature contribution already accounts for the feature value (for linear models, contribution = weight * feature value), and the sum of feature contributions is equal to the score or, for some classifiers, to the probability. Feature values are shown if &quot;show_feature_values&quot; is True.\">\n",
       "                    Contribution<sup>?</sup>\n",
       "                </th>\n",
       "            \n",
       "            <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
       "            \n",
       "        </tr>\n",
       "        </thead>\n",
       "        <tbody>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 80.00%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +1.845\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        Highlighted in text (sum)\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "        \n",
       "\n",
       "        \n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 88.65%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.821\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        &lt;BIAS&gt;\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "\n",
       "        </tbody>\n",
       "    </table>\n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "\n",
       "    <p style=\"margin-bottom: 2.5em; margin-top:-0.5em;\">\n",
       "        <span style=\"background-color: hsl(120, 100.00%, 99.63%); opacity: 0.80\" title=\"0.004\">in</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 94.16%); opacity: 0.81\" title=\"-0.188\">the</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 98.77%); opacity: 0.80\" title=\"-0.020\">us</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 95.35%); opacity: 0.81\" title=\"-0.136\">at</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 99.45%); opacity: 0.80\" title=\"0.006\">least</span><span style=\"opacity: 0.80\">, </span><span style=\"background-color: hsl(120, 100.00%, 98.69%); opacity: 0.80\" title=\"0.022\">someone</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 93.21%); opacity: 0.82\" title=\"-0.233\">who</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 97.66%); opacity: 0.80\" title=\"-0.051\">is</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 85.42%); opacity: 0.85\" title=\"-0.695\">half</span><span style=\"opacity: 0.80\">-</span><span style=\"background-color: hsl(120, 100.00%, 94.32%); opacity: 0.81\" title=\"0.181\">black</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 99.08%); opacity: 0.80\" title=\"-0.013\">is</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 99.60%); opacity: 0.80\" title=\"0.004\">considered</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 95.00%); opacity: 0.81\" title=\"-0.151\">to</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 98.05%); opacity: 0.80\" title=\"0.039\">be</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 84.28%); opacity: 0.85\" title=\"0.774\">black</span><span style=\"opacity: 0.80\">. </span><span style=\"background-color: hsl(0, 100.00%, 97.84%); opacity: 0.80\" title=\"-0.045\">my</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 98.44%); opacity: 0.80\" title=\"0.029\">grandchildren</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 97.95%); opacity: 0.80\" title=\"-0.042\">have</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 94.44%); opacity: 0.81\" title=\"-0.176\">a</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 84.64%); opacity: 0.85\" title=\"0.749\">white</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 98.24%); opacity: 0.80\" title=\"-0.034\">father</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 90.39%); opacity: 0.83\" title=\"-0.383\">and</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 93.76%); opacity: 0.81\" title=\"-0.207\">a</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 83.95%); opacity: 0.85\" title=\"0.797\">black</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 98.57%); opacity: 0.80\" title=\"0.025\">mother</span><span style=\"opacity: 0.80\">, </span><span style=\"background-color: hsl(0, 100.00%, 91.90%); opacity: 0.82\" title=\"-0.300\">and</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 95.37%); opacity: 0.81\" title=\"0.135\">are</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 98.31%); opacity: 0.80\" title=\"0.032\">seen</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 60.00%); opacity: 1.00\" title=\"2.940\">as</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 85.14%); opacity: 0.85\" title=\"0.714\">black</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 93.42%); opacity: 0.82\" title=\"-0.223\">by</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 92.65%); opacity: 0.82\" title=\"-0.261\">just</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 93.40%); opacity: 0.82\" title=\"-0.224\">about</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 98.29%); opacity: 0.80\" title=\"0.032\">everyone</span><span style=\"opacity: 0.80\">.</span>\n",
       "    </p>\n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate the lime TextExplainer model\n",
    "text_model_log = TextExplainer(random_state=1)\n",
    "\n",
    "#select a comment to investigate\n",
    "text = test_df.loc[59102,'comment_text']\n",
    "\n",
    "# Fit the Textexplainer using the logistic model predicted probabilites\n",
    "text_model_log.fit(text, fittedgrid_log.predict_proba)\n",
    "text_model_log.show_prediction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         jeff session another one trump orwellian choic...\n",
       "1         actually inspected infrastructure grand chief ...\n",
       "2         wishful thinking democrat fault  100 th time  ...\n",
       "3         instead wringing hand nibbling periphery issue...\n",
       "4         many commenters garbage piled high yard  bald ...\n",
       "                                ...                        \n",
       "194635    lose job promoting misinformation harmful student\n",
       "194636    thinning project meant lower fire danger impro...\n",
       "194637            hope millennials happy put airhead charge\n",
       "194638    I thinking kellyanne conway   k   trump whispe...\n",
       "194639    still figure pizza ak cost pizza washington  i...\n",
       "Name: comment_text_clean_detokenize, Length: 194640, dtype: object"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df['comment_text_clean_detokenize']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>created_date</th>\n",
       "      <th>publication_id</th>\n",
       "      <th>article_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>funny</th>\n",
       "      <th>wow</th>\n",
       "      <th>sad</th>\n",
       "      <th>likes</th>\n",
       "      <th>...</th>\n",
       "      <th>physical_disability</th>\n",
       "      <th>intellectual_or_learning_disability</th>\n",
       "      <th>psychiatric_or_mental_illness</th>\n",
       "      <th>other_disability</th>\n",
       "      <th>comment_text_clean</th>\n",
       "      <th>comment_text_clean_detokenize</th>\n",
       "      <th>Prediction_svc</th>\n",
       "      <th>Prediction_probability_svc</th>\n",
       "      <th>Prediction_log</th>\n",
       "      <th>Prediction_probability_log</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>86549</th>\n",
       "      <td>7086549</td>\n",
       "      <td>Now you're not making sense, what's golf got t...</td>\n",
       "      <td>2017-09-08 17:06:59.026680+00</td>\n",
       "      <td>102</td>\n",
       "      <td>375328</td>\n",
       "      <td>approved</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[making, sense, , golf, got, , talked, murder,...</td>\n",
       "      <td>making sense  golf got  talked murder gay syri...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.661940</td>\n",
       "      <td>1</td>\n",
       "      <td>0.661940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92316</th>\n",
       "      <td>7092316</td>\n",
       "      <td>CE:  No, CE, I am not a homosexual.  I'm a mon...</td>\n",
       "      <td>2017-09-28 16:36:03.981659+00</td>\n",
       "      <td>13</td>\n",
       "      <td>382691</td>\n",
       "      <td>approved</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[ce, , , ce, , homosexual, , I, monogamous, he...</td>\n",
       "      <td>ce   ce  homosexual  I monogamous heterosexual...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.575447</td>\n",
       "      <td>1</td>\n",
       "      <td>0.575447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92740</th>\n",
       "      <td>7092740</td>\n",
       "      <td>&gt;I am not defending the DUP\\r\\nLiar ! You STAR...</td>\n",
       "      <td>2017-06-10 06:40:45.143685+00</td>\n",
       "      <td>100</td>\n",
       "      <td>342372</td>\n",
       "      <td>rejected</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[, defending, dup, liar, , started, thread, de...</td>\n",
       "      <td>defending dup liar  started thread defending d...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.524313</td>\n",
       "      <td>1</td>\n",
       "      <td>0.524313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92835</th>\n",
       "      <td>7092835</td>\n",
       "      <td>It is disgraceful that BLM has managed to hija...</td>\n",
       "      <td>2017-03-28 20:54:10.058917+00</td>\n",
       "      <td>54</td>\n",
       "      <td>322763</td>\n",
       "      <td>approved</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[disgraceful, blm, managed, hijack, joyful, ev...</td>\n",
       "      <td>disgraceful blm managed hijack joyful event li...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.633841</td>\n",
       "      <td>1</td>\n",
       "      <td>0.633841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93236</th>\n",
       "      <td>7093236</td>\n",
       "      <td>We bring flowers to the dead be they school ki...</td>\n",
       "      <td>2016-06-24 20:09:07.725714+00</td>\n",
       "      <td>22</td>\n",
       "      <td>139610</td>\n",
       "      <td>approved</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[bring, flower, dead, school, kid, , black, bi...</td>\n",
       "      <td>bring flower dead school kid  black bible stud...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.514338</td>\n",
       "      <td>1</td>\n",
       "      <td>0.514338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94241</th>\n",
       "      <td>7094241</td>\n",
       "      <td>Gay men were the vanguard of fighting for marr...</td>\n",
       "      <td>2017-06-23 20:03:45.454887+00</td>\n",
       "      <td>54</td>\n",
       "      <td>347124</td>\n",
       "      <td>approved</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[gay, men, vanguard, fighting, marriage, right...</td>\n",
       "      <td>gay men vanguard fighting marriage right three...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.968993</td>\n",
       "      <td>1</td>\n",
       "      <td>0.968993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95145</th>\n",
       "      <td>7095145</td>\n",
       "      <td>Technically speaking, sodomy always involves s...</td>\n",
       "      <td>2017-08-16 23:43:10.028061+00</td>\n",
       "      <td>53</td>\n",
       "      <td>366698</td>\n",
       "      <td>approved</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[technically, speaking, , sodomy, always, invo...</td>\n",
       "      <td>technically speaking  sodomy always involves r...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.547827</td>\n",
       "      <td>1</td>\n",
       "      <td>0.547827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96458</th>\n",
       "      <td>7096458</td>\n",
       "      <td>More news outlets are deleting their commentar...</td>\n",
       "      <td>2017-04-27 13:48:21.733011+00</td>\n",
       "      <td>54</td>\n",
       "      <td>329864</td>\n",
       "      <td>approved</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[news, outlet, deleting, commentary, site, , g...</td>\n",
       "      <td>news outlet deleting commentary site  great li...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.538284</td>\n",
       "      <td>1</td>\n",
       "      <td>0.538284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97878</th>\n",
       "      <td>7097878</td>\n",
       "      <td>what the church teaches and what we put in law...</td>\n",
       "      <td>2017-03-30 02:29:15.699248+00</td>\n",
       "      <td>53</td>\n",
       "      <td>323025</td>\n",
       "      <td>approved</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[church, teach, put, law, two, different, thin...</td>\n",
       "      <td>church teach put law two different thing  form...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.795253</td>\n",
       "      <td>1</td>\n",
       "      <td>0.795253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100173</th>\n",
       "      <td>7100173</td>\n",
       "      <td>Regarding: \"We begin with Rana Abdelhamid, fou...</td>\n",
       "      <td>2016-12-31 03:47:28.256764+00</td>\n",
       "      <td>53</td>\n",
       "      <td>159288</td>\n",
       "      <td>approved</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[regarding, , , begin, rana, abdelhamid, , fou...</td>\n",
       "      <td>regarding   begin rana abdelhamid  founder wom...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.556937</td>\n",
       "      <td>1</td>\n",
       "      <td>0.556937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100223</th>\n",
       "      <td>7100223</td>\n",
       "      <td>Not only is the gay rights movement (gay agend...</td>\n",
       "      <td>2017-09-29 06:16:50.346425+00</td>\n",
       "      <td>13</td>\n",
       "      <td>382691</td>\n",
       "      <td>approved</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[gay, right, movement, , gay, agenda, , upfron...</td>\n",
       "      <td>gay right movement  gay agenda  upfront desire...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.866201</td>\n",
       "      <td>1</td>\n",
       "      <td>0.866201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102674</th>\n",
       "      <td>7102674</td>\n",
       "      <td>The pathological liar and thief is Trump. He c...</td>\n",
       "      <td>2016-11-29 20:51:18.904545+00</td>\n",
       "      <td>53</td>\n",
       "      <td>153390</td>\n",
       "      <td>approved</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[pathological, liar, thief, trump, , constantl...</td>\n",
       "      <td>pathological liar thief trump  constantly lied...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.507863</td>\n",
       "      <td>1</td>\n",
       "      <td>0.507863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103848</th>\n",
       "      <td>7103848</td>\n",
       "      <td>Is one of them gay?</td>\n",
       "      <td>2017-11-08 00:49:22.909838+00</td>\n",
       "      <td>55</td>\n",
       "      <td>398190</td>\n",
       "      <td>approved</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[one, gay, ]</td>\n",
       "      <td>one gay</td>\n",
       "      <td>1</td>\n",
       "      <td>0.927896</td>\n",
       "      <td>1</td>\n",
       "      <td>0.927896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104393</th>\n",
       "      <td>7104393</td>\n",
       "      <td>Every Texan and Republican should be blessed w...</td>\n",
       "      <td>2017-01-01 01:50:12.178343+00</td>\n",
       "      <td>21</td>\n",
       "      <td>159480</td>\n",
       "      <td>approved</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[every, texan, republican, blessed, gay, son, ...</td>\n",
       "      <td>every texan republican blessed gay son daughte...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.675990</td>\n",
       "      <td>1</td>\n",
       "      <td>0.675990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105138</th>\n",
       "      <td>7105138</td>\n",
       "      <td>Why do you say that? I believe she's gay and n...</td>\n",
       "      <td>2017-08-17 16:09:04.982193+00</td>\n",
       "      <td>55</td>\n",
       "      <td>367434</td>\n",
       "      <td>approved</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[say, , believe, gay, trans, , gay, involved, ...</td>\n",
       "      <td>say  believe gay trans  gay involved situation...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.708059</td>\n",
       "      <td>1</td>\n",
       "      <td>0.708059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105197</th>\n",
       "      <td>7105197</td>\n",
       "      <td>Gay Pride surely includes black people who are...</td>\n",
       "      <td>2017-06-26 04:21:36.751340+00</td>\n",
       "      <td>54</td>\n",
       "      <td>348505</td>\n",
       "      <td>approved</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[gay, pride, surely, includes, black, people, ...</td>\n",
       "      <td>gay pride surely includes black people gay  issue</td>\n",
       "      <td>1</td>\n",
       "      <td>0.957487</td>\n",
       "      <td>1</td>\n",
       "      <td>0.957487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106309</th>\n",
       "      <td>7106309</td>\n",
       "      <td>And an examination of gay and lesbian domestic...</td>\n",
       "      <td>2017-06-23 20:13:28.906701+00</td>\n",
       "      <td>54</td>\n",
       "      <td>347124</td>\n",
       "      <td>approved</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[examination, gay, lesbian, domestic, violence...</td>\n",
       "      <td>examination gay lesbian domestic violence rate...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.594038</td>\n",
       "      <td>1</td>\n",
       "      <td>0.594038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106897</th>\n",
       "      <td>7106897</td>\n",
       "      <td>Sex is not a toy, but its unitive role in marr...</td>\n",
       "      <td>2017-04-06 23:12:44.154948+00</td>\n",
       "      <td>53</td>\n",
       "      <td>324243</td>\n",
       "      <td>approved</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[sex, toy, , unitive, role, marriage, doctrina...</td>\n",
       "      <td>sex toy  unitive role marriage doctrinal  desi...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.571512</td>\n",
       "      <td>1</td>\n",
       "      <td>0.571512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107931</th>\n",
       "      <td>7107931</td>\n",
       "      <td>Thank you Rodney Diverticulitis and the rest o...</td>\n",
       "      <td>2017-06-26 10:58:37.778350+00</td>\n",
       "      <td>54</td>\n",
       "      <td>348505</td>\n",
       "      <td>approved</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[thank, rodney, diverticulitis, rest, blm, sho...</td>\n",
       "      <td>thank rodney diverticulitis rest blm showing u...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.590005</td>\n",
       "      <td>1</td>\n",
       "      <td>0.590005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109740</th>\n",
       "      <td>7109740</td>\n",
       "      <td>The question was about a Kosher or Halal deli ...</td>\n",
       "      <td>2017-09-08 13:42:14.028682+00</td>\n",
       "      <td>102</td>\n",
       "      <td>375328</td>\n",
       "      <td>approved</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[question, kosher, halal, deli, sued, serving,...</td>\n",
       "      <td>question kosher halal deli sued serving pork  ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.566817</td>\n",
       "      <td>1</td>\n",
       "      <td>0.566817</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             id                                       comment_text  \\\n",
       "86549   7086549  Now you're not making sense, what's golf got t...   \n",
       "92316   7092316  CE:  No, CE, I am not a homosexual.  I'm a mon...   \n",
       "92740   7092740  >I am not defending the DUP\\r\\nLiar ! You STAR...   \n",
       "92835   7092835  It is disgraceful that BLM has managed to hija...   \n",
       "93236   7093236  We bring flowers to the dead be they school ki...   \n",
       "94241   7094241  Gay men were the vanguard of fighting for marr...   \n",
       "95145   7095145  Technically speaking, sodomy always involves s...   \n",
       "96458   7096458  More news outlets are deleting their commentar...   \n",
       "97878   7097878  what the church teaches and what we put in law...   \n",
       "100173  7100173  Regarding: \"We begin with Rana Abdelhamid, fou...   \n",
       "100223  7100223  Not only is the gay rights movement (gay agend...   \n",
       "102674  7102674  The pathological liar and thief is Trump. He c...   \n",
       "103848  7103848                                Is one of them gay?   \n",
       "104393  7104393  Every Texan and Republican should be blessed w...   \n",
       "105138  7105138  Why do you say that? I believe she's gay and n...   \n",
       "105197  7105197  Gay Pride surely includes black people who are...   \n",
       "106309  7106309  And an examination of gay and lesbian domestic...   \n",
       "106897  7106897  Sex is not a toy, but its unitive role in marr...   \n",
       "107931  7107931  Thank you Rodney Diverticulitis and the rest o...   \n",
       "109740  7109740  The question was about a Kosher or Halal deli ...   \n",
       "\n",
       "                         created_date  publication_id  article_id    rating  \\\n",
       "86549   2017-09-08 17:06:59.026680+00             102      375328  approved   \n",
       "92316   2017-09-28 16:36:03.981659+00              13      382691  approved   \n",
       "92740   2017-06-10 06:40:45.143685+00             100      342372  rejected   \n",
       "92835   2017-03-28 20:54:10.058917+00              54      322763  approved   \n",
       "93236   2016-06-24 20:09:07.725714+00              22      139610  approved   \n",
       "94241   2017-06-23 20:03:45.454887+00              54      347124  approved   \n",
       "95145   2017-08-16 23:43:10.028061+00              53      366698  approved   \n",
       "96458   2017-04-27 13:48:21.733011+00              54      329864  approved   \n",
       "97878   2017-03-30 02:29:15.699248+00              53      323025  approved   \n",
       "100173  2016-12-31 03:47:28.256764+00              53      159288  approved   \n",
       "100223  2017-09-29 06:16:50.346425+00              13      382691  approved   \n",
       "102674  2016-11-29 20:51:18.904545+00              53      153390  approved   \n",
       "103848  2017-11-08 00:49:22.909838+00              55      398190  approved   \n",
       "104393  2017-01-01 01:50:12.178343+00              21      159480  approved   \n",
       "105138  2017-08-17 16:09:04.982193+00              55      367434  approved   \n",
       "105197  2017-06-26 04:21:36.751340+00              54      348505  approved   \n",
       "106309  2017-06-23 20:13:28.906701+00              54      347124  approved   \n",
       "106897  2017-04-06 23:12:44.154948+00              53      324243  approved   \n",
       "107931  2017-06-26 10:58:37.778350+00              54      348505  approved   \n",
       "109740  2017-09-08 13:42:14.028682+00             102      375328  approved   \n",
       "\n",
       "        funny  wow  sad  likes  ...  physical_disability  \\\n",
       "86549       0    0    0      0  ...                    0   \n",
       "92316       1    0    1      2  ...                    0   \n",
       "92740       0    0    0      0  ...                    0   \n",
       "92835       0    0    0     25  ...                    0   \n",
       "93236       0    0    0      1  ...                    0   \n",
       "94241       0    0    0      1  ...                    0   \n",
       "95145       0    0    0      0  ...                    0   \n",
       "96458       0    0    0      6  ...                    0   \n",
       "97878       0    0    0      4  ...                    0   \n",
       "100173      0    0    0      4  ...                    0   \n",
       "100223      0    0    0      0  ...                    0   \n",
       "102674      0    0    0     18  ...                    0   \n",
       "103848      0    0    0      0  ...                    0   \n",
       "104393      2    1    0      3  ...                    0   \n",
       "105138      0    0    0      0  ...                    0   \n",
       "105197      1    0    1     11  ...                    0   \n",
       "106309      0    0    0      1  ...                    0   \n",
       "106897      0    0    0      2  ...                    0   \n",
       "107931      0    0    0     43  ...                    0   \n",
       "109740      0    0    0      1  ...                    0   \n",
       "\n",
       "        intellectual_or_learning_disability  psychiatric_or_mental_illness  \\\n",
       "86549                                     0                              0   \n",
       "92316                                     0                              0   \n",
       "92740                                     0                              0   \n",
       "92835                                     0                              0   \n",
       "93236                                     0                              0   \n",
       "94241                                     0                              0   \n",
       "95145                                     0                              0   \n",
       "96458                                     0                              0   \n",
       "97878                                     0                              0   \n",
       "100173                                    0                              0   \n",
       "100223                                    0                              0   \n",
       "102674                                    0                              0   \n",
       "103848                                    0                              0   \n",
       "104393                                    0                              0   \n",
       "105138                                    0                              0   \n",
       "105197                                    0                              0   \n",
       "106309                                    0                              0   \n",
       "106897                                    0                              0   \n",
       "107931                                    0                              0   \n",
       "109740                                    0                              0   \n",
       "\n",
       "        other_disability                                 comment_text_clean  \\\n",
       "86549                  0  [making, sense, , golf, got, , talked, murder,...   \n",
       "92316                  0  [ce, , , ce, , homosexual, , I, monogamous, he...   \n",
       "92740                  0  [, defending, dup, liar, , started, thread, de...   \n",
       "92835                  0  [disgraceful, blm, managed, hijack, joyful, ev...   \n",
       "93236                  0  [bring, flower, dead, school, kid, , black, bi...   \n",
       "94241                  0  [gay, men, vanguard, fighting, marriage, right...   \n",
       "95145                  0  [technically, speaking, , sodomy, always, invo...   \n",
       "96458                  0  [news, outlet, deleting, commentary, site, , g...   \n",
       "97878                  0  [church, teach, put, law, two, different, thin...   \n",
       "100173                 0  [regarding, , , begin, rana, abdelhamid, , fou...   \n",
       "100223                 0  [gay, right, movement, , gay, agenda, , upfron...   \n",
       "102674                 0  [pathological, liar, thief, trump, , constantl...   \n",
       "103848                 0                                       [one, gay, ]   \n",
       "104393                 0  [every, texan, republican, blessed, gay, son, ...   \n",
       "105138                 0  [say, , believe, gay, trans, , gay, involved, ...   \n",
       "105197                 0  [gay, pride, surely, includes, black, people, ...   \n",
       "106309                 0  [examination, gay, lesbian, domestic, violence...   \n",
       "106897                 0  [sex, toy, , unitive, role, marriage, doctrina...   \n",
       "107931                 0  [thank, rodney, diverticulitis, rest, blm, sho...   \n",
       "109740                 0  [question, kosher, halal, deli, sued, serving,...   \n",
       "\n",
       "                            comment_text_clean_detokenize  Prediction_svc  \\\n",
       "86549   making sense  golf got  talked murder gay syri...               1   \n",
       "92316   ce   ce  homosexual  I monogamous heterosexual...               1   \n",
       "92740   defending dup liar  started thread defending d...               1   \n",
       "92835   disgraceful blm managed hijack joyful event li...               1   \n",
       "93236   bring flower dead school kid  black bible stud...               1   \n",
       "94241   gay men vanguard fighting marriage right three...               1   \n",
       "95145   technically speaking  sodomy always involves r...               1   \n",
       "96458   news outlet deleting commentary site  great li...               1   \n",
       "97878   church teach put law two different thing  form...               1   \n",
       "100173  regarding   begin rana abdelhamid  founder wom...               1   \n",
       "100223  gay right movement  gay agenda  upfront desire...               1   \n",
       "102674  pathological liar thief trump  constantly lied...               1   \n",
       "103848                                            one gay               1   \n",
       "104393  every texan republican blessed gay son daughte...               1   \n",
       "105138  say  believe gay trans  gay involved situation...               1   \n",
       "105197  gay pride surely includes black people gay  issue               1   \n",
       "106309  examination gay lesbian domestic violence rate...               1   \n",
       "106897  sex toy  unitive role marriage doctrinal  desi...               1   \n",
       "107931  thank rodney diverticulitis rest blm showing u...               1   \n",
       "109740  question kosher halal deli sued serving pork  ...               1   \n",
       "\n",
       "        Prediction_probability_svc  Prediction_log  Prediction_probability_log  \n",
       "86549                     0.661940               1                    0.661940  \n",
       "92316                     0.575447               1                    0.575447  \n",
       "92740                     0.524313               1                    0.524313  \n",
       "92835                     0.633841               1                    0.633841  \n",
       "93236                     0.514338               1                    0.514338  \n",
       "94241                     0.968993               1                    0.968993  \n",
       "95145                     0.547827               1                    0.547827  \n",
       "96458                     0.538284               1                    0.538284  \n",
       "97878                     0.795253               1                    0.795253  \n",
       "100173                    0.556937               1                    0.556937  \n",
       "100223                    0.866201               1                    0.866201  \n",
       "102674                    0.507863               1                    0.507863  \n",
       "103848                    0.927896               1                    0.927896  \n",
       "104393                    0.675990               1                    0.675990  \n",
       "105138                    0.708059               1                    0.708059  \n",
       "105197                    0.957487               1                    0.957487  \n",
       "106309                    0.594038               1                    0.594038  \n",
       "106897                    0.571512               1                    0.571512  \n",
       "107931                    0.590005               1                    0.590005  \n",
       "109740                    0.566817               1                    0.566817  \n",
       "\n",
       "[20 rows x 50 columns]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df[(test_df['target'] == 0) &(test_df['Prediction_log'] == 1) & (test_df['homosexual_gay_or_lesbian']==1)].iloc[40:60,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('tf-idf',\n",
       "                 TfidfVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.float64'>,\n",
       "                                 encoding='utf-8', input='content',\n",
       "                                 lowercase=False, max_df=1.0, max_features=None,\n",
       "                                 min_df=1, ngram_range=(1, 1), norm='l2',\n",
       "                                 preprocessor=None, smooth_idf=True,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 sublinear_tf=False,\n",
       "                                 token_pattern...\n",
       "                                 tokenizer=<bound method TweetTokenizer.tokenize of <nltk.tokenize.casual.TweetTokenizer object at 0x26c293668>>,\n",
       "                                 use_idf=True, vocabulary=None)),\n",
       "                ('model',\n",
       "                 LogisticRegression(C=1, class_weight=None, dual=False,\n",
       "                                    fit_intercept=True, intercept_scaling=1,\n",
       "                                    l1_ratio=None, max_iter=100,\n",
       "                                    multi_class='warn', n_jobs=None,\n",
       "                                    penalty='l1', random_state=None,\n",
       "                                    solver='warn', tol=0.0001, verbose=0,\n",
       "                                    warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predict_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['u',\n",
       " 'least',\n",
       " '',\n",
       " 'someone',\n",
       " 'halfblack',\n",
       " 'considered',\n",
       " 'black',\n",
       " '',\n",
       " 'grandchild',\n",
       " 'white',\n",
       " 'father',\n",
       " 'black',\n",
       " 'mother',\n",
       " '',\n",
       " 'seen',\n",
       " 'black',\n",
       " 'everyone',\n",
       " '']"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.loc[59102,'comment_text_clean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
