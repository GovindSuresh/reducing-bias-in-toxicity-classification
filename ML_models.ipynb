{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling - ML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal for our work is to not only train a model to identify toxic comments, but to do so while reducing bias.\n",
    "Bias in this task can be viewed as the situation where certain identies such as 'Black', 'Muslim', 'Gay' e.t.c, begin triggering toxic classification for comments they are in, even when the comment is actually positive. This is a key issue in toxic comment classification. \n",
    "\n",
    "The goal of the [jigsaw unintended Bias in Toxicity Classification](https://www.kaggle.com/c/jigsaw-unintended-bias-in-toxicity-classification/data) Kaggle challenge was to reduce this bias via a newly developed submetric which we have defined below.\n",
    "\n",
    "**Note: The goal of the model is simply to predict the toxicity score of a model.** \n",
    "\n",
    "The bias weighted ROC metric below is calulated by taking segmenting the the dataset into identity subgroups by using the provided identity labels and then calculating the subgroup metrics. \n",
    "\n",
    "### Metrics:\n",
    "\n",
    "In addition to accuracy we will observe the below metrics for our models\n",
    "\n",
    "#### Overall ROC-AUC:\n",
    "\n",
    "This is the standard ROC-AUC for the full evaluation set. In other words this is the area under the Reciever Operating Characteristic curve. It compares the true positive and false positive rates of a binary model.\n",
    "\n",
    "#### Subgroup ROC-AUC:\n",
    "\n",
    "Here, we restrict the data set to only the examples that mention the specific identity subgroup. A low value in this metric means the model does a poor job of distinguishing between toxic and non-toxic comments that mention the identity.\n",
    "\n",
    "#### BPSN AUC:\n",
    "\n",
    "BPSN (Background Positive, Subgroup Negative) AUC: Here, we restrict the test set to the non-toxic examples that mention the identity and the toxic examples that do not. A low value in this metric means that the model confuses non-toxic examples that mention the identity with toxic examples that do not, likely meaning that the model predicts higher toxicity scores than it should for non-toxic examples mentioning the identity.\n",
    "\n",
    "#### BNSP AUC:\n",
    "\n",
    "BNSP (Background Negative, Subgroup Positive) AUC: Here, we restrict the test set to the toxic examples that mention the identity and the non-toxic examples that do not. A low value here means that the model confuses toxic examples that mention the identity with non-toxic examples that do not, likely meaning that the model predicts lower toxicity scores than it should for toxic examples mentioning the identity.\n",
    "\n",
    "\n",
    "#### Generalized Mean of Bias AUCs\n",
    "To combine the per-identity Bias AUCs into one overall measure, we calculate their generalized mean as defined below:\n",
    "\n",
    "$M_p(m_s) = \\left(\\frac{1}{N} \\sum_{s=1}^{N} m_s^p\\right)^\\frac{1}{p}$\n",
    "\n",
    "Where:\n",
    "\n",
    "$M_p$ = the $p$th power-mean function\n",
    "\n",
    "$m_s$ = the bias metric $m$ calulated for subgroup $s$\n",
    "\n",
    "$N$ = number of identity subgroups\n",
    "\n",
    "For this competition, JigsawAI use a p value of -5 to encourage competitors to improve the model for the identity subgroups with the lowest model performance.\n",
    "\n",
    "### Final Metric\n",
    "We combine the overall AUC with the generalized mean of the Bias AUCs to calculate the final model score:\n",
    "\n",
    "$score = w_0 AUC_{overall} + \\sum_{a=1}^{A} w_a M_p(m_{s,a})$\n",
    "\n",
    "$A$ = number of submetrics (3)\n",
    "\n",
    "$m_{s,a}$ = bias metric for identity subgroup $s$ using submetric $a$\n",
    "\n",
    "$w_a$ = $a$ weighting for the relative importance of each submetric; all four $w$ values set to 0.25\n",
    "\n",
    "\n",
    "### Process:\n",
    "\n",
    "#### Classical ML models\n",
    "This is primarily an NLP task, our X feature matrix will be based off the text from online comments. We have defined a pre-processing pipeline in the 'preprocessing.ipynb' notebook to use for our our ML classifiers and a seperate pre-processing pipeline for the neural network models we are planning on training.\n",
    "\n",
    "From the classic ML classifer models, we intend to use the following models - our base word embedding technique will be TF-IDF: \n",
    "\n",
    "   * Logistic Regression\n",
    "   * SVM\n",
    "   * Random Forest\n",
    " \n",
    "   \n",
    "We will carry out hyperparameter optimization for each model and calculate the metrics for each.\n",
    "\n",
    "#### Neural Networks\n",
    "\n",
    "We will also train a neural network to answer this problem. We will start with a basic LSTM model which will be made of:\n",
    "    \n",
    "   * Two LSTM layers to read through the data\n",
    "   * Two Dense layers w/ 4 nodes\n",
    "   * Output layer using sigmoid for the classes\n",
    "   \n",
    "We will then seek to improve this LSTM by creating a Bidrectional LSTM (BiLSTM) which we believe will improve accuracy by reading input sequences in both directions. If time allows we will also attempt to include a simple attention mechanism.\n",
    "\n",
    "The NN models will use Glove 840B 300d word embeddings. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gov/anaconda3/envs/capstone/lib/python3.7/site-packages/tqdm/std.py:651: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  from pandas import Panel\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import string\n",
    "import contractions\n",
    "import tqdm\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "import gc\n",
    "import operator\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 1: Apply pre-processing to text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load train_data\n",
    "train_df = pd.read_csv('data/train_clean.csv')\n",
    "\n",
    "# Load in test data\n",
    "test_df = pd.read_csv('data/test_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.rename({'toxicity':'target'}, axis=1, inplace=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the unneeded columns\n",
    "train_df = train_df.iloc[:,1:]\n",
    "test_df = test_df.iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this cell we define the function that pre-processes our text\n",
    "\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
    "import contractions\n",
    "import string\n",
    "\n",
    "def text_cleaner(df, col_name, clean_col_name):\n",
    "    '''\n",
    "    Text pre-processing pipeline, we lemmatize words, expand contractions, remove common stop words, apply lower case,\n",
    "    tokenize, and delete punctuation. All functions use apply and list comprehension for speed benefit.\n",
    "   \n",
    "    INPUT:\n",
    "    df = name of dataframe\n",
    "    col_name = name of column to pre-process\n",
    "    clean_col_name = name of new cleaned_column\n",
    "   \n",
    "    OUTPUT:\n",
    "    None - changes are made directly to dataframe\n",
    "    \n",
    "    '''\n",
    "\n",
    "    # Lemmatize helper functions\n",
    "    # Lemmatize nouns\n",
    "    def lemmatize_text_noun(text):\n",
    "        return [lemmatizer.lemmatize(w, pos='n') for w in text]\n",
    "    \n",
    "    # Lemmatize verbs\n",
    "    def lemmatize_text_verb(text):\n",
    "        return [lemmatizer.lemmatize(w, pos='v') for w in text]\n",
    "    # Lemmatize adjectives\n",
    "    def lemmatize_text_adj(text):\n",
    "        return [lemmatizer.lemmatize(w, pos='a') for w in text]\n",
    "\n",
    "    # Lemmatize adverbs\n",
    "    def lemmatize_text_adv(text):\n",
    "        return [lemmatizer.lemmatize(w, pos='r') for w in text]\n",
    "    \n",
    "    # Expand contraction method\n",
    "    def contraction_expand(text):\n",
    "        return contractions.fix(text)\n",
    "    \n",
    "    # To lower case.\n",
    "    df[clean_col_name] = df[col_name].apply(lambda x: x.lower())\n",
    "    \n",
    "    # Expand contractions\n",
    "    df[clean_col_name] = df[clean_col_name].apply(lambda x: contraction_expand(x))\n",
    "    \n",
    "    #Tokenize:\n",
    "    tokenizer = TweetTokenizer(reduce_len=True)\n",
    "    df[clean_col_name] = df[clean_col_name].apply(lambda x: tokenizer.tokenize(x))\n",
    "   \n",
    "    \n",
    "    #Remove Stop words\n",
    "    stop_words = stopwords.words('english')\n",
    "    df[clean_col_name] = df[clean_col_name].apply(lambda x: [item for item in x if item not in stop_words])\n",
    "    \n",
    "    #Delete punctuation\n",
    "    punc_table = str.maketrans('', '', string.punctuation)\n",
    "    df[clean_col_name] = df[clean_col_name].apply(lambda x: [item.translate(punc_table) for item in x])\n",
    "    \n",
    "    # LEMMATIZATION\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    \n",
    "    df[clean_col_name] = df[clean_col_name].apply(lemmatize_text_noun)\n",
    "    df[clean_col_name] = df[clean_col_name].apply(lemmatize_text_verb)\n",
    "    df[clean_col_name] = df[clean_col_name].apply(lemmatize_text_adj)\n",
    "    df[clean_col_name] = df[clean_col_name].apply(lemmatize_text_adv)\n",
    "    \n",
    "    \n",
    "    return None\n",
    "\n",
    "\n",
    "def detokenizer(df, col_name):\n",
    "    detokenizer = TreebankWordDetokenizer()\n",
    "    df[col_name+'_detokenize'] = df[col_name].apply(lambda x: detokenizer.detokenize(x))\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 19min 18s, sys: 8.28 s, total: 19min 26s\n",
      "Wall time: 19min 30s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Run the cleaner func on train data\n",
    "text_cleaner(train_df, 'comment_text', 'comment_text_clean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "# Run the same cleaner on the training data\n",
    "text_cleaner(test_df, 'comment_text', 'comment_text_clean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 34s, sys: 803 ms, total: 3min 35s\n",
      "Wall time: 3min 37s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "detokenizer(train_df,'comment_text_clean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 23.9 s, sys: 194 ms, total: 24.1 s\n",
      "Wall time: 24.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# detokenize the test data\n",
    "detokenizer(test_df, 'comment_text_clean')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 2: Modelling\n",
    "\n",
    "The data has been pre-processed for our models. We can now begin model training.\n",
    "\n",
    "We have a seperate test dataset that will be kept aside for testing only once we have an ideal model. For hyperparameter optimizing we will use Scikit-learn's GridSearchCV. \n",
    "\n",
    "After we have fitted a model and predicted results, we can then append the predictions to the dataframe and calculate the subgroup AUCs and the final weighted metric . \n",
    "\n",
    "#### Defining subgroup AUC metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "SUBGROUP_AUC = 'subgroup_auc'\n",
    "BPSN_AUC = 'bpsn_auc'  # stands for background positive, subgroup negative\n",
    "BNSP_AUC = 'bnsp_auc'  # stands for background negative, subgroup positive\n",
    "\n",
    "\n",
    "# These calculations have been provided by Jigsaw AI for scoring based on the metrics of the kaggle competition\n",
    "# https://www.kaggle.com/c/jigsaw-unintended-bias-in-toxicity-classification/overview/evaluation\n",
    "\n",
    "# They work by filtering the relevant dataframe into specific subgroups and using the roc_auc_score metric from sklearn.\n",
    "\n",
    "def compute_auc(y_true, y_pred):\n",
    "    try:\n",
    "        return metrics.roc_auc_score(y_true, y_pred)\n",
    "    except ValueError:\n",
    "        return np.nan\n",
    "\n",
    "def compute_subgroup_auc(df, subgroup, label, model_name):\n",
    "    subgroup_examples = df[df[subgroup]]\n",
    "    return compute_auc(subgroup_examples[label], subgroup_examples[model_name])\n",
    "\n",
    "def compute_bpsn_auc(df, subgroup, label, model_name):\n",
    "    \"\"\"Computes the AUC of the within-subgroup negative examples and the background positive examples.\"\"\"\n",
    "    subgroup_negative_examples = df.loc[df[subgroup] & ~df[label]]\n",
    "    non_subgroup_positive_examples = df.loc[~df[subgroup] & df[label]]\n",
    "    examples = subgroup_negative_examples.append(non_subgroup_positive_examples)\n",
    "    return compute_auc(examples[label], examples[model_name])\n",
    "\n",
    "def compute_bnsp_auc(df, subgroup, label, model_name):\n",
    "    \"\"\"Computes the AUC of the within-subgroup positive examples and the background negative examples.\"\"\"\n",
    "    subgroup_positive_examples = df.loc[df[subgroup] & df[label]]\n",
    "    non_subgroup_negative_examples = df.loc[~df[subgroup] & ~df[label]]\n",
    "    examples = subgroup_positive_examples.append(non_subgroup_negative_examples)\n",
    "    return compute_auc(examples[label], examples[model_name])\n",
    "\n",
    "def compute_bias_metrics_for_model(dataset,\n",
    "                                   subgroups,\n",
    "                                   model,\n",
    "                                   label_col,\n",
    "                                   include_asegs=False):\n",
    "    \"\"\"Computes per-subgroup metrics for all subgroups and one model.\"\"\"\n",
    "    records = []\n",
    "    for subgroup in subgroups:\n",
    "        record = {\n",
    "            'subgroup': subgroup,\n",
    "            'subgroup_size': len(dataset.loc[dataset[subgroup]])\n",
    "        }\n",
    "        record[SUBGROUP_AUC] = compute_subgroup_auc(dataset, subgroup, label_col, model)\n",
    "        record[BPSN_AUC] = compute_bpsn_auc(dataset, subgroup, label_col, model)\n",
    "        record[BNSP_AUC] = compute_bnsp_auc(dataset, subgroup, label_col, model)\n",
    "        records.append(record)\n",
    "    return pd.DataFrame(records).sort_values('subgroup_auc', ascending=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These calculations have been provided by Jigsaw AI for scoring based on the metrics of the kaggle competition\n",
    "# https://www.kaggle.com/c/jigsaw-unintended-bias-in-toxicity-classification/overview/evaluation\n",
    "\n",
    "# They work by filtering the relevant dataframe into specific subgroups and using the roc_auc_score metric from sklearn.\n",
    "\n",
    "def calculate_overall_auc(df, model_name):\n",
    "    true_labels = df[TOXICITY_COLUMN]\n",
    "    predicted_labels = df[model_name]\n",
    "    return metrics.roc_auc_score(true_labels, predicted_labels)\n",
    "\n",
    "def power_mean(series, p):\n",
    "    total = sum(np.power(series, p))\n",
    "    return np.power(total / len(series), 1 / p)\n",
    "\n",
    "def get_final_metric(bias_df, overall_auc, POWER=-5, OVERALL_MODEL_WEIGHT=0.25):\n",
    "    bias_score = np.average([\n",
    "        power_mean(bias_df[SUBGROUP_AUC], POWER),\n",
    "        power_mean(bias_df[BPSN_AUC], POWER),\n",
    "        power_mean(bias_df[BNSP_AUC], POWER)\n",
    "    ])\n",
    "    return (OVERALL_MODEL_WEIGHT * overall_auc) + ((1 - OVERALL_MODEL_WEIGHT) * bias_score)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train shape: (1804874,)\n",
      "y_test shape: (194640,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression\n",
    "\n",
    "We will use Grid Search Cross validation to optimize our hyperparameters on the training set. We will then fit the best estimator and then predict on the test set and calculate relevent metrics.\n",
    "\n",
    "Because the subgroup ROCs are calculated post prediction and require predictions to be appended to a dataframe, we cannot actually pass the metrics into the scoring function of scikit-learn's gridsearchCV(). Instead we will just test the models on accuracy and total ROC-AUC and then refitting the grid-search on the model with the best ROC-AUC as a proxy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.65 ms, sys: 3.6 ms, total: 5.25 ms\n",
      "Wall time: 8.3 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVC\n",
    "#no scaling data is already transformed\n",
    "\n",
    "# Instantiate the tokenizer to use in the vectorizer\n",
    "tweet_tokenizer = TweetTokenizer(reduce_len=True)\n",
    "\n",
    "# Instantiate the vectorizer, we will pass in the TweetTokenizer() from nltk \n",
    "tfid_vec_2 = TfidfVectorizer(lowercase=False, tokenizer = tweet_tokenizer.tokenize)\n",
    "\n",
    "# define pipeline\n",
    "pipeline = Pipeline([#('tf-idf', tfid_vec_2), \n",
    "                     ('model', SVC())])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "# Define scoring functions\n",
    "scorers = {'AUC': 'roc_auc', 'Accuracy': make_scorer(accuracy_score)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define parameters\n",
    "param_grid_log = [{'model': [LogisticRegression()], 'tf-idf': [tfid_vec_2], \n",
    "                   'model__penalty': ['l1', 'l2'],\n",
    "                   'model__C': [.001, 0.01, 0.1, 1, 10, 100]}]\n",
    "\n",
    "# Setting refit='AUC', refits an estimator on the whole dataset with the\n",
    "# parameter setting that has the best cross-validated AUC score, i.e it finds the params that gives the best scores\n",
    "# then refits using the ones that give the best AUC. \n",
    "grid_log = GridSearchCV(pipeline, param_grid_log, cv=5, scoring=scorers, refit='AUC', \n",
    "                        return_train_score=True, n_jobs=-1)\n",
    "\n",
    "fittedgrid_log = grid_log.fit(train_df['comment_text_clean_detokenize'], train_df['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib\n",
    "# Save best estimator to file\n",
    "joblib.dump(fittedgrid.best_estimator_, 'saved_models/best_log_reg.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run this to load the model if required\n",
    "from sklearn.externals import joblib\n",
    "from joblib import load\n",
    "fittedgrid_log = load('saved_models/best_log_reg.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get scores\n",
    "train_accuracy = fittedgrid_log.score(train_df['comment_text_clean_detokenize'], y_train)\n",
    "test_accuracy = fittedgrid_log.score(test_df['comment_text_clean_detokenize'], y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict train and test values\n",
    "y_train_pred = fittedgrid_log.predict(train_df['comment_text_clean_detokenize'])\n",
    "y_test_pred = fittedgrid_log.predict(test_df['comment_text_clean_detokenize'])\n",
    "\n",
    "y_train_pred_prob = fittedgrid_log.predict_proba(train_df['comment_text_clean_detokenize'])\n",
    "y_test_pred_prob = fittedgrid_log.predict_proba(test_df['comment_text_clean_detokenize'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.97    179192\n",
      "           1       0.76      0.50      0.60     15448\n",
      "\n",
      "    accuracy                           0.95    194640\n",
      "   macro avg       0.86      0.74      0.79    194640\n",
      "weighted avg       0.94      0.95      0.94    194640\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Confusion Matrix and Classification Report, we want to store the F1 Score.\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# store the precision, recall, and f1 score for later and print the classification report\n",
    "log_precision = precision_score(y_test, y_test_pred)\n",
    "log_recall = recall_score(y_test, y_test_pred)\n",
    "log_f1 = f1_score(y_test, y_test_pred)\n",
    "\n",
    "print(classification_report(y_test, y_test_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append preds and probabilities to train and valid dfs\n",
    "train_df['Prediction_log'] = y_train_pred\n",
    "train_df['Prediction_probability_log'] = y_train_pred_prob[:, 1]\n",
    "test_df['Prediction_log'] = y_test_pred\n",
    "test_df['Prediction_probability_log'] = y_test_pred_prob[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identity columns used to calculate subgroup AUC\n",
    "identity_columns = [\n",
    "    'male', 'female', 'homosexual_gay_or_lesbian', 'christian', 'jewish',\n",
    "    'muslim', 'black', 'white', 'psychiatric_or_mental_illness']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in identity_columns + ['target']:\n",
    "    train_df[col] = np.where(train_df[col] >= 0.5, True, False)\n",
    "    test_df[col] = np.where(test_df[col] >= 0.5, True, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the AUC metrics \n",
    "\n",
    "SUBGROUP_AUC = 'subgroup_auc'\n",
    "BPSN_AUC = 'bpsn_auc'  # stands for background positive, subgroup negative\n",
    "BNSP_AUC = 'bnsp_auc'\n",
    "\n",
    "MODEL_NAME = 'Prediction_log'\n",
    "TOXICITY_COLUMN = 'target'\n",
    "\n",
    "log_bias_metrics_df_train = compute_bias_metrics_for_model(train_df, identity_columns, MODEL_NAME, TOXICITY_COLUMN)\n",
    "log_final_metric_train = get_final_metric(log_bias_metrics_df_train, calculate_overall_auc(train_df, MODEL_NAME))\n",
    "\n",
    "log_bias_metrics_df_test = compute_bias_metrics_for_model(test_df, identity_columns, MODEL_NAME, TOXICITY_COLUMN)\n",
    "log_final_metric_test = get_final_metric(log_bias_metrics_df_test, calculate_overall_auc(test_df, MODEL_NAME))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_bias_metrics_df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'train_accuracy:{train_accuracy}')\n",
    "print(f'train weighted subgroup AUC:{get_final_metric(bias_metrics_df_train, calculate_overall_auc(train_df, MODEL_NAME))}')\n",
    "print(f'test_accuracy:{test_accuracy}')\n",
    "print(f'test weighted subgroup AUC::{get_final_metric(bias_metrics_df_val, calculate_overall_auc(test_df, MODEL_NAME))}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Evaluation:\n",
    "\n",
    "The logistic regression performed well on pure accuracy, with a train accuracy of 95.38% and 94.96% test accuracy. What is also positive to see is that our hyperparameter optimization has led to a model which does not overfit excessively. \n",
    "\n",
    "However when we look at the weighted subgroup AUC metric, the 71.9% train score and 71.5% test score show that the model did have a tendency towards biased predictions for certain subgroup. In comparison, the benchmark CNN that was provided had a weighted AUC score of 88.35% albeit just on a validation set \n",
    "\n",
    "\n",
    "For example we can see that for the 'black' identity BPSN AUC was relatively low, suggesting the model is likely overweighting mentions of the 'black' identity with toxicity. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM\n",
    "\n",
    "We will now carry out a similar process with SVM to see if this performs appreciably different to logistic regression. \n",
    "\n",
    "#### Grid searching on a subset of data\n",
    "\n",
    "Given the length of time taken to grid search using SVM, we will run a gridsearch on a subset of our dataset by taking a new train test split. We will then use the results there as a proxy for the optimal parameters for our full dataset.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# Create a new split of the training dataframe to use for this reduced test. \n",
    "# we will not need the remainder. We will take 1/4 of the total data set\n",
    "remainder, reduced_df = train_test_split(train_df, test_size=0.25, stratify=train_df['target'], random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid search applies tfid_vec_2 to all models. We try combinations of model loss function penalty strength and\n",
    "# model gamma amma is a parameter for non linear hyperplanes. \n",
    "# The higher the gamma value it tries to exactly fit the training data set\n",
    "\n",
    "param_grid_svc = [{'model__kernel': ['rbf'],'tf-idf': [tfid_vec_2],\n",
    "              'model__C': [0.1, 1, 10,], 'model__gamma': [0.1, 1, 10, 'scale'] 'model__probability': [True]}]\n",
    "\n",
    "grid_svc = GridSearchCV(pipeline, param_grid_svc, scoring=scorers, cv=5, refit='AUC',\n",
    "                       return_train_score=True, n_jobs=-1, verbose=10)\n",
    "\n",
    "reduced_grid_svm = grid_svc.fit(train_df['comment_text_clean_detokenize'], train_df['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gives the model with the best AUC score\n",
    "reduced_grid_svm.best_estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gives the model with the best AUC score\n",
    "reduced_grid_svm.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Full dataset grid search\n",
    "\n",
    "param_grid_svc = [{'model__kernel': ['rbf'],'tf-idf': [tfid_vec_2],\n",
    "              'model__C': [0.1, 1, 10], 'model__probability': [True]}]\n",
    "\n",
    "grid_svc = GridSearchCV(pipeline, param_grid_svc, scoring=scorers, cv=5, refit='AUC',\n",
    "                       return_train_score=True, n_jobs=-1, verbose=10)\n",
    "\n",
    "fittedgrid_svc = grid_svc.fit(train_df['comment_text_clean_detokenize'], train_df['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save best estimator to file\n",
    "joblib.dump(fittedgrid_svc.best_estimator_, 'saved_models/best_svm.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get scores\n",
    "train_accuracy = fittedgrid_svc.score(train_df['comment_text_clean_detokenize'], y_train)\n",
    "test_accuracy = fittedgrid_svc.score(test_df['comment_text_clean_detokenize'], y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict train and test values\n",
    "y_train_pred = fittedgrid_svc.predict(train_df['comment_text_clean_detokenize'])\n",
    "y_test_pred = fittedgrid_svc.predict(test_df['comment_text_clean_detokenize'])\n",
    "\n",
    "y_train_pred_prob = fittedgrid_svc.predict_proba(train_df['comment_text_clean_detokenize'])\n",
    "y_test_pred_prob = fittedgrid_svc.predict_proba(test_df['comment_text_clean_detokenize'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store the precision, recall, and f1 score for later and print the classification report\n",
    "svm_precision = precision_score(y_test, y_test_pred)\n",
    "svm_recall = recall_score(y_test, y_test_pred)\n",
    "svm_f1 = f1_score(y_test, y_test_pred)\n",
    "\n",
    "display(classification_report(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append preds and probabilities to train and valid dfs\n",
    "\n",
    "\n",
    "train_df['Prediction_svc'] = y_train_pred\n",
    "train_df['Prediction_probability_svc'] = y_train_pred_prob[:, 1]\n",
    "test_df['Prediction_svc'] = y_test_pred\n",
    "test_df['Prediction_probability_svc'] = y_test_pred_prob[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the AUC metrics \n",
    "\n",
    "SUBGROUP_AUC = 'subgroup_auc'\n",
    "BPSN_AUC = 'bpsn_auc'  # stands for background positive, subgroup negative\n",
    "BNSP_AUC = 'bnsp_auc'\n",
    "\n",
    "MODEL_NAME = 'Prediction_svc'\n",
    "TOXICITY_COLUMN = 'target'\n",
    "\n",
    "svm_bias_metrics_df_train = compute_bias_metrics_for_model(train_df, identity_columns, MODEL_NAME, TOXICITY_COLUMN)\n",
    "svm_final_metric_train = get_final_metric(svm_bias_metrics_df_train, calculate_overall_auc(train_df, MODEL_NAME))\n",
    "\n",
    "svm_bias_metrics_df_test = compute_bias_metrics_for_model(test_df, identity_columns, MODEL_NAME, TOXICITY_COLUMN)\n",
    "svm_final_metric_test get_final_metric(svm_bias_metrics_df_test, calculate_overall_auc(test_df, MODEL_NAME))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest -- Put in code for single run rf model \n",
    "\n",
    "For our final model we will try the Random Forest Classifier which is an ensemble method. It is based on the Decision Tree model, only the Random Forest works by fitting on random sub samples of the data (with replacement), which is known as 'bagging'. A voting algorithm is then applied on the results of each of the trees to determine the final class of the data point. The aim of Random Forest is to train a series of overfit models and then average out the results via voting to get better results. The main hyperparemeter we will optimize for is the number of decision trees to use. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grid Search on a subset of data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the length of time taken to grid search on the Random Forest Classifier, we will run a gridsearch on a subset of our dataset by taking a new train test split. We will then use the results there as a proxy for the optimal parameters for our full dataset. We will use the same train_test split as used for the SVM subset search. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:  5.4min\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed: 13.1min\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed: 35.6min\n",
      "[Parallel(n_jobs=-1)]: Done  25 out of  36 | elapsed: 78.8min remaining: 34.7min\n",
      "[Parallel(n_jobs=-1)]: Done  29 out of  36 | elapsed: 113.6min remaining: 27.4min\n",
      "[Parallel(n_jobs=-1)]: Done  33 out of  36 | elapsed: 132.4min remaining: 12.0min\n",
      "[Parallel(n_jobs=-1)]: Done  36 out of  36 | elapsed: 165.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 50min 44s, sys: 12.9 s, total: 50min 57s\n",
      "Wall time: 3h 35min 49s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Note, most of the time here actually comes from the application of the tfid vectorizer to each fold of the data\n",
    "# Random forest itself takes ~5minutes to run on the vectorized data.\n",
    "\n",
    "# We control the model max depth \n",
    "param_grid_RF = {'model': [RandomForestClassifier()], 'tf-idf': [tfid_vec_2], \n",
    "                 'model__n_estimators': [10,50,100],\n",
    "                 'model__max_depth': [100, 500, 1000, 5000],\n",
    "             }\n",
    "reduced_grid_RF = GridSearchCV(pipeline, param_grid_RF, scoring=scorers, cv=3, refit='AUC',\n",
    "                       return_train_score=True, n_jobs=-1, verbose = 10)\n",
    "\n",
    "reduced_grid_RF = reduced_grid_RF.fit(reduced_df['comment_text_clean_detokenize'], reduced_df['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('tf-idf',\n",
       "                 TfidfVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.float64'>,\n",
       "                                 encoding='utf-8', input='content',\n",
       "                                 lowercase=False, max_df=1.0, max_features=None,\n",
       "                                 min_df=1, ngram_range=(1, 1), norm='l2',\n",
       "                                 preprocessor=None, smooth_idf=True,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 sublinear_tf=False,\n",
       "                                 token_pattern...\n",
       "                 RandomForestClassifier(bootstrap=True, class_weight=None,\n",
       "                                        criterion='gini', max_depth=1000,\n",
       "                                        max_features='auto',\n",
       "                                        max_leaf_nodes=None,\n",
       "                                        min_impurity_decrease=0.0,\n",
       "                                        min_impurity_split=None,\n",
       "                                        min_samples_leaf=1, min_samples_split=2,\n",
       "                                        min_weight_fraction_leaf=0.0,\n",
       "                                        n_estimators=100, n_jobs=None,\n",
       "                                        oob_score=False, random_state=None,\n",
       "                                        verbose=0, warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the best estimator parameters\n",
    "reduced_grid_RF.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9230210872062684"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# gives the best AUC score\n",
    "reduced_grid_RF.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reduced_grid_RF.cv_results_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above test has suggested that in terms of hyperparameters, we should look at a model that has n_estimators around 100 or above, and max_depth of around 1000. We will use this as a guide for our grid search. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grid Search in the full dataset\n",
    "Now that we have a good idea of optimal parameters, we will run another grid search on a few parameters around the optimal figures provided by our test on the subset of data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running a grid-search on the full set of data \n",
    "param_grid_RF = {'model': [RandomForestClassifier()], 'tf-idf': [tfid_vec_2], \n",
    "                 'model__n_estimators': [100,150,200],\n",
    "                 'model__max_depth': [1000, 2000, 3000, 4000],\n",
    "             }\n",
    "grid_RF = GridSearchCV(pipeline, param_grid_RF, scoring=scorers, cv=3, refit='AUC',\n",
    "                       return_train_score=True, n_jobs=-1, verbose = 10)\n",
    "\n",
    "fittedgrid_RF = grid_RF.fit(train_df['comment_text_clean_detokenize'], train_df['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict train and test values\n",
    "y_train_pred = fittedgrid_rf.predict(train_df['comment_text_clean_detokenize'])\n",
    "y_test_pred = fittedgrid_rf.predict(test_df['comment_text_clean_detokenize'])\n",
    "\n",
    "y_train_pred_prob = fittedgrid_rf.predict_proba(train_df['comment_text_clean_detokenize'])\n",
    "y_test_pred_prob = fittedgrid_rf.predict_proba(test_df['comment_text_clean_detokenize'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store the precision, recall, and f1 score for later and print the classification report\n",
    "rf_precision = precision_score(y_test, y_test_pred)\n",
    "rf_recall = recall_score(y_test, y_test_pred)\n",
    "rf_f1 = f1_score(y_test, y_test_pred)\n",
    "\n",
    "display(classification_report(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identity columns used to calculate subgroup AUC\n",
    "identity_columns = [\n",
    "    'male', 'female', 'homosexual_gay_or_lesbian', 'christian', 'jewish',\n",
    "    'muslim', 'black', 'white', 'psychiatric_or_mental_illness']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in identity_columns + ['target']:\n",
    "    train_df[col] = np.where(train_df[col] >= 0.5, True, False)\n",
    "    test_df[col] = np.where(test_df[col] >= 0.5, True, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append preds and probabilities to train and valid dfs\n",
    "train_df['Prediction_RF'] = y_train_pred\n",
    "train_df['Prediction_probability_RF'] = y_train_pred_prob[:, 1]\n",
    "test_df['Prediction_RF'] = y_test_pred\n",
    "test_df['Prediction_probability_RF'] = y_test_pred_prob[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the AUC metrics \n",
    "\n",
    "SUBGROUP_AUC = 'subgroup_auc'\n",
    "BPSN_AUC = 'bpsn_auc'  # stands for background positive, subgroup negative\n",
    "BNSP_AUC = 'bnsp_auc'\n",
    "\n",
    "MODEL_NAME = 'Prediction_RF'\n",
    "TOXICITY_COLUMN = 'target'\n",
    "\n",
    "rf_bias_metrics_df_train = compute_bias_metrics_for_model(train_df, identity_columns, MODEL_NAME, TOXICITY_COLUMN)\n",
    "rf_final_metric_train = get_final_metric(rf_bias_metrics_df_train, calculate_overall_auc(train_df, MODEL_NAME))\n",
    "\n",
    "rf_bias_metrics_df_test = compute_bias_metrics_for_model(test_df, identity_columns, MODEL_NAME, TOXICITY_COLUMN)\n",
    "rf_final_metric_test = get_final_metric(rf_bias_metrics_df_test, calculate_overall_auc(test_df, MODEL_NAME))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_bias_metrics_df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_final_metric_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'train_accuracy:{train_accuracy}')\n",
    "print(f'train weighted AUC:{rf_final_metric_train}')\n",
    "print(f'test_accuracy:{test_accuracy}')\n",
    "print(f'test weighted AUC::{rf_final_metric_test}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "We can see that the best estimator was selected with no bound on the max tree depth. THis has caused the model to significantly overfit on "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model performance\n",
    "\n",
    "Now that we have trained three seperate models which have been shown to deliver strong performance in text classification tasks in the past let us take the time to compare them side-by-side and also discuss their short-comings in terms of reducing bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Display the subgroup bias metrics tables for each model and then the final metrics for each model for test only\n",
    "display(log_bias_metrics_df_test)\n",
    "display(svm_bias_metrics_df_test)\n",
    "display(rf_bias_metrics_df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display final metrics for each model for test only.\n",
    "print(f' Final metric for Logistic Regression: {log_final_metric_test}')\n",
    "print(f' Final metric for SVM: {svm_final_metric_test}')\n",
    "print(f' Final metric for Random Forest: {rf_final_metric_test}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lime implementation for logreg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import eli5\n",
    "from eli5.lime import TextExplainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in log model\n",
    "joblib.dump(fittedgrid.best_estimator_, 'saved_models/best_log_reg.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "    table.eli5-weights tr:hover {\n",
       "        filter: brightness(85%);\n",
       "    }\n",
       "</style>\n",
       "\n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "        \n",
       "\n",
       "    \n",
       "\n",
       "        \n",
       "\n",
       "        \n",
       "    \n",
       "        \n",
       "        \n",
       "    \n",
       "        <p style=\"margin-bottom: 0.5em; margin-top: 0em\">\n",
       "            <b>\n",
       "    \n",
       "        y=1\n",
       "    \n",
       "</b>\n",
       "\n",
       "    \n",
       "    (probability <b>0.736</b>, score <b>1.024</b>)\n",
       "\n",
       "top features\n",
       "        </p>\n",
       "    \n",
       "    <table class=\"eli5-weights\"\n",
       "           style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto; margin-bottom: 2em;\">\n",
       "        <thead>\n",
       "        <tr style=\"border: none;\">\n",
       "            \n",
       "                <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\" title=\"Feature contribution already accounts for the feature value (for linear models, contribution = weight * feature value), and the sum of feature contributions is equal to the score or, for some classifiers, to the probability. Feature values are shown if &quot;show_feature_values&quot; is True.\">\n",
       "                    Contribution<sup>?</sup>\n",
       "                </th>\n",
       "            \n",
       "            <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
       "            \n",
       "        </tr>\n",
       "        </thead>\n",
       "        <tbody>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 80.00%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +1.845\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        Highlighted in text (sum)\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "        \n",
       "\n",
       "        \n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 88.65%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.821\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        &lt;BIAS&gt;\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "\n",
       "        </tbody>\n",
       "    </table>\n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "\n",
       "    <p style=\"margin-bottom: 2.5em; margin-top:-0.5em;\">\n",
       "        <span style=\"background-color: hsl(120, 100.00%, 99.63%); opacity: 0.80\" title=\"0.004\">in</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 94.16%); opacity: 0.81\" title=\"-0.188\">the</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 98.77%); opacity: 0.80\" title=\"-0.020\">us</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 95.35%); opacity: 0.81\" title=\"-0.136\">at</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 99.45%); opacity: 0.80\" title=\"0.006\">least</span><span style=\"opacity: 0.80\">, </span><span style=\"background-color: hsl(120, 100.00%, 98.69%); opacity: 0.80\" title=\"0.022\">someone</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 93.21%); opacity: 0.82\" title=\"-0.233\">who</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 97.66%); opacity: 0.80\" title=\"-0.051\">is</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 85.42%); opacity: 0.85\" title=\"-0.695\">half</span><span style=\"opacity: 0.80\">-</span><span style=\"background-color: hsl(120, 100.00%, 94.32%); opacity: 0.81\" title=\"0.181\">black</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 99.08%); opacity: 0.80\" title=\"-0.013\">is</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 99.60%); opacity: 0.80\" title=\"0.004\">considered</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 95.00%); opacity: 0.81\" title=\"-0.151\">to</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 98.05%); opacity: 0.80\" title=\"0.039\">be</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 84.28%); opacity: 0.85\" title=\"0.774\">black</span><span style=\"opacity: 0.80\">. </span><span style=\"background-color: hsl(0, 100.00%, 97.84%); opacity: 0.80\" title=\"-0.045\">my</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 98.44%); opacity: 0.80\" title=\"0.029\">grandchildren</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 97.95%); opacity: 0.80\" title=\"-0.042\">have</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 94.44%); opacity: 0.81\" title=\"-0.176\">a</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 84.64%); opacity: 0.85\" title=\"0.749\">white</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 98.24%); opacity: 0.80\" title=\"-0.034\">father</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 90.39%); opacity: 0.83\" title=\"-0.383\">and</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 93.76%); opacity: 0.81\" title=\"-0.207\">a</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 83.95%); opacity: 0.85\" title=\"0.797\">black</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 98.57%); opacity: 0.80\" title=\"0.025\">mother</span><span style=\"opacity: 0.80\">, </span><span style=\"background-color: hsl(0, 100.00%, 91.90%); opacity: 0.82\" title=\"-0.300\">and</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 95.37%); opacity: 0.81\" title=\"0.135\">are</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 98.31%); opacity: 0.80\" title=\"0.032\">seen</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 60.00%); opacity: 1.00\" title=\"2.940\">as</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 85.14%); opacity: 0.85\" title=\"0.714\">black</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 93.42%); opacity: 0.82\" title=\"-0.223\">by</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 92.65%); opacity: 0.82\" title=\"-0.261\">just</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 93.40%); opacity: 0.82\" title=\"-0.224\">about</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 98.29%); opacity: 0.80\" title=\"0.032\">everyone</span><span style=\"opacity: 0.80\">.</span>\n",
       "    </p>\n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_model_log = TextExplainer(random_state=1)\n",
    "\n",
    "text = test_df.loc[59102,'comment_text']\n",
    "\n",
    "text_model_log.fit(text, fittedgrid_log.predict_proba)\n",
    "text_model_log.show_prediction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         jeff session another one trump orwellian choic...\n",
       "1         actually inspected infrastructure grand chief ...\n",
       "2         wishful thinking democrat fault  100 th time  ...\n",
       "3         instead wringing hand nibbling periphery issue...\n",
       "4         many commenters garbage piled high yard  bald ...\n",
       "                                ...                        \n",
       "194635    lose job promoting misinformation harmful student\n",
       "194636    thinning project meant lower fire danger impro...\n",
       "194637            hope millennials happy put airhead charge\n",
       "194638    I thinking kellyanne conway   k   trump whispe...\n",
       "194639    still figure pizza ak cost pizza washington  i...\n",
       "Name: comment_text_clean_detokenize, Length: 194640, dtype: object"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df['comment_text_clean_detokenize']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>created_date</th>\n",
       "      <th>publication_id</th>\n",
       "      <th>article_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>funny</th>\n",
       "      <th>wow</th>\n",
       "      <th>sad</th>\n",
       "      <th>likes</th>\n",
       "      <th>...</th>\n",
       "      <th>physical_disability</th>\n",
       "      <th>intellectual_or_learning_disability</th>\n",
       "      <th>psychiatric_or_mental_illness</th>\n",
       "      <th>other_disability</th>\n",
       "      <th>comment_text_clean</th>\n",
       "      <th>comment_text_clean_detokenize</th>\n",
       "      <th>Prediction_svc</th>\n",
       "      <th>Prediction_probability_svc</th>\n",
       "      <th>Prediction_log</th>\n",
       "      <th>Prediction_probability_log</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>59102</th>\n",
       "      <td>7059102</td>\n",
       "      <td>In the US at least, someone who is half-black ...</td>\n",
       "      <td>2016-10-15 07:49:23.171142+00</td>\n",
       "      <td>53</td>\n",
       "      <td>148503</td>\n",
       "      <td>approved</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[u, least, , someone, halfblack, considered, b...</td>\n",
       "      <td>u least  someone halfblack considered black  g...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.736040</td>\n",
       "      <td>1</td>\n",
       "      <td>0.736040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62101</th>\n",
       "      <td>7062101</td>\n",
       "      <td>I would say the photo is not fake. It is a rea...</td>\n",
       "      <td>2016-06-04 23:07:41.077770+00</td>\n",
       "      <td>21</td>\n",
       "      <td>138054</td>\n",
       "      <td>approved</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[would, say, photo, fake, , real, photo, , eve...</td>\n",
       "      <td>would say photo fake  real photo  even say tak...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.580310</td>\n",
       "      <td>1</td>\n",
       "      <td>0.580310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63982</th>\n",
       "      <td>7063982</td>\n",
       "      <td>The reason no KKK member or neo- Nazi wouldn't...</td>\n",
       "      <td>2017-08-17 19:00:58.413842+00</td>\n",
       "      <td>102</td>\n",
       "      <td>367562</td>\n",
       "      <td>approved</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[reason, kkk, member, neo, , nazi, would, vote...</td>\n",
       "      <td>reason kkk member neo  nazi would voted barack...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.842451</td>\n",
       "      <td>1</td>\n",
       "      <td>0.842451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67553</th>\n",
       "      <td>7067553</td>\n",
       "      <td>You may have lost to Trump; but you sure have ...</td>\n",
       "      <td>2017-01-23 15:47:27.135615+00</td>\n",
       "      <td>54</td>\n",
       "      <td>163496</td>\n",
       "      <td>approved</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[may, lost, trump, , sure, clue, happened, , h...</td>\n",
       "      <td>may lost trump  sure clue happened  here tip r...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.629164</td>\n",
       "      <td>1</td>\n",
       "      <td>0.629164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67887</th>\n",
       "      <td>7067887</td>\n",
       "      <td>I posted this info, but people have more fun p...</td>\n",
       "      <td>2017-08-30 20:16:15.845371+00</td>\n",
       "      <td>102</td>\n",
       "      <td>372110</td>\n",
       "      <td>approved</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[posted, info, , people, fun, pointing, finger...</td>\n",
       "      <td>posted info  people fun pointing finger rather...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.747986</td>\n",
       "      <td>1</td>\n",
       "      <td>0.747986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68316</th>\n",
       "      <td>7068316</td>\n",
       "      <td>The FBI statistics you're referring to point o...</td>\n",
       "      <td>2017-08-30 04:37:03.116935+00</td>\n",
       "      <td>102</td>\n",
       "      <td>372110</td>\n",
       "      <td>approved</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[fbi, statistic, referring, point, white, blac...</td>\n",
       "      <td>fbi statistic referring point white black most...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.539965</td>\n",
       "      <td>1</td>\n",
       "      <td>0.539965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71154</th>\n",
       "      <td>7071154</td>\n",
       "      <td>Typical response of the entitled white male wi...</td>\n",
       "      <td>2016-07-10 00:23:04.787112+00</td>\n",
       "      <td>21</td>\n",
       "      <td>141018</td>\n",
       "      <td>approved</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[typical, response, entitled, white, male, und...</td>\n",
       "      <td>typical response entitled white male underlyin...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.756865</td>\n",
       "      <td>1</td>\n",
       "      <td>0.756865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71313</th>\n",
       "      <td>7071313</td>\n",
       "      <td>The Electoral College was designed to support ...</td>\n",
       "      <td>2017-08-13 01:33:33.428425+00</td>\n",
       "      <td>13</td>\n",
       "      <td>365725</td>\n",
       "      <td>approved</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[electoral, college, designed, support, race, ...</td>\n",
       "      <td>electoral college designed support race based ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.542400</td>\n",
       "      <td>1</td>\n",
       "      <td>0.542400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77472</th>\n",
       "      <td>7077472</td>\n",
       "      <td>Obama is to blame for all the hate shown towar...</td>\n",
       "      <td>2016-07-12 23:22:56.167130+00</td>\n",
       "      <td>21</td>\n",
       "      <td>141234</td>\n",
       "      <td>approved</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[obama, blame, hate, shown, towards, police, ,...</td>\n",
       "      <td>obama blame hate shown towards police  furguso...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.904188</td>\n",
       "      <td>1</td>\n",
       "      <td>0.904188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79693</th>\n",
       "      <td>7079693</td>\n",
       "      <td>1/3 black.</td>\n",
       "      <td>2017-10-12 17:35:16.953682+00</td>\n",
       "      <td>54</td>\n",
       "      <td>388225</td>\n",
       "      <td>rejected</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[13, black, ]</td>\n",
       "      <td>13 black</td>\n",
       "      <td>1</td>\n",
       "      <td>0.541024</td>\n",
       "      <td>1</td>\n",
       "      <td>0.541024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79875</th>\n",
       "      <td>7079875</td>\n",
       "      <td>Black Lives Matter has nothing to do with gay ...</td>\n",
       "      <td>2017-06-26 02:08:20.508244+00</td>\n",
       "      <td>54</td>\n",
       "      <td>348505</td>\n",
       "      <td>approved</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>53</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[black, life, matter, nothing, gay, pride, , g...</td>\n",
       "      <td>black life matter nothing gay pride  get venue</td>\n",
       "      <td>1</td>\n",
       "      <td>0.717545</td>\n",
       "      <td>1</td>\n",
       "      <td>0.717545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80009</th>\n",
       "      <td>7080009</td>\n",
       "      <td>sky\\r\\n\\r\\nI hardly see Harper as a defender o...</td>\n",
       "      <td>2017-01-23 17:20:02.094911+00</td>\n",
       "      <td>54</td>\n",
       "      <td>163496</td>\n",
       "      <td>approved</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[sky, hardly, see, harper, defender, feminism,...</td>\n",
       "      <td>sky hardly see harper defender feminism  think...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.839582</td>\n",
       "      <td>1</td>\n",
       "      <td>0.839582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80794</th>\n",
       "      <td>7080794</td>\n",
       "      <td>Seems our first black president has a black son.</td>\n",
       "      <td>2016-10-03 14:53:42.477969+00</td>\n",
       "      <td>13</td>\n",
       "      <td>147028</td>\n",
       "      <td>rejected</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[seems, first, black, president, black, son, ]</td>\n",
       "      <td>seems first black president black son</td>\n",
       "      <td>1</td>\n",
       "      <td>0.823816</td>\n",
       "      <td>1</td>\n",
       "      <td>0.823816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83971</th>\n",
       "      <td>7083971</td>\n",
       "      <td>Blaming all liberals for this terrible crime i...</td>\n",
       "      <td>2017-06-14 18:23:55.851171+00</td>\n",
       "      <td>13</td>\n",
       "      <td>344256</td>\n",
       "      <td>approved</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[blaming, liberal, terrible, crime, despicable...</td>\n",
       "      <td>blaming liberal terrible crime despicable  bla...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.589580</td>\n",
       "      <td>1</td>\n",
       "      <td>0.589580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85791</th>\n",
       "      <td>7085791</td>\n",
       "      <td>Another Person of color murdered by the SPD. \\...</td>\n",
       "      <td>2017-06-19 16:32:07.028231+00</td>\n",
       "      <td>84</td>\n",
       "      <td>346070</td>\n",
       "      <td>approved</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[another, person, color, murdered, spd, , anot...</td>\n",
       "      <td>another person color murdered spd  another men...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.639338</td>\n",
       "      <td>1</td>\n",
       "      <td>0.639338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86549</th>\n",
       "      <td>7086549</td>\n",
       "      <td>Now you're not making sense, what's golf got t...</td>\n",
       "      <td>2017-09-08 17:06:59.026680+00</td>\n",
       "      <td>102</td>\n",
       "      <td>375328</td>\n",
       "      <td>approved</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[making, sense, , golf, got, , talked, murder,...</td>\n",
       "      <td>making sense  golf got  talked murder gay syri...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.661940</td>\n",
       "      <td>1</td>\n",
       "      <td>0.661940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87205</th>\n",
       "      <td>7087205</td>\n",
       "      <td>Maybe Black men should quit killing black men,...</td>\n",
       "      <td>2016-07-09 21:42:52.186187+00</td>\n",
       "      <td>21</td>\n",
       "      <td>141018</td>\n",
       "      <td>approved</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[maybe, black, men, quit, killing, black, men,...</td>\n",
       "      <td>maybe black men quit killing black men  would ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.606414</td>\n",
       "      <td>1</td>\n",
       "      <td>0.606414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87444</th>\n",
       "      <td>7087444</td>\n",
       "      <td>I'm a liberal and I don't deny any of that. I ...</td>\n",
       "      <td>2017-08-17 16:20:35.412605+00</td>\n",
       "      <td>102</td>\n",
       "      <td>367562</td>\n",
       "      <td>approved</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[I, liberal, deny, , despise, nathan, bedford,...</td>\n",
       "      <td>I liberal deny  despise nathan bedford forrest...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.518933</td>\n",
       "      <td>1</td>\n",
       "      <td>0.518933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89341</th>\n",
       "      <td>7089341</td>\n",
       "      <td>They are extremists to the left as well, which...</td>\n",
       "      <td>2017-08-04 16:08:36.437010+00</td>\n",
       "      <td>22</td>\n",
       "      <td>362461</td>\n",
       "      <td>approved</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[extremist, left, well, , president, obama, au...</td>\n",
       "      <td>extremist left well  president obama authorize...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.533863</td>\n",
       "      <td>1</td>\n",
       "      <td>0.533863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91725</th>\n",
       "      <td>7091725</td>\n",
       "      <td>I disagree. I think it's obvious that the main...</td>\n",
       "      <td>2017-09-01 00:41:58.731419+00</td>\n",
       "      <td>13</td>\n",
       "      <td>372635</td>\n",
       "      <td>approved</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[disagree, , think, obvious, main, point, marc...</td>\n",
       "      <td>disagree  think obvious main point march charl...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.860424</td>\n",
       "      <td>1</td>\n",
       "      <td>0.860424</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20 rows  50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id                                       comment_text  \\\n",
       "59102  7059102  In the US at least, someone who is half-black ...   \n",
       "62101  7062101  I would say the photo is not fake. It is a rea...   \n",
       "63982  7063982  The reason no KKK member or neo- Nazi wouldn't...   \n",
       "67553  7067553  You may have lost to Trump; but you sure have ...   \n",
       "67887  7067887  I posted this info, but people have more fun p...   \n",
       "68316  7068316  The FBI statistics you're referring to point o...   \n",
       "71154  7071154  Typical response of the entitled white male wi...   \n",
       "71313  7071313  The Electoral College was designed to support ...   \n",
       "77472  7077472  Obama is to blame for all the hate shown towar...   \n",
       "79693  7079693                                         1/3 black.   \n",
       "79875  7079875  Black Lives Matter has nothing to do with gay ...   \n",
       "80009  7080009  sky\\r\\n\\r\\nI hardly see Harper as a defender o...   \n",
       "80794  7080794   Seems our first black president has a black son.   \n",
       "83971  7083971  Blaming all liberals for this terrible crime i...   \n",
       "85791  7085791  Another Person of color murdered by the SPD. \\...   \n",
       "86549  7086549  Now you're not making sense, what's golf got t...   \n",
       "87205  7087205  Maybe Black men should quit killing black men,...   \n",
       "87444  7087444  I'm a liberal and I don't deny any of that. I ...   \n",
       "89341  7089341  They are extremists to the left as well, which...   \n",
       "91725  7091725  I disagree. I think it's obvious that the main...   \n",
       "\n",
       "                        created_date  publication_id  article_id    rating  \\\n",
       "59102  2016-10-15 07:49:23.171142+00              53      148503  approved   \n",
       "62101  2016-06-04 23:07:41.077770+00              21      138054  approved   \n",
       "63982  2017-08-17 19:00:58.413842+00             102      367562  approved   \n",
       "67553  2017-01-23 15:47:27.135615+00              54      163496  approved   \n",
       "67887  2017-08-30 20:16:15.845371+00             102      372110  approved   \n",
       "68316  2017-08-30 04:37:03.116935+00             102      372110  approved   \n",
       "71154  2016-07-10 00:23:04.787112+00              21      141018  approved   \n",
       "71313  2017-08-13 01:33:33.428425+00              13      365725  approved   \n",
       "77472  2016-07-12 23:22:56.167130+00              21      141234  approved   \n",
       "79693  2017-10-12 17:35:16.953682+00              54      388225  rejected   \n",
       "79875  2017-06-26 02:08:20.508244+00              54      348505  approved   \n",
       "80009  2017-01-23 17:20:02.094911+00              54      163496  approved   \n",
       "80794  2016-10-03 14:53:42.477969+00              13      147028  rejected   \n",
       "83971  2017-06-14 18:23:55.851171+00              13      344256  approved   \n",
       "85791  2017-06-19 16:32:07.028231+00              84      346070  approved   \n",
       "86549  2017-09-08 17:06:59.026680+00             102      375328  approved   \n",
       "87205  2016-07-09 21:42:52.186187+00              21      141018  approved   \n",
       "87444  2017-08-17 16:20:35.412605+00             102      367562  approved   \n",
       "89341  2017-08-04 16:08:36.437010+00              22      362461  approved   \n",
       "91725  2017-09-01 00:41:58.731419+00              13      372635  approved   \n",
       "\n",
       "       funny  wow  sad  likes  ...  physical_disability  \\\n",
       "59102      0    0    0      7  ...                    0   \n",
       "62101      0    0    0      1  ...                    0   \n",
       "63982      0    0    1      0  ...                    0   \n",
       "67553      0    0    0      7  ...                    0   \n",
       "67887      0    0    0      1  ...                    0   \n",
       "68316      0    0    0      3  ...                    0   \n",
       "71154      0    0    0      0  ...                    0   \n",
       "71313      0    0    0      3  ...                    0   \n",
       "77472      0    0    0      2  ...                    0   \n",
       "79693      0    0    0      0  ...                    0   \n",
       "79875      2    0    0     53  ...                    0   \n",
       "80009      0    0    0      0  ...                    0   \n",
       "80794      0    0    0      0  ...                    0   \n",
       "83971      0    0    0      7  ...                    0   \n",
       "85791      0    0    0      1  ...                    0   \n",
       "86549      0    0    0      0  ...                    0   \n",
       "87205      0    0    0      3  ...                    0   \n",
       "87444      0    1    0     13  ...                    0   \n",
       "89341      0    0    0      1  ...                    0   \n",
       "91725      1    0    0      1  ...                    0   \n",
       "\n",
       "       intellectual_or_learning_disability  psychiatric_or_mental_illness  \\\n",
       "59102                                    0                              0   \n",
       "62101                                    0                              0   \n",
       "63982                                    0                              0   \n",
       "67553                                    0                              0   \n",
       "67887                                    0                              0   \n",
       "68316                                    0                              0   \n",
       "71154                                    0                              0   \n",
       "71313                                    0                              0   \n",
       "77472                                    0                              0   \n",
       "79693                                    0                              0   \n",
       "79875                                    0                              0   \n",
       "80009                                    0                              0   \n",
       "80794                                    0                              0   \n",
       "83971                                    0                              0   \n",
       "85791                                    0                              1   \n",
       "86549                                    0                              0   \n",
       "87205                                    0                              0   \n",
       "87444                                    0                              0   \n",
       "89341                                    0                              0   \n",
       "91725                                    0                              0   \n",
       "\n",
       "       other_disability                                 comment_text_clean  \\\n",
       "59102                 0  [u, least, , someone, halfblack, considered, b...   \n",
       "62101                 0  [would, say, photo, fake, , real, photo, , eve...   \n",
       "63982                 0  [reason, kkk, member, neo, , nazi, would, vote...   \n",
       "67553                 0  [may, lost, trump, , sure, clue, happened, , h...   \n",
       "67887                 0  [posted, info, , people, fun, pointing, finger...   \n",
       "68316                 0  [fbi, statistic, referring, point, white, blac...   \n",
       "71154                 0  [typical, response, entitled, white, male, und...   \n",
       "71313                 0  [electoral, college, designed, support, race, ...   \n",
       "77472                 0  [obama, blame, hate, shown, towards, police, ,...   \n",
       "79693                 0                                      [13, black, ]   \n",
       "79875                 0  [black, life, matter, nothing, gay, pride, , g...   \n",
       "80009                 0  [sky, hardly, see, harper, defender, feminism,...   \n",
       "80794                 0     [seems, first, black, president, black, son, ]   \n",
       "83971                 0  [blaming, liberal, terrible, crime, despicable...   \n",
       "85791                 0  [another, person, color, murdered, spd, , anot...   \n",
       "86549                 0  [making, sense, , golf, got, , talked, murder,...   \n",
       "87205                 0  [maybe, black, men, quit, killing, black, men,...   \n",
       "87444                 0  [I, liberal, deny, , despise, nathan, bedford,...   \n",
       "89341                 0  [extremist, left, well, , president, obama, au...   \n",
       "91725                 0  [disagree, , think, obvious, main, point, marc...   \n",
       "\n",
       "                           comment_text_clean_detokenize  Prediction_svc  \\\n",
       "59102  u least  someone halfblack considered black  g...               1   \n",
       "62101  would say photo fake  real photo  even say tak...               1   \n",
       "63982  reason kkk member neo  nazi would voted barack...               1   \n",
       "67553  may lost trump  sure clue happened  here tip r...               1   \n",
       "67887  posted info  people fun pointing finger rather...               1   \n",
       "68316  fbi statistic referring point white black most...               1   \n",
       "71154  typical response entitled white male underlyin...               1   \n",
       "71313  electoral college designed support race based ...               1   \n",
       "77472  obama blame hate shown towards police  furguso...               1   \n",
       "79693                                           13 black               1   \n",
       "79875     black life matter nothing gay pride  get venue               1   \n",
       "80009  sky hardly see harper defender feminism  think...               1   \n",
       "80794              seems first black president black son               1   \n",
       "83971  blaming liberal terrible crime despicable  bla...               1   \n",
       "85791  another person color murdered spd  another men...               1   \n",
       "86549  making sense  golf got  talked murder gay syri...               1   \n",
       "87205  maybe black men quit killing black men  would ...               1   \n",
       "87444  I liberal deny  despise nathan bedford forrest...               1   \n",
       "89341  extremist left well  president obama authorize...               1   \n",
       "91725  disagree  think obvious main point march charl...               1   \n",
       "\n",
       "       Prediction_probability_svc  Prediction_log  Prediction_probability_log  \n",
       "59102                    0.736040               1                    0.736040  \n",
       "62101                    0.580310               1                    0.580310  \n",
       "63982                    0.842451               1                    0.842451  \n",
       "67553                    0.629164               1                    0.629164  \n",
       "67887                    0.747986               1                    0.747986  \n",
       "68316                    0.539965               1                    0.539965  \n",
       "71154                    0.756865               1                    0.756865  \n",
       "71313                    0.542400               1                    0.542400  \n",
       "77472                    0.904188               1                    0.904188  \n",
       "79693                    0.541024               1                    0.541024  \n",
       "79875                    0.717545               1                    0.717545  \n",
       "80009                    0.839582               1                    0.839582  \n",
       "80794                    0.823816               1                    0.823816  \n",
       "83971                    0.589580               1                    0.589580  \n",
       "85791                    0.639338               1                    0.639338  \n",
       "86549                    0.661940               1                    0.661940  \n",
       "87205                    0.606414               1                    0.606414  \n",
       "87444                    0.518933               1                    0.518933  \n",
       "89341                    0.533863               1                    0.533863  \n",
       "91725                    0.860424               1                    0.860424  \n",
       "\n",
       "[20 rows x 50 columns]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df[(test_df['target'] == 0) &(test_df['Prediction_log'] == 1) & (test_df['black']==1)].iloc[40:60,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('tf-idf',\n",
       "                 TfidfVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.float64'>,\n",
       "                                 encoding='utf-8', input='content',\n",
       "                                 lowercase=False, max_df=1.0, max_features=None,\n",
       "                                 min_df=1, ngram_range=(1, 1), norm='l2',\n",
       "                                 preprocessor=None, smooth_idf=True,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 sublinear_tf=False,\n",
       "                                 token_pattern...\n",
       "                                 tokenizer=<bound method TweetTokenizer.tokenize of <nltk.tokenize.casual.TweetTokenizer object at 0x26c293668>>,\n",
       "                                 use_idf=True, vocabulary=None)),\n",
       "                ('model',\n",
       "                 LogisticRegression(C=1, class_weight=None, dual=False,\n",
       "                                    fit_intercept=True, intercept_scaling=1,\n",
       "                                    l1_ratio=None, max_iter=100,\n",
       "                                    multi_class='warn', n_jobs=None,\n",
       "                                    penalty='l1', random_state=None,\n",
       "                                    solver='warn', tol=0.0001, verbose=0,\n",
       "                                    warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predict_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         0\n",
       "1         0\n",
       "2         0\n",
       "3         0\n",
       "4         1\n",
       "         ..\n",
       "194635    0\n",
       "194636    0\n",
       "194637    1\n",
       "194638    0\n",
       "194639    0\n",
       "Name: Prediction_log, Length: 194640, dtype: int64"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df['Prediction_log']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
