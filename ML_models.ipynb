{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling - ML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal for our work is to not only train a model to identify toxic comments, but to do so while reducing bias.\n",
    "Bias in this task can be viewed as the situation where certain identies such as 'Black', 'Muslim', 'Gay' e.t.c, begin triggering toxic classification for comments they are in, even when the comment is actually positive. This is a key issue in toxic comment classification. \n",
    "\n",
    "The goal of the [jigsaw unintended Bias in Toxicity Classification](https://www.kaggle.com/c/jigsaw-unintended-bias-in-toxicity-classification/data) Kaggle challenge was to reduce this bias via a newly developed submetric which we have defined below.\n",
    "\n",
    "**Note: The goal of the model is simply to predict the toxicity score of a model.** \n",
    "\n",
    "The bias weighted ROC metric below is calulated by taking segmenting the the dataset into identity subgroups by using the provided identity labels and then calculating the subgroup metrics.\n",
    "\n",
    "In this notebook we have trained some baseline models which we will use as a baseline to compare our neural network against. \n",
    "\n",
    "### Metrics:\n",
    "\n",
    "In addition to accuracy we will observe the below metrics for our models\n",
    "\n",
    "#### Overall ROC-AUC:\n",
    "\n",
    "This is the standard ROC-AUC for the full evaluation set. In other words this is the area under the Reciever Operating Characteristic curve. It compares the true positive and false positive rates of a binary model.\n",
    "\n",
    "#### Subgroup ROC-AUC:\n",
    "\n",
    "Here, we restrict the data set to only the examples that mention the specific identity subgroup. A low value in this metric means the model does a poor job of distinguishing between toxic and non-toxic comments that mention the identity.\n",
    "\n",
    "#### BPSN AUC:\n",
    "\n",
    "BPSN (Background Positive, Subgroup Negative) AUC: Here, we restrict the test set to the non-toxic examples that mention the identity and the toxic examples that do not. A low value in this metric means that the model confuses non-toxic examples that mention the identity with toxic examples that do not, likely meaning that the model predicts higher toxicity scores than it should for non-toxic examples mentioning the identity.\n",
    "\n",
    "#### BNSP AUC:\n",
    "\n",
    "BNSP (Background Negative, Subgroup Positive) AUC: Here, we restrict the test set to the toxic examples that mention the identity and the non-toxic examples that do not. A low value here means that the model confuses toxic examples that mention the identity with non-toxic examples that do not, likely meaning that the model predicts lower toxicity scores than it should for toxic examples mentioning the identity.\n",
    "\n",
    "\n",
    "#### Generalized Mean of Bias AUCs\n",
    "To combine the per-identity Bias AUCs into one overall measure, we calculate their generalized mean as defined below:\n",
    "\n",
    "$M_p(m_s) = \\left(\\frac{1}{N} \\sum_{s=1}^{N} m_s^p\\right)^\\frac{1}{p}$\n",
    "\n",
    "Where:\n",
    "\n",
    "$M_p$ = the $p$th power-mean function\n",
    "\n",
    "$m_s$ = the bias metric $m$ calulated for subgroup $s$\n",
    "\n",
    "$N$ = number of identity subgroups\n",
    "\n",
    "For this competition, JigsawAI use a p value of -5 to encourage competitors to improve the model for the identity subgroups with the lowest model performance.\n",
    "\n",
    "### Final Metric\n",
    "We combine the overall AUC with the generalized mean of the Bias AUCs to calculate the final model score:\n",
    "\n",
    "$score = w_0 AUC_{overall} + \\sum_{a=1}^{A} w_a M_p(m_{s,a})$\n",
    "\n",
    "$A$ = number of submetrics (3)\n",
    "\n",
    "$m_{s,a}$ = bias metric for identity subgroup $s$ using submetric $a$\n",
    "\n",
    "$w_a$ = $a$ weighting for the relative importance of each submetric; all four $w$ values set to 0.25\n",
    "\n",
    "\n",
    "### Process:\n",
    "\n",
    "#### Classical ML models\n",
    "This is primarily an NLP task, our X feature matrix will be based off the text from online comments. We have defined a pre-processing pipeline in the 'preprocessing.ipynb' notebook to use for our our ML classifiers and a seperate pre-processing pipeline for the neural network models we are planning on training.\n",
    "\n",
    "From the classic ML classifer models, we intend to use the following models - our base word embedding technique will be TF-IDF: \n",
    "\n",
    "   * Logistic Regression\n",
    "   * SVM\n",
    "   * Random Forest\n",
    " \n",
    "   \n",
    "We will carry out hyperparameter optimization for each model and calculate the metrics for each.\n",
    "\n",
    "#### Neural Networks\n",
    "*see NN_model.ipynb*\n",
    "\n",
    "We will also train a neural network to answer this problem. We will start with a basic LSTM model which will be made of:\n",
    "    \n",
    "   * LSTM layers to read through the data\n",
    "   * Dense layers\n",
    "   * Output layer using sigmoid for the classes\n",
    "   \n",
    "We will then seek to improve this LSTM by creating a Bidrectional LSTM (BiLSTM) which we believe will improve accuracy by reading input sequences in both directions. If time allows we will also attempt to include a simple attention mechanism.\n",
    "\n",
    "The NN models will use Glove 840B 300d word embeddings. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import string\n",
    "import contractions\n",
    "import tqdm\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "import gc\n",
    "import operator\n",
    "pd.options.display.float_format = '{:,.3f}'.format\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 1: Apply pre-processing to text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load train_data\n",
    "train_df = pd.read_csv('data/train_clean.csv')\n",
    "\n",
    "# Load in test data\n",
    "test_df = pd.read_csv('data/test_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.rename({'toxicity':'target'}, axis=1, inplace=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the unneeded columns\n",
    "train_df = train_df.iloc[:,1:]\n",
    "test_df = test_df.iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this cell we define the function that pre-processes our text\n",
    "\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
    "import contractions\n",
    "import string\n",
    "\n",
    "def text_cleaner(df, col_name, clean_col_name):\n",
    "    '''\n",
    "    Text pre-processing pipeline, we lemmatize words, expand contractions, remove common stop words, apply lower case,\n",
    "    tokenize, and delete punctuation. All functions use apply and list comprehension for speed benefit.\n",
    "   \n",
    "    INPUT:\n",
    "    df = name of dataframe\n",
    "    col_name = name of column to pre-process\n",
    "    clean_col_name = name of new cleaned_column\n",
    "   \n",
    "    OUTPUT:\n",
    "    None - changes are made directly to dataframe\n",
    "    \n",
    "    '''\n",
    "\n",
    "    # Lemmatize helper functions\n",
    "    # Lemmatize nouns\n",
    "    def lemmatize_text_noun(text):\n",
    "        return [lemmatizer.lemmatize(w, pos='n') for w in text]\n",
    "    \n",
    "    # Lemmatize verbs\n",
    "    def lemmatize_text_verb(text):\n",
    "        return [lemmatizer.lemmatize(w, pos='v') for w in text]\n",
    "    # Lemmatize adjectives\n",
    "    def lemmatize_text_adj(text):\n",
    "        return [lemmatizer.lemmatize(w, pos='a') for w in text]\n",
    "\n",
    "    # Lemmatize adverbs\n",
    "    def lemmatize_text_adv(text):\n",
    "        return [lemmatizer.lemmatize(w, pos='r') for w in text]\n",
    "    \n",
    "    # Expand contraction method\n",
    "    def contraction_expand(text):\n",
    "        return contractions.fix(text)\n",
    "    \n",
    "    # To lower case.\n",
    "    df[clean_col_name] = df[col_name].apply(lambda x: x.lower())\n",
    "    \n",
    "    # Expand contractions\n",
    "    df[clean_col_name] = df[clean_col_name].apply(lambda x: contraction_expand(x))\n",
    "    \n",
    "    #Tokenize:\n",
    "    tokenizer = TweetTokenizer(reduce_len=True)\n",
    "    df[clean_col_name] = df[clean_col_name].apply(lambda x: tokenizer.tokenize(x))\n",
    "   \n",
    "    \n",
    "    #Remove Stop words\n",
    "    stop_words = stopwords.words('english')\n",
    "    df[clean_col_name] = df[clean_col_name].apply(lambda x: [item for item in x if item not in stop_words])\n",
    "    \n",
    "    #Delete punctuation\n",
    "    punc_table = str.maketrans('', '', string.punctuation)\n",
    "    df[clean_col_name] = df[clean_col_name].apply(lambda x: [item.translate(punc_table) for item in x])\n",
    "    \n",
    "    # LEMMATIZATION\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    \n",
    "    df[clean_col_name] = df[clean_col_name].apply(lemmatize_text_noun)\n",
    "    df[clean_col_name] = df[clean_col_name].apply(lemmatize_text_verb)\n",
    "    df[clean_col_name] = df[clean_col_name].apply(lemmatize_text_adj)\n",
    "    df[clean_col_name] = df[clean_col_name].apply(lemmatize_text_adv)\n",
    "    \n",
    "    \n",
    "    return None\n",
    "\n",
    "\n",
    "def detokenizer(df, col_name):\n",
    "    detokenizer = TreebankWordDetokenizer()\n",
    "    df[col_name+'_detokenize'] = df[col_name].apply(lambda x: detokenizer.detokenize(x))\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 19min 18s, sys: 8.28 s, total: 19min 26s\n",
      "Wall time: 19min 30s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Run the cleaner func on train data\n",
    "text_cleaner(train_df, 'comment_text', 'comment_text_clean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "# Run the same cleaner on the training data\n",
    "text_cleaner(test_df, 'comment_text', 'comment_text_clean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 34s, sys: 803 ms, total: 3min 35s\n",
      "Wall time: 3min 37s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "detokenizer(train_df,'comment_text_clean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 23.9 s, sys: 194 ms, total: 24.1 s\n",
      "Wall time: 24.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# detokenize the test data\n",
    "detokenizer(test_df, 'comment_text_clean')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 2: Modelling\n",
    "\n",
    "The data has been pre-processed for our models. We can now begin model training.\n",
    "\n",
    "We have a seperate test dataset that will be kept aside for testing only once we have an ideal model. For hyperparameter optimizing we will use Scikit-learn's GridSearchCV. \n",
    "\n",
    "After we have fitted a model and predicted results, we can then append the predictions to the dataframe and calculate the subgroup AUCs and the final weighted metric . \n",
    "\n",
    "#### Defining subgroup AUC metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "SUBGROUP_AUC = 'subgroup_auc'\n",
    "BPSN_AUC = 'bpsn_auc'  # stands for background positive, subgroup negative\n",
    "BNSP_AUC = 'bnsp_auc'  # stands for background negative, subgroup positive\n",
    "\n",
    "\n",
    "# These calculations have been provided by Jigsaw AI for scoring based on the metrics of the kaggle competition\n",
    "# https://www.kaggle.com/c/jigsaw-unintended-bias-in-toxicity-classification/overview/evaluation\n",
    "\n",
    "# They work by filtering the relevant dataframe into specific subgroups and using the roc_auc_score metric from sklearn.\n",
    "\n",
    "def compute_auc(y_true, y_pred):\n",
    "    try:\n",
    "        return metrics.roc_auc_score(y_true, y_pred)\n",
    "    except ValueError:\n",
    "        return np.nan\n",
    "\n",
    "def compute_subgroup_auc(df, subgroup, label, model_name):\n",
    "    subgroup_examples = df[df[subgroup]]\n",
    "    return compute_auc(subgroup_examples[label], subgroup_examples[model_name])\n",
    "\n",
    "def compute_bpsn_auc(df, subgroup, label, model_name):\n",
    "    \"\"\"Computes the AUC of the within-subgroup negative examples and the background positive examples.\"\"\"\n",
    "    subgroup_negative_examples = df.loc[df[subgroup] & ~df[label]]\n",
    "    non_subgroup_positive_examples = df.loc[~df[subgroup] & df[label]]\n",
    "    examples = subgroup_negative_examples.append(non_subgroup_positive_examples)\n",
    "    return compute_auc(examples[label], examples[model_name])\n",
    "\n",
    "def compute_bnsp_auc(df, subgroup, label, model_name):\n",
    "    \"\"\"Computes the AUC of the within-subgroup positive examples and the background negative examples.\"\"\"\n",
    "    subgroup_positive_examples = df.loc[df[subgroup] & df[label]]\n",
    "    non_subgroup_negative_examples = df.loc[~df[subgroup] & ~df[label]]\n",
    "    examples = subgroup_positive_examples.append(non_subgroup_negative_examples)\n",
    "    return compute_auc(examples[label], examples[model_name])\n",
    "\n",
    "def compute_bias_metrics_for_model(dataset,\n",
    "                                   subgroups,\n",
    "                                   model,\n",
    "                                   label_col,\n",
    "                                   include_asegs=False):\n",
    "    \"\"\"Computes per-subgroup metrics for all subgroups and one model.\"\"\"\n",
    "    records = []\n",
    "    for subgroup in subgroups:\n",
    "        record = {\n",
    "            'subgroup': subgroup,\n",
    "            'subgroup_size': len(dataset.loc[dataset[subgroup]])\n",
    "        }\n",
    "        record[SUBGROUP_AUC] = compute_subgroup_auc(dataset, subgroup, label_col, model)\n",
    "        record[BPSN_AUC] = compute_bpsn_auc(dataset, subgroup, label_col, model)\n",
    "        record[BNSP_AUC] = compute_bnsp_auc(dataset, subgroup, label_col, model)\n",
    "        records.append(record)\n",
    "    return pd.DataFrame(records).sort_values('subgroup_auc', ascending=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These calculations have been provided by Jigsaw AI for scoring based on the metrics of the kaggle competition\n",
    "# https://www.kaggle.com/c/jigsaw-unintended-bias-in-toxicity-classification/overview/evaluation\n",
    "\n",
    "# They work by filtering the relevant dataframe into specific subgroups and using the roc_auc_score metric from sklearn.\n",
    "\n",
    "def calculate_overall_auc(df, model_name):\n",
    "    true_labels = df[TOXICITY_COLUMN]\n",
    "    predicted_labels = df[model_name]\n",
    "    return metrics.roc_auc_score(true_labels, predicted_labels)\n",
    "\n",
    "def power_mean(series, p):\n",
    "    total = sum(np.power(series, p))\n",
    "    return np.power(total / len(series), 1 / p)\n",
    "\n",
    "def get_final_metric(bias_df, overall_auc, POWER=-5, OVERALL_MODEL_WEIGHT=0.25):\n",
    "    bias_score = np.average([\n",
    "        power_mean(bias_df[SUBGROUP_AUC], POWER),\n",
    "        power_mean(bias_df[BPSN_AUC], POWER),\n",
    "        power_mean(bias_df[BNSP_AUC], POWER)\n",
    "    ])\n",
    "    return (OVERALL_MODEL_WEIGHT * overall_auc) + ((1 - OVERALL_MODEL_WEIGHT) * bias_score)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train shape: (1804874,)\n",
      "y_test shape: (194640,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression\n",
    "\n",
    "We will use Grid Search Cross validation to optimize our hyperparameters on the training set. We will then fit the best estimator and then predict on the test set and calculate relevent metrics.\n",
    "\n",
    "Because the subgroup ROCs are calculated post prediction and require predictions to be appended to a dataframe, we cannot actually pass the metrics into the scoring function of scikit-learn's gridsearchCV(). Instead we will just test the models on accuracy and total ROC-AUC and then refitting the grid-search on the model with the best ROC-AUC as a proxy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.65 ms, sys: 3.6 ms, total: 5.25 ms\n",
      "Wall time: 8.3 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVC\n",
    "#no scaling data is already transformed\n",
    "\n",
    "# Instantiate the tokenizer to use in the vectorizer\n",
    "tweet_tokenizer = TweetTokenizer(reduce_len=True)\n",
    "\n",
    "# Instantiate the vectorizer, we will pass in the TweetTokenizer() from nltk \n",
    "tfid_vec_2 = TfidfVectorizer(lowercase=False, tokenizer = tweet_tokenizer.tokenize)\n",
    "\n",
    "# define pipeline\n",
    "pipeline = Pipeline([('tf-idf', tfid_vec_2), \n",
    "                     ('model', SVC())])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "# Define scoring functions\n",
    "scorers = {'AUC': 'roc_auc', 'Accuracy': make_scorer(accuracy_score)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define parameters\n",
    "param_grid_log = [{'model': [LogisticRegression()], 'tf-idf': [tfid_vec_2], \n",
    "                   'model__penalty': ['l1', 'l2'],\n",
    "                   'model__C': [.001, 0.01, 0.1, 1, 10, 100]}]\n",
    "\n",
    "# Setting refit='AUC', refits an estimator on the whole dataset with the\n",
    "# parameter setting that has the best cross-validated AUC score, i.e it finds the params that gives the best scores\n",
    "# then refits using the ones that give the best AUC. \n",
    "grid_log = GridSearchCV(pipeline, param_grid_log, cv=5, scoring=scorers, refit='AUC', \n",
    "                        return_train_score=True, n_jobs=-1)\n",
    "\n",
    "fittedgrid_log = grid_log.fit(train_df['comment_text_clean_detokenize'], train_df['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib\n",
    "# Save best estimator to file\n",
    "joblib.dump(fittedgrid.best_estimator_, 'saved_models/best_log_reg.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run this to load the model if required\n",
    "from sklearn.externals import joblib\n",
    "from joblib import load\n",
    "fittedgrid_log = load('saved_models/best_log_reg.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get scores\n",
    "train_accuracy_log = fittedgrid_log.score(train_df['comment_text_clean_detokenize'], y_train)\n",
    "test_accuracy_log = fittedgrid_log.score(test_df['comment_text_clean_detokenize'], y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict train and test values\n",
    "y_train_pred = fittedgrid_log.predict(train_df['comment_text_clean_detokenize'])\n",
    "y_test_pred = fittedgrid_log.predict(test_df['comment_text_clean_detokenize'])\n",
    "\n",
    "y_train_pred_prob_log = fittedgrid_log.predict_proba(train_df['comment_text_clean_detokenize'])\n",
    "y_test_pred_prob_log = fittedgrid_log.predict_proba(test_df['comment_text_clean_detokenize'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.97    179192\n",
      "           1       0.76      0.50      0.60     15448\n",
      "\n",
      "    accuracy                           0.95    194640\n",
      "   macro avg       0.86      0.74      0.79    194640\n",
      "weighted avg       0.94      0.95      0.94    194640\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Confusion Matrix and Classification Report, we want to store the F1 Score.\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# store the precision, recall, and f1 score for later and print the classification report\n",
    "log_precision = precision_score(y_test, y_test_pred)\n",
    "log_recall = recall_score(y_test, y_test_pred)\n",
    "log_f1 = f1_score(y_test, y_test_pred)\n",
    "\n",
    "print(classification_report(y_test, y_test_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area under curve (AUC):0.9408323249419588\n"
     ]
    }
   ],
   "source": [
    "# Lets plot out the regular ROC curve\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "\n",
    "fprs, tprs, thresholds = roc_curve(y_test, y_test_pred_prob_log[:,1])\n",
    "roc_auc = roc_auc_score(y_test, y_test_pred_prob_log[:,1])\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fprs, tprs, color='darkorange',\n",
    "         lw=2, label='AUC = %0.2f' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=1, linestyle='--')\n",
    "plt.xlabel('False Positive Rate (FPR)')\n",
    "plt.ylabel('True Positive Rate (TPR)')\n",
    "plt.title('ROC Curve for Logistic Regression')\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()\n",
    "\n",
    "print(f'Area under curve (AUC):{roc_auc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append preds and probabilities to train and valid dfs\n",
    "train_df['Prediction_log'] = y_train_pred\n",
    "train_df['Prediction_probability_log'] = y_train_pred_prob[:, 1]\n",
    "test_df['Prediction_log'] = y_test_pred\n",
    "test_df['Prediction_probability_log'] = y_test_pred_prob[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identity columns used to calculate subgroup AUC\n",
    "identity_columns = [\n",
    "    'male', 'female', 'homosexual_gay_or_lesbian', 'christian', 'jewish',\n",
    "    'muslim', 'black', 'white', 'psychiatric_or_mental_illness']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in identity_columns + ['target']:\n",
    "    train_df[col] = np.where(train_df[col] >= 0.5, True, False)\n",
    "    test_df[col] = np.where(test_df[col] >= 0.5, True, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the AUC metrics \n",
    "\n",
    "SUBGROUP_AUC = 'subgroup_auc'\n",
    "BPSN_AUC = 'bpsn_auc'  # stands for background positive, subgroup negative\n",
    "BNSP_AUC = 'bnsp_auc'\n",
    "\n",
    "MODEL_NAME = 'Prediction_log'\n",
    "TOXICITY_COLUMN = 'target'\n",
    "\n",
    "log_bias_metrics_df_train = compute_bias_metrics_for_model(train_df, identity_columns, MODEL_NAME, TOXICITY_COLUMN)\n",
    "log_final_metric_train = get_final_metric(log_bias_metrics_df_train, calculate_overall_auc(train_df, MODEL_NAME))\n",
    "\n",
    "log_bias_metrics_df_test = compute_bias_metrics_for_model(test_df, identity_columns, MODEL_NAME, TOXICITY_COLUMN)\n",
    "log_final_metric_test = get_final_metric(log_bias_metrics_df_test, calculate_overall_auc(test_df, MODEL_NAME))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_bias_metrics_df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'train_accuracy:{train_accuracy}')\n",
    "print(f'train weighted subgroup AUC:{get_final_metric(bias_metrics_df_train, calculate_overall_auc(train_df, MODEL_NAME))}')\n",
    "print(f'test_accuracy:{test_accuracy}')\n",
    "print(f'test weighted subgroup AUC::{get_final_metric(bias_metrics_df_val, calculate_overall_auc(test_df, MODEL_NAME))}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Evaluation:\n",
    "\n",
    "The logistic regression performed well on pure accuracy, with a train accuracy of 95.38% and 94.96% test accuracy. What is also positive to see is that our hyperparameter optimization has led to a model which does not overfit excessively. \n",
    "\n",
    "However when we look at the weighted subgroup AUC metric, the 71.9% train score and 71.5% test score show that the model did have a tendency towards biased predictions for certain subgroup. In comparison, the benchmark CNN that was provided had a weighted AUC score of 88.35% albeit just on a validation set \n",
    "\n",
    "\n",
    "For example we can see that for the 'black' identity BPSN AUC was relatively low, suggesting the model is likely overweighting mentions of the 'black' identity with toxicity. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost\n",
    "\n",
    "We will now carry out a similar process with the XGBoost classifie,\n",
    "\n",
    "#### Grid searching on a subset of data\n",
    "\n",
    "Given the length of time taken to grid search using SVM, we will run a gridsearch on a subset of our dataset by taking a new train test split. We will then use the results there as a proxy for the optimal parameters for our full dataset.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# Create a new split of the training dataframe to use for this reduced test. \n",
    "# we will not need the remainder. We will take 1/4 of the total data set\n",
    "remainder, reduced_df = train_test_split(train_df, test_size=0.25, stratify=train_df['target'], random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 27 candidates, totalling 81 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:  9.7min\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed: 19.2min\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed: 21.3min\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed: 40.4min\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed: 50.9min\n",
      "[Parallel(n_jobs=-1)]: Done  45 tasks      | elapsed: 61.1min\n",
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed: 71.7min\n",
      "[Parallel(n_jobs=-1)]: Done  75 out of  81 | elapsed: 100.7min remaining:  8.1min\n",
      "[Parallel(n_jobs=-1)]: Done  81 out of  81 | elapsed: 104.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 14min 39s, sys: 1min 17s, total: 15min 56s\n",
      "Wall time: 1h 48min 25s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Grid search applies tfid_vec_2 to all models. XGB is a boosting method so the idea is to train a sequence of weak models.\n",
    "# we are using a decision tree implementation so this means we will train a sequence of low depth trees.\n",
    "# one of the key hyperparameters is therefore learning rate. \n",
    "# min_child_weight controls what the minimum weight a child can have to classify it as a final node. Higher values mean\n",
    "# more conservative decision boundaries\n",
    "# gamma sets a minimum loss reduction amount. If drawing a class boundary at a certain point does not breach this threshold\n",
    "# the model will not draw the boundary.\n",
    "\n",
    "param_grid_xgb = [{'model': [XGBClassifier()], 'tf-idf': [tfid_vec_2],\n",
    "                    \"model__learning_rate\"    : [ 0.15, 0.30, 0.45 ] , #default 0.3\n",
    "                     \"model__min_child_weight\" : [ 1, 3, 7 ], #1 is default\n",
    "                     \"model__gamma\"            : [ 0.0, 0.2, 0.4 ], #default is 0 \n",
    "                      }]\n",
    "\n",
    "reduced_grid_xgb = GridSearchCV(pipeline, param_grid_xgb, scoring=scorers, cv=3, refit='AUC',\n",
    "                       return_train_score=True, n_jobs=-1, verbose=10)\n",
    "\n",
    "reduced_grid_xgb = reduced_grid_xgb.fit(reduced_df['comment_text_clean_detokenize'], reduced_df['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('tf-idf',\n",
       "                 TfidfVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.float64'>,\n",
       "                                 encoding='utf-8', input='content',\n",
       "                                 lowercase=False, max_df=1.0, max_features=None,\n",
       "                                 min_df=1, ngram_range=(1, 1), norm='l2',\n",
       "                                 preprocessor=None, smooth_idf=True,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 sublinear_tf=False,\n",
       "                                 token_pattern...\n",
       "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
       "                               colsample_bylevel=1, colsample_bynode=1,\n",
       "                               colsample_bytree=1, gamma=0.4,\n",
       "                               learning_rate=0.45, max_delta_step=0,\n",
       "                               max_depth=3, min_child_weight=3, missing=None,\n",
       "                               n_estimators=100, n_jobs=1, nthread=None,\n",
       "                               objective='binary:logistic', random_state=0,\n",
       "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "                               seed=None, silent=None, subsample=1,\n",
       "                               verbosity=1))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Gives the model with the best AUC score\n",
    "reduced_grid_xgb.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that from our gridsearch of the subset of data, the best model had max_depth of 3, min child weight of 3, gamma of 0.4 and a learning rate of 0.45. We will use this information to train a XGB model on the full dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9063757091545201"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# what is the best AUC score\n",
    "reduced_grid_xgb.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fitting model on full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 14min 15s, sys: 9.19 s, total: 14min 24s\n",
      "Wall time: 14min 38s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0.4,\n",
       "              learning_rate=0.45, max_delta_step=0, max_depth=3,\n",
       "              min_child_weight=3, missing=None, n_estimators=100, n_jobs=1,\n",
       "              nthread=None, objective='binary:logistic', random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "              silent=None, subsample=1, verbosity=1)"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "#as we aren't using gridsearch, we will need to directly transform the train and test features using the \n",
    "#tfidf vectorizer\n",
    "X_train = tfid_vec_2.transform(train_df['comment_text_clean_detokenize'])\n",
    "X_test = tfid_vec_2.transform(test_df['comment_text_clean_detokenize'])\n",
    "\n",
    "#instantiate XGB Classfier with parameters learned from earlier\n",
    "XGB_model = XGBClassifier(max_depth =3, learning_rate=0.45, min_child_weight=3, gamma=0.4)\n",
    "# Fit model on training set\n",
    "XGB_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['saved_models/best_XGB.pkl']"
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save best estimator to file\n",
    "joblib.dump(XGB_model, 'saved_models/best_XGB.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get scores\n",
    "train_accuracy_xgb = XGB_model.score(X_train, y_train)\n",
    "test_accuracy_xgb = XGB_model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict train and test values\n",
    "y_train_pred = XGB_model.predict(X_train)\n",
    "y_test_pred = XGB_model.predict(X_test)\n",
    "\n",
    "y_train_pred_prob_xgb = XGB_model.predict_proba(X_train)\n",
    "y_test_pred_prob_xgb = XGB_model.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.99      0.97    179192\n",
      "           1       0.79      0.41      0.54     15448\n",
      "\n",
      "    accuracy                           0.94    194640\n",
      "   macro avg       0.87      0.70      0.75    194640\n",
      "weighted avg       0.94      0.94      0.94    194640\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# store the precision, recall, and f1 score for later and print the classification report\n",
    "xgb_precision = precision_score(y_test, y_test_pred)\n",
    "xgb_recall = recall_score(y_test, y_test_pred)\n",
    "xgb_f1 = f1_score(y_test, y_test_pred)\n",
    "\n",
    "print(classification_report(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area under curve (AUC):0.9031525355668136\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "\n",
    "fprs, tprs, thresholds = roc_curve(y_test, y_test_pred_prob_xgb[:,1])\n",
    "roc_auc = roc_auc_score(y_test, y_test_pred_prob_xgb[:,1])\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fprs, tprs, color='darkorange',\n",
    "         lw=2, label='AUC = %0.2f' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=1, linestyle='--')\n",
    "plt.xlabel('False Positive Rate (FPR)')\n",
    "plt.ylabel('True Positive Rate (TPR)')\n",
    "plt.title('ROC Curve for XGBoost')\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()\n",
    "\n",
    "print(f'Area under curve (AUC):{roc_auc}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append preds and probabilities to train and valid dfs\n",
    "\n",
    "\n",
    "train_df['Prediction_xgb'] = y_train_pred\n",
    "train_df['Prediction_probability_xgb'] = y_train_pred_prob[:, 1]\n",
    "test_df['Prediction_xgb'] = y_test_pred\n",
    "test_df['Prediction_probability_xgb'] = y_test_pred_prob[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the AUC metrics \n",
    "\n",
    "SUBGROUP_AUC = 'subgroup_auc'\n",
    "BPSN_AUC = 'bpsn_auc'  # stands for background positive, subgroup negative\n",
    "BNSP_AUC = 'bnsp_auc'\n",
    "\n",
    "MODEL_NAME = 'Prediction_svc'\n",
    "TOXICITY_COLUMN = 'target'\n",
    "\n",
    "xgb_bias_metrics_df_train = compute_bias_metrics_for_model(train_df, identity_columns, MODEL_NAME, TOXICITY_COLUMN)\n",
    "xgb_final_metric_train = get_final_metric(xgb_bias_metrics_df_train, calculate_overall_auc(train_df, MODEL_NAME))\n",
    "\n",
    "xgb_bias_metrics_df_test = compute_bias_metrics_for_model(test_df, identity_columns, MODEL_NAME, TOXICITY_COLUMN)\n",
    "xgb_final_metric_test = get_final_metric(xgb_bias_metrics_df_test, calculate_overall_auc(test_df, MODEL_NAME))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7126513014416012"
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_final_metric_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest\n",
    "\n",
    "For our final model we will try the Random Forest Classifier which is an ensemble method. It is based on the Decision Tree model, only the Random Forest works by fitting on random sub samples of the data (with replacement), which is known as 'bagging'. A voting algorithm is then applied on the results of each of the trees to determine the final class of the data point. The aim of Random Forest is to train a series of overfit models and then average out the results via voting to get better results. The main hyperparemeter we will optimize for is the number of decision trees to use. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grid Search on a subset of data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the length of time taken to grid search on the Random Forest Classifier, we will run a gridsearch on a subset of our dataset by taking a new train test split. We will then use the results there as a proxy for the optimal parameters for our full dataset. We will use the same train_test split as used for the SVM subset search. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:  5.4min\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed: 13.1min\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed: 35.6min\n",
      "[Parallel(n_jobs=-1)]: Done  25 out of  36 | elapsed: 78.8min remaining: 34.7min\n",
      "[Parallel(n_jobs=-1)]: Done  29 out of  36 | elapsed: 113.6min remaining: 27.4min\n",
      "[Parallel(n_jobs=-1)]: Done  33 out of  36 | elapsed: 132.4min remaining: 12.0min\n",
      "[Parallel(n_jobs=-1)]: Done  36 out of  36 | elapsed: 165.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 50min 44s, sys: 12.9 s, total: 50min 57s\n",
      "Wall time: 3h 35min 49s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Note, most of the time here actually comes from the application of the tfid vectorizer to each fold of the data\n",
    "# Random forest itself takes ~5minutes to run on the vectorized data.\n",
    "\n",
    "# We control the model max depth \n",
    "param_grid_RF = {'model': [RandomForestClassifier()], 'tf-idf': [tfid_vec_2], \n",
    "                 'model__n_estimators': [10,50,100],\n",
    "                 'model__max_depth': [100, 500, 1000, 5000],\n",
    "             }\n",
    "reduced_grid_RF = GridSearchCV(pipeline, param_grid_RF, scoring=scorers, cv=3, refit='AUC',\n",
    "                       return_train_score=True, n_jobs=-1, verbose = 10)\n",
    "\n",
    "reduced_grid_RF = reduced_grid_RF.fit(reduced_df['comment_text_clean_detokenize'], reduced_df['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('tf-idf',\n",
       "                 TfidfVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.float64'>,\n",
       "                                 encoding='utf-8', input='content',\n",
       "                                 lowercase=False, max_df=1.0, max_features=None,\n",
       "                                 min_df=1, ngram_range=(1, 1), norm='l2',\n",
       "                                 preprocessor=None, smooth_idf=True,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 sublinear_tf=False,\n",
       "                                 token_pattern...\n",
       "                 RandomForestClassifier(bootstrap=True, class_weight=None,\n",
       "                                        criterion='gini', max_depth=1000,\n",
       "                                        max_features='auto',\n",
       "                                        max_leaf_nodes=None,\n",
       "                                        min_impurity_decrease=0.0,\n",
       "                                        min_impurity_split=None,\n",
       "                                        min_samples_leaf=1, min_samples_split=2,\n",
       "                                        min_weight_fraction_leaf=0.0,\n",
       "                                        n_estimators=100, n_jobs=None,\n",
       "                                        oob_score=False, random_state=None,\n",
       "                                        verbose=0, warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the best estimator parameters\n",
    "reduced_grid_RF.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9230210872062684"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# gives the best AUC score\n",
    "reduced_grid_RF.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reduced_grid_RF.cv_results_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above test has suggested that in terms of hyperparameters, we should look at a model that has n_estimators around 100 or above, and max_depth of around 1000. We will use this as a guide for our grid search. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grid Search in the full dataset\n",
    "Now that we have a good idea of optimal parameters, we will run another grid search on a few parameters around the optimal figures provided by our test on the subset of data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running a grid-search on the full set of data \n",
    "param_grid_RF = {'model': [RandomForestClassifier()], 'tf-idf': [tfid_vec_2], \n",
    "                 'model__n_estimators': [100,150,200],\n",
    "                 'model__max_depth': [1000, 2000, 3000, 4000],\n",
    "             }\n",
    "grid_RF = GridSearchCV(pipeline, param_grid_RF, scoring=scorers, cv=3, refit='AUC',\n",
    "                       return_train_score=True, n_jobs=-1, verbose = 10)\n",
    "\n",
    "fittedgrid_RF = grid_RF.fit(train_df['comment_text_clean_detokenize'], train_df['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=1000, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = tfid_vec_2.transform(train_df['comment_text_clean_detokenize'])\n",
    "X_test = tfid_vec_2.transform(test_df['comment_text_clean_detokenize'])\n",
    "RF_model = RandomForestClassifier(n_estimators = 100, max_depth = 1000)\n",
    "RF_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 20s, sys: 3.61 s, total: 1min 24s\n",
      "Wall time: 1min 26s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "rf_test_accuracy = RF_model.score(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9417591450883682"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['saved_models/best_RF.pkl']"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save best estimator to file\n",
    "joblib.dump(RF_model, 'saved_models/best_RF.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict train and test values\n",
    "#y_train_pred = RF_model.predict(X_train)\n",
    "#y_test_pred = RF_model.predict(X_test)\n",
    "\n",
    "#y_train_pred_prob_rf = RF_model.predict_proba(X_train)\n",
    "y_test_pred_prob_rf = RF_model.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.96265644, 0.03734356],\n",
       "       [0.97665037, 0.02334963],\n",
       "       [0.97868673, 0.02131327],\n",
       "       ...,\n",
       "       [0.46485893, 0.53514107],\n",
       "       [0.88846968, 0.11153032],\n",
       "       [0.96707338, 0.03292662]])"
      ]
     },
     "execution_count": 372,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_pred_prob_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.99      0.97    179192\n",
      "           1       0.83      0.34      0.48     15448\n",
      "\n",
      "    accuracy                           0.94    194640\n",
      "   macro avg       0.89      0.67      0.72    194640\n",
      "weighted avg       0.94      0.94      0.93    194640\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# store the precision, recall, and f1 score for later and print the classification report\n",
    "rf_precision = precision_score(y_test, y_test_pred)\n",
    "rf_recall = recall_score(y_test, y_test_pred)\n",
    "rf_f1 = f1_score(y_test, y_test_pred)\n",
    "\n",
    "print(classification_report(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area under curve (AUC):0.9247063596820333\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Lets plot the standard ROC curve\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "\n",
    "fprs, tprs, thresholds = roc_curve(y_test, y_test_pred_prob_rf[:,1])\n",
    "roc_auc = roc_auc_score(y_test, y_test_pred_prob_rf[:,1])\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fprs, tprs, color='darkorange',\n",
    "         lw=2, label='AUC = %0.2f' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=1, linestyle='--')\n",
    "plt.xlabel('False Positive Rate (FPR)')\n",
    "plt.ylabel('True Positive Rate (TPR)')\n",
    "plt.title('ROC Curve for Random Forest')\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()\n",
    "\n",
    "print(f'Area under curve (AUC):{roc_auc}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identity columns used to calculate subgroup AUC\n",
    "identity_columns = [\n",
    "    'male', 'female', 'homosexual_gay_or_lesbian', 'christian', 'jewish',\n",
    "    'muslim', 'black', 'white', 'psychiatric_or_mental_illness']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in identity_columns + ['target']:\n",
    "    train_df[col] = np.where(train_df[col] >= 0.5, True, False)\n",
    "    test_df[col] = np.where(test_df[col] >= 0.5, True, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append preds and probabilities to train and valid dfs\n",
    "train_df['Prediction_RF'] = y_train_pred\n",
    "train_df['Prediction_probability_RF'] = y_train_pred_prob[:, 1]\n",
    "test_df['Prediction_RF'] = y_test_pred\n",
    "test_df['Prediction_probability_RF'] = y_test_pred_prob[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the AUC metrics \n",
    "\n",
    "SUBGROUP_AUC = 'subgroup_auc'\n",
    "BPSN_AUC = 'bpsn_auc'  # stands for background positive, subgroup negative\n",
    "BNSP_AUC = 'bnsp_auc'\n",
    "\n",
    "MODEL_NAME = 'Prediction_RF'\n",
    "TOXICITY_COLUMN = 'target'\n",
    "\n",
    "rf_bias_metrics_df_train = compute_bias_metrics_for_model(train_df, identity_columns, MODEL_NAME, TOXICITY_COLUMN)\n",
    "rf_final_metric_train = get_final_metric(rf_bias_metrics_df_train, calculate_overall_auc(train_df, MODEL_NAME))\n",
    "\n",
    "rf_bias_metrics_df_test = compute_bias_metrics_for_model(test_df, identity_columns, MODEL_NAME, TOXICITY_COLUMN)\n",
    "rf_final_metric_test = get_final_metric(rf_bias_metrics_df_test, calculate_overall_auc(test_df, MODEL_NAME))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subgroup</th>\n",
       "      <th>subgroup_size</th>\n",
       "      <th>subgroup_auc</th>\n",
       "      <th>bpsn_auc</th>\n",
       "      <th>bnsp_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>black</td>\n",
       "      <td>1519</td>\n",
       "      <td>0.535805</td>\n",
       "      <td>0.671200</td>\n",
       "      <td>0.534692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>christian</td>\n",
       "      <td>4226</td>\n",
       "      <td>0.538518</td>\n",
       "      <td>0.671294</td>\n",
       "      <td>0.536449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>jewish</td>\n",
       "      <td>835</td>\n",
       "      <td>0.542044</td>\n",
       "      <td>0.668454</td>\n",
       "      <td>0.540397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>muslim</td>\n",
       "      <td>2040</td>\n",
       "      <td>0.542836</td>\n",
       "      <td>0.672161</td>\n",
       "      <td>0.540382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>homosexual_gay_or_lesbian</td>\n",
       "      <td>1065</td>\n",
       "      <td>0.546340</td>\n",
       "      <td>0.669129</td>\n",
       "      <td>0.545196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>white</td>\n",
       "      <td>2452</td>\n",
       "      <td>0.556286</td>\n",
       "      <td>0.671977</td>\n",
       "      <td>0.555543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>female</td>\n",
       "      <td>5155</td>\n",
       "      <td>0.573352</td>\n",
       "      <td>0.671357</td>\n",
       "      <td>0.572037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>psychiatric_or_mental_illness</td>\n",
       "      <td>511</td>\n",
       "      <td>0.584684</td>\n",
       "      <td>0.664368</td>\n",
       "      <td>0.586552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>male</td>\n",
       "      <td>4386</td>\n",
       "      <td>0.585907</td>\n",
       "      <td>0.670266</td>\n",
       "      <td>0.584965</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        subgroup  subgroup_size  subgroup_auc  bpsn_auc  \\\n",
       "6                          black           1519      0.535805  0.671200   \n",
       "3                      christian           4226      0.538518  0.671294   \n",
       "4                         jewish            835      0.542044  0.668454   \n",
       "5                         muslim           2040      0.542836  0.672161   \n",
       "2      homosexual_gay_or_lesbian           1065      0.546340  0.669129   \n",
       "7                          white           2452      0.556286  0.671977   \n",
       "1                         female           5155      0.573352  0.671357   \n",
       "8  psychiatric_or_mental_illness            511      0.584684  0.664368   \n",
       "0                           male           4386      0.585907  0.670266   \n",
       "\n",
       "   bnsp_auc  \n",
       "6  0.534692  \n",
       "3  0.536449  \n",
       "4  0.540397  \n",
       "5  0.540382  \n",
       "2  0.545196  \n",
       "7  0.555543  \n",
       "1  0.572037  \n",
       "8  0.586552  \n",
       "0  0.584965  "
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_bias_metrics_df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6108032567341172"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_final_metric_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'train_accuracy:{train_accuracy}')\n",
    "print(f'train weighted AUC:{rf_final_metric_train}')\n",
    "print(f'test_accuracy:{test_accuracy}')\n",
    "print(f'test weighted AUC::{rf_final_metric_test}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of the classical models the Random Forest was by far the weakest in terms of the final weighted AUC metric. It generally did poorly accross all the identity subgroups. In addition to this, it had very poor recall on the test set, implying that the model was failing to identify many cases of toxic commentary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing Model performance\n",
    "\n",
    "Now that we have trained three seperate models which have been shown to deliver strong performance in text classification tasks in the past let us take the time to compare them side-by-side and also discuss their short-comings in terms of reducing bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Display the subgroup bias metrics tables for each model and then the final metrics for each model for test only\n",
    "display(log_bias_metrics_df_test)\n",
    "display(svm_bias_metrics_df_test)\n",
    "display(rf_bias_metrics_df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display final metrics for each model for test only.\n",
    "print(f' Final metric for Logistic Regression: {log_final_metric_test}')\n",
    "print(f' Final metric for SVM: {svm_final_metric_test}')\n",
    "print(f' Final metric for Random Forest: {rf_final_metric_test}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NN model results taken from NN_model ipynb\n",
    "NN_final_metric_test = 0.920\n",
    "NN_precision_test = 0.754\n",
    "NN_Recall_test = 0.628\n",
    "NN_f1_test = 0.681\n",
    "NN_accuracy_test = 0.953"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'Accuracy': [test_accuracy_log, test_accuracy_xgb, rf_test_accuracy, NN_accuracy_test ], \n",
    "        'Precision': [log_precision, xgb_precision, rf_precision, NN_precision_test ],\n",
    "       'Recall': [log_recall, xgb_recall, rf_recall, NN_Recall_test], 'F1': [log_f1, xgb_f1, rf_f1, NN_f1_test ],\n",
    "       'Final Bias Metric': [log_final_metric_test, xgb_final_metric_test, rf_final_metric_test, NN_final_metric_test ]}\n",
    "\n",
    "results_df = pd.DataFrame(data, index=['Logistic', 'XGboost', 'Random Forest', 'LSTM'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Final Bias Metric</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Logistic</th>\n",
       "      <td>0.947</td>\n",
       "      <td>0.758</td>\n",
       "      <td>0.495</td>\n",
       "      <td>0.599</td>\n",
       "      <td>0.713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGboost</th>\n",
       "      <td>0.944</td>\n",
       "      <td>0.785</td>\n",
       "      <td>0.408</td>\n",
       "      <td>0.537</td>\n",
       "      <td>0.713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>0.942</td>\n",
       "      <td>0.826</td>\n",
       "      <td>0.338</td>\n",
       "      <td>0.479</td>\n",
       "      <td>0.611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LSTM</th>\n",
       "      <td>0.953</td>\n",
       "      <td>0.754</td>\n",
       "      <td>0.628</td>\n",
       "      <td>0.681</td>\n",
       "      <td>0.920</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Accuracy  Precision  Recall    F1  Final Bias Metric\n",
       "Logistic          0.947      0.758   0.495 0.599              0.713\n",
       "XGboost           0.944      0.785   0.408 0.537              0.713\n",
       "Random Forest     0.942      0.826   0.338 0.479              0.611\n",
       "LSTM              0.953      0.754   0.628 0.681              0.920"
      ]
     },
     "execution_count": 357,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the results we can see that our LSTM model has generally outperformed all three of the other models in the metrics selected. In particular we can see that the final bias metric, the weighted average of the subgroup AUCs, was significantly higher for the LSTM than the others at 0.92. This suggests that the LSTM model was better than the other models at minimising bias by not focussing on specific occurances of certain identy words when evaluating a particular comment. This fits in with our initial hypothesis and it is a positive result. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets plot all 4 ROC curves"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Steps for further exploration:\n",
    "\n",
    "All our models generally showed strong precision, suggesting that when they did classify something as toxic they were generally accurate. However we can see that recall was usually weak, suggesting that the model struggled to pick out all cases of toxicity. We believe this is highly likely to be due to the large class imbalance in the dataset where only ~8% of the data was classified as toxic. A natural first step would be to therefore re-run the model on a more balanced dataset. Another option would be to lower the threshold for toxicity, however this can come at the expense of precision.\n",
    "\n",
    "We would also like to carry out a more exhaustive hyperparameter optimization exercise for our models. Unfortunately, it quickly became apparent that doing so on our current computing hardwarde was not feasible and cloud hardware was primarily used to train our LSTM. With access to more powerful hardware we would be able to better optmize our models.\n",
    "\n",
    "For our LSTM model, we would definitely like to try further network structures, including potentially adding a further bi-directional layer or an attention mechanism. Attention mechanisms have been proven to be very effective in tasks where a model needs to focus in on specific areas of a sequence that containt he most relevant information and are core parts of many SotA NLP architectures. In addition with more time we would like to try out different glove embeddings and also process our text further to potentially increase the percentage of our vocabulary covered by the word embeddings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Pipeline' object has no attribute 'best_estimator_'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-368-4d6bf037c315>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#coef_df['Non_toxic'] = Logit.coef_[0,:]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#c#oef_df['Toxic'] = Logit.coef_[1,:]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mfittedgrid_log\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'Pipeline' object has no attribute 'best_estimator_'"
     ]
    }
   ],
   "source": [
    "#coef_df = pd.DataFrame(bagofwords.get_feature_names(), columns=['token'])\n",
    "\n",
    "#coef_df['Non_toxic'] = Logit.coef_[0,:]\n",
    "#c#oef_df['Toxic'] = Logit.coef_[1,:]\n",
    "fittedgrid_log.best_estimator_.coef_[1,:]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the results of our ML models using eli5\n",
    "\n",
    "Below we use the eli5 package to help interpret our results. We will do this using the logistic model we fit due to only certain sklearn classifiers being compatible. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import eli5\n",
    "from eli5.lime import TextExplainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "# We need to fit a standard Logistic Model using the same parametrs as our fitted grid as eli5 does not take in grids\n",
    "eli5_log_model = LogisticRegression(C=1, penalty='l1')\n",
    "# use the train and test transformed arrays from earlier\n",
    "eli5_log_model.fit(X_train,y_train)\n",
    "\n",
    "#score to check accuracy similar\n",
    "accuracy = eli5_log_model.score(X_test, y_test)\n",
    "#predict the test \n",
    "preds = eli5_log_model.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['eli5_log'] = preds[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['eli5_log'] = np.where(test_df['eli5_log']>=0.5,1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1804874x181709 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 42012254 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "eli5.show_prediction(eli5_log_model, test_df.loc[23566,'comment_text_clean_detokenize'], vec=tfid_vec_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "    table.eli5-weights tr:hover {\n",
       "        filter: brightness(85%);\n",
       "    }\n",
       "</style>\n",
       "\n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "        \n",
       "\n",
       "    \n",
       "\n",
       "        \n",
       "            \n",
       "                \n",
       "                \n",
       "    \n",
       "        <p style=\"margin-bottom: 0.5em; margin-top: 0em\">\n",
       "            <b>\n",
       "    \n",
       "        y=Non-toxic\n",
       "    \n",
       "</b>\n",
       "\n",
       "    \n",
       "    (probability <b>0.875</b>, score <b>-1.947</b>)\n",
       "\n",
       "top features\n",
       "        </p>\n",
       "    \n",
       "    <table class=\"eli5-weights\"\n",
       "           style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto; margin-bottom: 2em;\">\n",
       "        <thead>\n",
       "        <tr style=\"border: none;\">\n",
       "            \n",
       "                <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\" title=\"Feature contribution already accounts for the feature value (for linear models, contribution = weight * feature value), and the sum of feature contributions is equal to the score or, for some classifiers, to the probability. Feature values are shown if &quot;show_feature_values&quot; is True.\">\n",
       "                    Contribution<sup>?</sup>\n",
       "                </th>\n",
       "            \n",
       "            <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
       "            \n",
       "        </tr>\n",
       "        </thead>\n",
       "        <tbody>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 80.00%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +4.068\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        &lt;BIAS&gt;\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 98.01%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.151\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        preference\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 99.26%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.037\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        less\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 99.30%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.034\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        wonderful\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 99.39%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.028\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        part\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 99.41%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.027\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        typo\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 99.43%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.025\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        feel\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 99.45%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.024\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        question\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 99.51%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.020\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        condemnation\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 99.52%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.020\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        actually\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 99.52%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.020\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        personal\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 99.57%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.017\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        business\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 99.61%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.015\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        play\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 99.61%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.014\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        think\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 99.62%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.014\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        do\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 99.65%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.012\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        life\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 99.68%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.011\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        fact\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 99.69%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.011\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        possible\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 99.72%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.009\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        family\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 99.72%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.009\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        know\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 99.82%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.005\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        support\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 99.85%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.004\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        young\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 99.85%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.004\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        really\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 99.89%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.002\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        people\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "        \n",
       "\n",
       "        \n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 99.76%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.008\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        care\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 99.68%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.011\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        absolutely\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 99.62%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.014\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        person\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 99.57%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.017\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        I\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 99.38%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.029\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        old\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 99.32%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.032\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        guy\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 99.26%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.037\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        men\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 99.06%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.052\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        wife\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 98.45%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.105\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        heterosexual\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 97.39%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.222\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        sex\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 94.93%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.573\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        sexual\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 89.90%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -1.533\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        homosexual\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "\n",
       "        </tbody>\n",
       "    </table>\n",
       "\n",
       "            \n",
       "        \n",
       "\n",
       "        \n",
       "\n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "Explanation(estimator=\"LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\\n                   intercept_scaling=1, l1_ratio=None, max_iter=100,\\n                   multi_class='warn', n_jobs=None, penalty='l1',\\n                   random_state=None, solver='warn', tol=0.0001, verbose=0,\\n                   warm_start=False)\", description=None, error=None, method='linear model', is_regression=False, targets=[TargetExplanation(target='Non-toxic', feature_weights=FeatureWeights(pos=[FeatureWeight(feature='<BIAS>', weight=4.067819526352757, std=None, value=1.0), FeatureWeight(feature='preference', weight=0.15050612342487557, std=None, value=0.09848561374752673), FeatureWeight(feature='less', weight=0.036944886978590434, std=None, value=0.0500007178968633), FeatureWeight(feature='wonderful', weight=0.03366097949275505, std=None, value=0.04248781514865893), FeatureWeight(feature='part', weight=0.028071741398437572, std=None, value=0.028695163706261836), FeatureWeight(feature='typo', weight=0.026525265257097065, std=None, value=0.05552247344761501), FeatureWeight(feature='feel', weight=0.02510549275237288, std=None, value=0.030215840943073273), FeatureWeight(feature='question', weight=0.023841653295555622, std=None, value=0.02989906224280827), FeatureWeight(feature='condemnation', weight=0.02026188992118554, std=None, value=0.05234319218098195), FeatureWeight(feature='actually', weight=0.019820321467975, std=None, value=0.027909609531955874), FeatureWeight(feature='personal', weight=0.019710444406929213, std=None, value=0.03441866191382622), FeatureWeight(feature='business', weight=0.016951853666838285, std=None, value=0.02949374721939931), FeatureWeight(feature='play', weight=0.01457930155185926, std=None, value=0.031171737086051646), FeatureWeight(feature='think', weight=0.01441062144290144, std=None, value=0.02056907354815411), FeatureWeight(feature='do', weight=0.014166183433322727, std=None, value=0.029319737402930382), FeatureWeight(feature='life', weight=0.012448280707995136, std=None, value=0.027174048980096552), FeatureWeight(feature='fact', weight=0.010839712371861526, std=None, value=0.026469590531643414), FeatureWeight(feature='possible', weight=0.010553022429058853, std=None, value=0.035006343821040904), FeatureWeight(feature='family', weight=0.0093540006619206, std=None, value=0.029651813188166162), FeatureWeight(feature='know', weight=0.009237308450812094, std=None, value=0.02141555522935561), FeatureWeight(feature='support', weight=0.004999720265117958, std=None, value=0.027467486358471824), FeatureWeight(feature='young', weight=0.0036654504265455556, std=None, value=0.033846188512670905), FeatureWeight(feature='really', weight=0.00362754966135804, std=None, value=0.025857875671579034), FeatureWeight(feature='people', weight=0.0022696096266836482, std=None, value=0.01903367763501745)], neg=[FeatureWeight(feature='homosexual', weight=-1.5333567146966083, std=None, value=0.24161180220043157), FeatureWeight(feature='sexual', weight=-0.573117504249419, std=None, value=0.11510645269997512), FeatureWeight(feature='sex', weight=-0.22189934896406804, std=None, value=0.03863307178797715), FeatureWeight(feature='heterosexual', weight=-0.10525988881695267, std=None, value=0.05552247344761501), FeatureWeight(feature='wife', weight=-0.051797752776036335, std=None, value=0.03866720671384609), FeatureWeight(feature='men', weight=-0.03651617378313542, std=None, value=0.03383374101463431), FeatureWeight(feature='guy', weight=-0.03225704785716684, std=None, value=0.03004123887762275), FeatureWeight(feature='old', weight=-0.02868211338270907, std=None, value=0.029844398374451343), FeatureWeight(feature='I', weight=-0.016989373098195867, std=None, value=0.11251272723185926), FeatureWeight(feature='person', weight=-0.014201923335239518, std=None, value=0.02935669962375227), FeatureWeight(feature='absolutely', weight=-0.011204155808376842, std=None, value=0.03651218283971557), FeatureWeight(feature='care', weight=-0.007510241722540822, std=None, value=0.028050857768798794)], pos_remaining=0, neg_remaining=0), proba=0.8750731045334196, score=-1.9465787009543574, weighted_spans=None, heatmap=None)], feature_importances=None, decision_tree=None, highlight_spaces=None, transition_features=None, image=None)"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = test_df.loc[92316,'comment_text']\n",
    "text\n",
    "eli5.explain_prediction(eli5_log_model, text, \n",
    "                        target_names=['Non-toxic', 'Toxic'], vec=tfid_vec_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Racist out comes don't have to motivated by a since of white superiority. Simple ignorance is all it takes. I worked in the public sector for 30 years in Eugene, often being the only black male in the office. I would not consider the vast majority of white folks I worked with to be conscious racists. However, the majority of them were ignorant about their own bias'. For example, they may say they hire people they feel comfortable with. However, since most of them never had a close black friend, they some how end up hiring only white folks. Of course, if they crew up in Idaho, how would they get to know any black people well enough to make friends? For example, I am the only black man to be a manager in the 100 year history of EWEB. For every one on those years EWEB was less than a mile from the UO. No one in management at EWEB think there is anything wrong or unusual with that reality. I would not be surprised if all public offices in Oregon have some degree of that blindness.\""
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = test_df.loc[166392,'comment_text']\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'racist come motivated since white superiority  simple ignorance take  worked public sector 30 year eugene  often black male office  would consider vast majority white folk worked conscious racist  however  majority ignorant bias   example  may say hire people feel comfortable  however  since never close black friend  end hiring white folk  course  crew idaho  would get know black people well enough make friend  example  black man manager 100 year history eweb  every one year eweb le mile uo  one management eweb think anything wrong unusual reality  would surprised public office oregon degree blindness'"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text2 = test_df.loc[23566,'comment_text_clean_detokenize']\n",
    "text2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>created_date</th>\n",
       "      <th>publication_id</th>\n",
       "      <th>article_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>funny</th>\n",
       "      <th>wow</th>\n",
       "      <th>sad</th>\n",
       "      <th>likes</th>\n",
       "      <th>...</th>\n",
       "      <th>intellectual_or_learning_disability</th>\n",
       "      <th>psychiatric_or_mental_illness</th>\n",
       "      <th>other_disability</th>\n",
       "      <th>comment_text_clean</th>\n",
       "      <th>comment_text_clean_detokenize</th>\n",
       "      <th>Prediction_svc</th>\n",
       "      <th>Prediction_probability_svc</th>\n",
       "      <th>Prediction_log</th>\n",
       "      <th>Prediction_probability_log</th>\n",
       "      <th>eli5_log</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>878</th>\n",
       "      <td>7000878</td>\n",
       "      <td>Oh man..., no one is trying to \"wear\" anyone d...</td>\n",
       "      <td>2017-08-28 16:42:44.817441+00</td>\n",
       "      <td>22</td>\n",
       "      <td>370137</td>\n",
       "      <td>approved</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[oh, man, , , one, trying, , wear, , anyone, l...</td>\n",
       "      <td>oh man   one trying  wear  anyone left  ask bl...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.604803</td>\n",
       "      <td>1</td>\n",
       "      <td>0.604803</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1090</th>\n",
       "      <td>7001090</td>\n",
       "      <td>Interesting that the DP failed to tell the ent...</td>\n",
       "      <td>2017-08-30 03:35:00.945664+00</td>\n",
       "      <td>102</td>\n",
       "      <td>372110</td>\n",
       "      <td>approved</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[interesting, dp, failed, tell, entire, story,...</td>\n",
       "      <td>interesting dp failed tell entire story  sayin...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.468953</td>\n",
       "      <td>0</td>\n",
       "      <td>0.468953</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1329</th>\n",
       "      <td>7001329</td>\n",
       "      <td>\"Democrats renounced racism. \"\\r\\n\\r\\nSo  Tim ...</td>\n",
       "      <td>2017-09-03 15:26:54.188281+00</td>\n",
       "      <td>13</td>\n",
       "      <td>373393</td>\n",
       "      <td>approved</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[, democrat, renounced, racism, , , tim, agree...</td>\n",
       "      <td>democrat renounced racism   tim agrees democra...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.427517</td>\n",
       "      <td>0</td>\n",
       "      <td>0.427517</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1686</th>\n",
       "      <td>7001686</td>\n",
       "      <td>You can't make this stuff up ..\\r\\n.A white ra...</td>\n",
       "      <td>2017-10-12 02:26:36.040025+00</td>\n",
       "      <td>105</td>\n",
       "      <td>387829</td>\n",
       "      <td>approved</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[make, stuff, \\r\\n, white, rapper, rant, playe...</td>\n",
       "      <td>make stuff \\r\\n white rapper rant played black...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.921078</td>\n",
       "      <td>1</td>\n",
       "      <td>0.921078</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3562</th>\n",
       "      <td>7003562</td>\n",
       "      <td>What annoys me is the way these politically co...</td>\n",
       "      <td>2016-12-08 16:31:29.779533+00</td>\n",
       "      <td>54</td>\n",
       "      <td>155349</td>\n",
       "      <td>approved</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[annoys, way, politically, correct, term, gone...</td>\n",
       "      <td>annoys way politically correct term gone full ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.812175</td>\n",
       "      <td>1</td>\n",
       "      <td>0.812175</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3599</th>\n",
       "      <td>7003599</td>\n",
       "      <td>You don't have a clue of what it's like to be ...</td>\n",
       "      <td>2017-02-25 15:16:06.873103+00</td>\n",
       "      <td>53</td>\n",
       "      <td>314382</td>\n",
       "      <td>approved</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[clue, like, , grew, among, black, , worked, b...</td>\n",
       "      <td>clue like  grew among black  worked black  pla...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.560420</td>\n",
       "      <td>1</td>\n",
       "      <td>0.560420</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3602</th>\n",
       "      <td>7003602</td>\n",
       "      <td>Well personally, as a white guy I was accused ...</td>\n",
       "      <td>2017-11-06 21:52:38.604522+00</td>\n",
       "      <td>102</td>\n",
       "      <td>397590</td>\n",
       "      <td>approved</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[well, personally, , white, guy, accused, raci...</td>\n",
       "      <td>well personally  white guy accused racism furi...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.939019</td>\n",
       "      <td>1</td>\n",
       "      <td>0.939019</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4204</th>\n",
       "      <td>7004204</td>\n",
       "      <td>Yes. \\r\\n\\r\\nUnlike women, gays, lesbians, tra...</td>\n",
       "      <td>2017-05-22 18:12:29.957359+00</td>\n",
       "      <td>13</td>\n",
       "      <td>336018</td>\n",
       "      <td>approved</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[yes, , unlike, woman, , gay, , lesbian, , tra...</td>\n",
       "      <td>yes  unlike woman  gay  lesbian  transgenders ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.860850</td>\n",
       "      <td>1</td>\n",
       "      <td>0.860850</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4826</th>\n",
       "      <td>7004826</td>\n",
       "      <td>I'm talking about the eugenics practiced in Or...</td>\n",
       "      <td>2016-04-19 16:39:05.823989+00</td>\n",
       "      <td>13</td>\n",
       "      <td>60528</td>\n",
       "      <td>approved</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[I, talking, eugenics, practiced, oregon, invo...</td>\n",
       "      <td>I talking eugenics practiced oregon involuntar...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.796792</td>\n",
       "      <td>1</td>\n",
       "      <td>0.796792</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5844</th>\n",
       "      <td>7005844</td>\n",
       "      <td>It's simple.\\r\\nWorking means getting up and g...</td>\n",
       "      <td>2017-09-10 14:49:42.415101+00</td>\n",
       "      <td>102</td>\n",
       "      <td>376135</td>\n",
       "      <td>approved</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[simple, , working, mean, getting, going, work...</td>\n",
       "      <td>simple  working mean getting going work  buyin...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.699297</td>\n",
       "      <td>1</td>\n",
       "      <td>0.699297</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7722</th>\n",
       "      <td>7007722</td>\n",
       "      <td>Walter:  I'm sure you deny feeling \"white man'...</td>\n",
       "      <td>2017-09-03 18:36:12.576890+00</td>\n",
       "      <td>13</td>\n",
       "      <td>373393</td>\n",
       "      <td>approved</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[walter, , I, sure, deny, feeling, , white, ma...</td>\n",
       "      <td>walter  I sure deny feeling  white man guilt  ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.582941</td>\n",
       "      <td>1</td>\n",
       "      <td>0.582941</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10059</th>\n",
       "      <td>7010059</td>\n",
       "      <td>I am a retired Army colonel. This PC, left win...</td>\n",
       "      <td>2017-11-08 16:31:48.801952+00</td>\n",
       "      <td>105</td>\n",
       "      <td>398116</td>\n",
       "      <td>approved</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[retired, army, colonel, , pc, , left, wing, j...</td>\n",
       "      <td>retired army colonel  pc  left wing jerk tryin...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.548858</td>\n",
       "      <td>1</td>\n",
       "      <td>0.548858</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10831</th>\n",
       "      <td>7010831</td>\n",
       "      <td>Yes, breathing while black.</td>\n",
       "      <td>2017-09-02 21:59:40.362604+00</td>\n",
       "      <td>53</td>\n",
       "      <td>373093</td>\n",
       "      <td>approved</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[yes, , breathing, black, ]</td>\n",
       "      <td>yes  breathing black</td>\n",
       "      <td>1</td>\n",
       "      <td>0.718893</td>\n",
       "      <td>1</td>\n",
       "      <td>0.718893</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12581</th>\n",
       "      <td>7012581</td>\n",
       "      <td>Forget about the Catholic component. It's very...</td>\n",
       "      <td>2016-10-14 15:55:45.727706+00</td>\n",
       "      <td>53</td>\n",
       "      <td>148503</td>\n",
       "      <td>approved</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[forget, catholic, component, , clear, race, i...</td>\n",
       "      <td>forget catholic component  clear race importan...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.684445</td>\n",
       "      <td>1</td>\n",
       "      <td>0.684445</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13444</th>\n",
       "      <td>7013444</td>\n",
       "      <td>I'm a moderate and don't get caught up in eith...</td>\n",
       "      <td>2017-08-16 18:12:31.914734+00</td>\n",
       "      <td>102</td>\n",
       "      <td>367233</td>\n",
       "      <td>approved</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[I, moderate, get, caught, either, side, polit...</td>\n",
       "      <td>I moderate get caught either side politics  th...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.485873</td>\n",
       "      <td>0</td>\n",
       "      <td>0.485873</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13680</th>\n",
       "      <td>7013680</td>\n",
       "      <td>Are you kidding? 99% of the chronic thieves bu...</td>\n",
       "      <td>2017-08-24 22:06:27.097897+00</td>\n",
       "      <td>21</td>\n",
       "      <td>370264</td>\n",
       "      <td>approved</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[kidding, , 99, , chronic, thief, busted, plac...</td>\n",
       "      <td>kidding  99  chronic thief busted place work w...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.774574</td>\n",
       "      <td>1</td>\n",
       "      <td>0.774574</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14070</th>\n",
       "      <td>7014070</td>\n",
       "      <td>This country and the NFL has made more black m...</td>\n",
       "      <td>2017-09-23 19:37:12.534970+00</td>\n",
       "      <td>55</td>\n",
       "      <td>381076</td>\n",
       "      <td>approved</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[country, nfl, made, black, millionaire, anyth...</td>\n",
       "      <td>country nfl made black millionaire anything el...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.653236</td>\n",
       "      <td>1</td>\n",
       "      <td>0.653236</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16036</th>\n",
       "      <td>7016036</td>\n",
       "      <td>You are wrong. Racism can be active or passive...</td>\n",
       "      <td>2017-09-03 18:35:16.925135+00</td>\n",
       "      <td>13</td>\n",
       "      <td>373393</td>\n",
       "      <td>approved</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[wrong, , racism, active, passive, , attention...</td>\n",
       "      <td>wrong  racism active passive  attention need i...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.882464</td>\n",
       "      <td>1</td>\n",
       "      <td>0.882464</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21363</th>\n",
       "      <td>7021363</td>\n",
       "      <td>\"Yeah, that’s not the point: you removed statu...</td>\n",
       "      <td>2017-08-28 17:15:58.989283+00</td>\n",
       "      <td>22</td>\n",
       "      <td>370137</td>\n",
       "      <td>approved</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[, yeah, , point, , removed, statue, mary, bab...</td>\n",
       "      <td>yeah  point  removed statue mary baby jesus  c...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.550947</td>\n",
       "      <td>1</td>\n",
       "      <td>0.550947</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21626</th>\n",
       "      <td>7021626</td>\n",
       "      <td>Let me\\r\\n\\r\\nFirst, the percentage of whites ...</td>\n",
       "      <td>2017-01-23 17:12:19.417798+00</td>\n",
       "      <td>54</td>\n",
       "      <td>163496</td>\n",
       "      <td>approved</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[let, first, , percentage, white, indian, citi...</td>\n",
       "      <td>let first  percentage white indian citizen pra...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.817162</td>\n",
       "      <td>1</td>\n",
       "      <td>0.817162</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22993</th>\n",
       "      <td>7022993</td>\n",
       "      <td>Eastman votes against honoring Hmong and Laoti...</td>\n",
       "      <td>2017-05-06 11:42:18.537246+00</td>\n",
       "      <td>21</td>\n",
       "      <td>332432</td>\n",
       "      <td>approved</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>55</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[eastman, vote, honoring, hmong, laotian, vete...</td>\n",
       "      <td>eastman vote honoring hmong laotian veteran  v...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.551769</td>\n",
       "      <td>1</td>\n",
       "      <td>0.551769</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23102</th>\n",
       "      <td>7023102</td>\n",
       "      <td>I think you're saying the being born rich is p...</td>\n",
       "      <td>2017-08-16 22:47:54.024159+00</td>\n",
       "      <td>13</td>\n",
       "      <td>366931</td>\n",
       "      <td>approved</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[think, saying, born, rich, probably, factor, ...</td>\n",
       "      <td>think saying born rich probably factor trump b...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.670123</td>\n",
       "      <td>1</td>\n",
       "      <td>0.670123</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23566</th>\n",
       "      <td>7023566</td>\n",
       "      <td>Racist out comes don't have to motivated by a ...</td>\n",
       "      <td>2017-09-18 17:01:22.386060+00</td>\n",
       "      <td>13</td>\n",
       "      <td>378947</td>\n",
       "      <td>approved</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[racist, come, motivated, since, white, superi...</td>\n",
       "      <td>racist come motivated since white superiority ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.813732</td>\n",
       "      <td>1</td>\n",
       "      <td>0.813732</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29236</th>\n",
       "      <td>7029236</td>\n",
       "      <td>Chris in Ottawa,\\r\\n\\r\\nAre you KIDDING me?\\r\\...</td>\n",
       "      <td>2017-07-30 15:52:16.305318+00</td>\n",
       "      <td>54</td>\n",
       "      <td>360964</td>\n",
       "      <td>approved</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[chris, ottawa, , kidding, , mean, , kidding, ...</td>\n",
       "      <td>chris ottawa  kidding  mean  kidding  nonchine...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.671653</td>\n",
       "      <td>1</td>\n",
       "      <td>0.671653</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32443</th>\n",
       "      <td>7032443</td>\n",
       "      <td>A Nazi would be more inclined, ideologically, ...</td>\n",
       "      <td>2017-08-18 14:15:38.899097+00</td>\n",
       "      <td>102</td>\n",
       "      <td>367562</td>\n",
       "      <td>approved</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[nazi, would, inclined, , ideologically, , vot...</td>\n",
       "      <td>nazi would inclined  ideologically  vote berni...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.700639</td>\n",
       "      <td>1</td>\n",
       "      <td>0.700639</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34296</th>\n",
       "      <td>7034296</td>\n",
       "      <td>garycrum - Clearly, the country has been divid...</td>\n",
       "      <td>2016-03-17 16:26:41.527452+00</td>\n",
       "      <td>13</td>\n",
       "      <td>49679</td>\n",
       "      <td>approved</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[garycrum, , clearly, , country, divided, time...</td>\n",
       "      <td>garycrum  clearly  country divided time  persp...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.567251</td>\n",
       "      <td>1</td>\n",
       "      <td>0.567251</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36050</th>\n",
       "      <td>7036050</td>\n",
       "      <td>And do it in the 50s when public schools for b...</td>\n",
       "      <td>2017-10-16 21:28:48.500213+00</td>\n",
       "      <td>102</td>\n",
       "      <td>389721</td>\n",
       "      <td>approved</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[50, public, school, black, horrible, , white,...</td>\n",
       "      <td>50 public school black horrible  white get leg</td>\n",
       "      <td>1</td>\n",
       "      <td>0.893342</td>\n",
       "      <td>1</td>\n",
       "      <td>0.893342</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36368</th>\n",
       "      <td>7036368</td>\n",
       "      <td>Jim, I don't think you can handle the truth ab...</td>\n",
       "      <td>2017-06-08 22:50:12.371396+00</td>\n",
       "      <td>13</td>\n",
       "      <td>341755</td>\n",
       "      <td>approved</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[jim, , think, handle, truth, role, white, rac...</td>\n",
       "      <td>jim  think handle truth role white racism hist...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.586750</td>\n",
       "      <td>1</td>\n",
       "      <td>0.586750</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36449</th>\n",
       "      <td>7036449</td>\n",
       "      <td>I'm having a hard time believing that you feel...</td>\n",
       "      <td>2016-10-24 20:11:23.056474+00</td>\n",
       "      <td>53</td>\n",
       "      <td>148708</td>\n",
       "      <td>approved</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[I, hard, time, believing, feel, bad, black, p...</td>\n",
       "      <td>I hard time believing feel bad black populatio...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.543354</td>\n",
       "      <td>1</td>\n",
       "      <td>0.543354</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40972</th>\n",
       "      <td>7040972</td>\n",
       "      <td>So, Muslims are not \"our people\"? Let's say th...</td>\n",
       "      <td>2016-11-30 21:20:47.109316+00</td>\n",
       "      <td>53</td>\n",
       "      <td>153390</td>\n",
       "      <td>approved</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[, muslim, , people, , , let, u, say, number, ...</td>\n",
       "      <td>muslim  people   let u say number black violen...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.530568</td>\n",
       "      <td>1</td>\n",
       "      <td>0.530568</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30 rows × 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id                                       comment_text  \\\n",
       "878    7000878  Oh man..., no one is trying to \"wear\" anyone d...   \n",
       "1090   7001090  Interesting that the DP failed to tell the ent...   \n",
       "1329   7001329  \"Democrats renounced racism. \"\\r\\n\\r\\nSo  Tim ...   \n",
       "1686   7001686  You can't make this stuff up ..\\r\\n.A white ra...   \n",
       "3562   7003562  What annoys me is the way these politically co...   \n",
       "3599   7003599  You don't have a clue of what it's like to be ...   \n",
       "3602   7003602  Well personally, as a white guy I was accused ...   \n",
       "4204   7004204  Yes. \\r\\n\\r\\nUnlike women, gays, lesbians, tra...   \n",
       "4826   7004826  I'm talking about the eugenics practiced in Or...   \n",
       "5844   7005844  It's simple.\\r\\nWorking means getting up and g...   \n",
       "7722   7007722  Walter:  I'm sure you deny feeling \"white man'...   \n",
       "10059  7010059  I am a retired Army colonel. This PC, left win...   \n",
       "10831  7010831                        Yes, breathing while black.   \n",
       "12581  7012581  Forget about the Catholic component. It's very...   \n",
       "13444  7013444  I'm a moderate and don't get caught up in eith...   \n",
       "13680  7013680  Are you kidding? 99% of the chronic thieves bu...   \n",
       "14070  7014070  This country and the NFL has made more black m...   \n",
       "16036  7016036  You are wrong. Racism can be active or passive...   \n",
       "21363  7021363  \"Yeah, that’s not the point: you removed statu...   \n",
       "21626  7021626  Let me\\r\\n\\r\\nFirst, the percentage of whites ...   \n",
       "22993  7022993  Eastman votes against honoring Hmong and Laoti...   \n",
       "23102  7023102  I think you're saying the being born rich is p...   \n",
       "23566  7023566  Racist out comes don't have to motivated by a ...   \n",
       "29236  7029236  Chris in Ottawa,\\r\\n\\r\\nAre you KIDDING me?\\r\\...   \n",
       "32443  7032443  A Nazi would be more inclined, ideologically, ...   \n",
       "34296  7034296  garycrum - Clearly, the country has been divid...   \n",
       "36050  7036050  And do it in the 50s when public schools for b...   \n",
       "36368  7036368  Jim, I don't think you can handle the truth ab...   \n",
       "36449  7036449  I'm having a hard time believing that you feel...   \n",
       "40972  7040972  So, Muslims are not \"our people\"? Let's say th...   \n",
       "\n",
       "                        created_date  publication_id  article_id    rating  \\\n",
       "878    2017-08-28 16:42:44.817441+00              22      370137  approved   \n",
       "1090   2017-08-30 03:35:00.945664+00             102      372110  approved   \n",
       "1329   2017-09-03 15:26:54.188281+00              13      373393  approved   \n",
       "1686   2017-10-12 02:26:36.040025+00             105      387829  approved   \n",
       "3562   2016-12-08 16:31:29.779533+00              54      155349  approved   \n",
       "3599   2017-02-25 15:16:06.873103+00              53      314382  approved   \n",
       "3602   2017-11-06 21:52:38.604522+00             102      397590  approved   \n",
       "4204   2017-05-22 18:12:29.957359+00              13      336018  approved   \n",
       "4826   2016-04-19 16:39:05.823989+00              13       60528  approved   \n",
       "5844   2017-09-10 14:49:42.415101+00             102      376135  approved   \n",
       "7722   2017-09-03 18:36:12.576890+00              13      373393  approved   \n",
       "10059  2017-11-08 16:31:48.801952+00             105      398116  approved   \n",
       "10831  2017-09-02 21:59:40.362604+00              53      373093  approved   \n",
       "12581  2016-10-14 15:55:45.727706+00              53      148503  approved   \n",
       "13444  2017-08-16 18:12:31.914734+00             102      367233  approved   \n",
       "13680  2017-08-24 22:06:27.097897+00              21      370264  approved   \n",
       "14070  2017-09-23 19:37:12.534970+00              55      381076  approved   \n",
       "16036  2017-09-03 18:35:16.925135+00              13      373393  approved   \n",
       "21363  2017-08-28 17:15:58.989283+00              22      370137  approved   \n",
       "21626  2017-01-23 17:12:19.417798+00              54      163496  approved   \n",
       "22993  2017-05-06 11:42:18.537246+00              21      332432  approved   \n",
       "23102  2017-08-16 22:47:54.024159+00              13      366931  approved   \n",
       "23566  2017-09-18 17:01:22.386060+00              13      378947  approved   \n",
       "29236  2017-07-30 15:52:16.305318+00              54      360964  approved   \n",
       "32443  2017-08-18 14:15:38.899097+00             102      367562  approved   \n",
       "34296  2016-03-17 16:26:41.527452+00              13       49679  approved   \n",
       "36050  2017-10-16 21:28:48.500213+00             102      389721  approved   \n",
       "36368  2017-06-08 22:50:12.371396+00              13      341755  approved   \n",
       "36449  2016-10-24 20:11:23.056474+00              53      148708  approved   \n",
       "40972  2016-11-30 21:20:47.109316+00              53      153390  approved   \n",
       "\n",
       "       funny  wow  sad  likes  ...  intellectual_or_learning_disability  \\\n",
       "878        0    0    0      0  ...                                    0   \n",
       "1090       0    0    0     17  ...                                    0   \n",
       "1329       0    0    0      0  ...                                    0   \n",
       "1686       0    0    0      1  ...                                    0   \n",
       "3562       2    0    0      2  ...                                    0   \n",
       "3599       0    0    0      0  ...                                    0   \n",
       "3602       0    0    0      0  ...                                    0   \n",
       "4204       1    0    0      2  ...                                    0   \n",
       "4826       0    0    0      0  ...                                    0   \n",
       "5844       1    0    1      3  ...                                    0   \n",
       "7722       1    0    0      3  ...                                    0   \n",
       "10059      0    0    0      1  ...                                    0   \n",
       "10831      0    0    0      1  ...                                    0   \n",
       "12581      0    0    0     22  ...                                    0   \n",
       "13444      1    0    0      1  ...                                    0   \n",
       "13680      0    0    0      9  ...                                    0   \n",
       "14070      0    0    1      2  ...                                    0   \n",
       "16036      1    0    0      2  ...                                    0   \n",
       "21363      0    0    0      0  ...                                    0   \n",
       "21626      0    0    0      0  ...                                    0   \n",
       "22993      2    0    1     55  ...                                    0   \n",
       "23102      1    0    0      2  ...                                    0   \n",
       "23566      0    0    0      0  ...                                    0   \n",
       "29236      0    0    0      5  ...                                    0   \n",
       "32443      0    0    1      0  ...                                    0   \n",
       "34296      0    0    0      0  ...                                    0   \n",
       "36050      0    0    0      1  ...                                    0   \n",
       "36368      0    0    0      0  ...                                    0   \n",
       "36449      0    0    0      1  ...                                    0   \n",
       "40972      0    0    0      0  ...                                    0   \n",
       "\n",
       "       psychiatric_or_mental_illness  other_disability  \\\n",
       "878                                0                 0   \n",
       "1090                               0                 0   \n",
       "1329                               0                 0   \n",
       "1686                               0                 0   \n",
       "3562                               0                 0   \n",
       "3599                               0                 0   \n",
       "3602                               0                 0   \n",
       "4204                               0                 0   \n",
       "4826                               0                 0   \n",
       "5844                               0                 0   \n",
       "7722                               0                 0   \n",
       "10059                              0                 0   \n",
       "10831                              0                 0   \n",
       "12581                              0                 0   \n",
       "13444                              0                 0   \n",
       "13680                              0                 0   \n",
       "14070                              0                 0   \n",
       "16036                              0                 0   \n",
       "21363                              0                 0   \n",
       "21626                              0                 0   \n",
       "22993                              0                 0   \n",
       "23102                              0                 0   \n",
       "23566                              0                 0   \n",
       "29236                              0                 0   \n",
       "32443                              0                 0   \n",
       "34296                              0                 0   \n",
       "36050                              0                 0   \n",
       "36368                              0                 0   \n",
       "36449                              0                 0   \n",
       "40972                              0                 0   \n",
       "\n",
       "                                      comment_text_clean  \\\n",
       "878    [oh, man, , , one, trying, , wear, , anyone, l...   \n",
       "1090   [interesting, dp, failed, tell, entire, story,...   \n",
       "1329   [, democrat, renounced, racism, , , tim, agree...   \n",
       "1686   [make, stuff, \\r\\n, white, rapper, rant, playe...   \n",
       "3562   [annoys, way, politically, correct, term, gone...   \n",
       "3599   [clue, like, , grew, among, black, , worked, b...   \n",
       "3602   [well, personally, , white, guy, accused, raci...   \n",
       "4204   [yes, , unlike, woman, , gay, , lesbian, , tra...   \n",
       "4826   [I, talking, eugenics, practiced, oregon, invo...   \n",
       "5844   [simple, , working, mean, getting, going, work...   \n",
       "7722   [walter, , I, sure, deny, feeling, , white, ma...   \n",
       "10059  [retired, army, colonel, , pc, , left, wing, j...   \n",
       "10831                        [yes, , breathing, black, ]   \n",
       "12581  [forget, catholic, component, , clear, race, i...   \n",
       "13444  [I, moderate, get, caught, either, side, polit...   \n",
       "13680  [kidding, , 99, , chronic, thief, busted, plac...   \n",
       "14070  [country, nfl, made, black, millionaire, anyth...   \n",
       "16036  [wrong, , racism, active, passive, , attention...   \n",
       "21363  [, yeah, , point, , removed, statue, mary, bab...   \n",
       "21626  [let, first, , percentage, white, indian, citi...   \n",
       "22993  [eastman, vote, honoring, hmong, laotian, vete...   \n",
       "23102  [think, saying, born, rich, probably, factor, ...   \n",
       "23566  [racist, come, motivated, since, white, superi...   \n",
       "29236  [chris, ottawa, , kidding, , mean, , kidding, ...   \n",
       "32443  [nazi, would, inclined, , ideologically, , vot...   \n",
       "34296  [garycrum, , clearly, , country, divided, time...   \n",
       "36050  [50, public, school, black, horrible, , white,...   \n",
       "36368  [jim, , think, handle, truth, role, white, rac...   \n",
       "36449  [I, hard, time, believing, feel, bad, black, p...   \n",
       "40972  [, muslim, , people, , , let, u, say, number, ...   \n",
       "\n",
       "                           comment_text_clean_detokenize  Prediction_svc  \\\n",
       "878    oh man   one trying  wear  anyone left  ask bl...               1   \n",
       "1090   interesting dp failed tell entire story  sayin...               0   \n",
       "1329   democrat renounced racism   tim agrees democra...               0   \n",
       "1686   make stuff \\r\\n white rapper rant played black...               1   \n",
       "3562   annoys way politically correct term gone full ...               1   \n",
       "3599   clue like  grew among black  worked black  pla...               1   \n",
       "3602   well personally  white guy accused racism furi...               1   \n",
       "4204   yes  unlike woman  gay  lesbian  transgenders ...               1   \n",
       "4826   I talking eugenics practiced oregon involuntar...               1   \n",
       "5844   simple  working mean getting going work  buyin...               1   \n",
       "7722   walter  I sure deny feeling  white man guilt  ...               1   \n",
       "10059  retired army colonel  pc  left wing jerk tryin...               1   \n",
       "10831                               yes  breathing black               1   \n",
       "12581  forget catholic component  clear race importan...               1   \n",
       "13444  I moderate get caught either side politics  th...               0   \n",
       "13680  kidding  99  chronic thief busted place work w...               1   \n",
       "14070  country nfl made black millionaire anything el...               1   \n",
       "16036  wrong  racism active passive  attention need i...               1   \n",
       "21363  yeah  point  removed statue mary baby jesus  c...               1   \n",
       "21626  let first  percentage white indian citizen pra...               1   \n",
       "22993  eastman vote honoring hmong laotian veteran  v...               1   \n",
       "23102  think saying born rich probably factor trump b...               1   \n",
       "23566  racist come motivated since white superiority ...               1   \n",
       "29236  chris ottawa  kidding  mean  kidding  nonchine...               1   \n",
       "32443  nazi would inclined  ideologically  vote berni...               1   \n",
       "34296  garycrum  clearly  country divided time  persp...               1   \n",
       "36050     50 public school black horrible  white get leg               1   \n",
       "36368  jim  think handle truth role white racism hist...               1   \n",
       "36449  I hard time believing feel bad black populatio...               1   \n",
       "40972  muslim  people   let u say number black violen...               1   \n",
       "\n",
       "       Prediction_probability_svc  Prediction_log  Prediction_probability_log  \\\n",
       "878                      0.604803               1                    0.604803   \n",
       "1090                     0.468953               0                    0.468953   \n",
       "1329                     0.427517               0                    0.427517   \n",
       "1686                     0.921078               1                    0.921078   \n",
       "3562                     0.812175               1                    0.812175   \n",
       "3599                     0.560420               1                    0.560420   \n",
       "3602                     0.939019               1                    0.939019   \n",
       "4204                     0.860850               1                    0.860850   \n",
       "4826                     0.796792               1                    0.796792   \n",
       "5844                     0.699297               1                    0.699297   \n",
       "7722                     0.582941               1                    0.582941   \n",
       "10059                    0.548858               1                    0.548858   \n",
       "10831                    0.718893               1                    0.718893   \n",
       "12581                    0.684445               1                    0.684445   \n",
       "13444                    0.485873               0                    0.485873   \n",
       "13680                    0.774574               1                    0.774574   \n",
       "14070                    0.653236               1                    0.653236   \n",
       "16036                    0.882464               1                    0.882464   \n",
       "21363                    0.550947               1                    0.550947   \n",
       "21626                    0.817162               1                    0.817162   \n",
       "22993                    0.551769               1                    0.551769   \n",
       "23102                    0.670123               1                    0.670123   \n",
       "23566                    0.813732               1                    0.813732   \n",
       "29236                    0.671653               1                    0.671653   \n",
       "32443                    0.700639               1                    0.700639   \n",
       "34296                    0.567251               1                    0.567251   \n",
       "36050                    0.893342               1                    0.893342   \n",
       "36368                    0.586750               1                    0.586750   \n",
       "36449                    0.543354               1                    0.543354   \n",
       "40972                    0.530568               1                    0.530568   \n",
       "\n",
       "       eli5_log  \n",
       "878           1  \n",
       "1090          1  \n",
       "1329          1  \n",
       "1686          1  \n",
       "3562          1  \n",
       "3599          1  \n",
       "3602          1  \n",
       "4204          1  \n",
       "4826          1  \n",
       "5844          1  \n",
       "7722          1  \n",
       "10059         1  \n",
       "10831         1  \n",
       "12581         1  \n",
       "13444         1  \n",
       "13680         1  \n",
       "14070         1  \n",
       "16036         1  \n",
       "21363         1  \n",
       "21626         1  \n",
       "22993         1  \n",
       "23102         1  \n",
       "23566         1  \n",
       "29236         1  \n",
       "32443         1  \n",
       "34296         1  \n",
       "36050         1  \n",
       "36368         1  \n",
       "36449         1  \n",
       "40972         1  \n",
       "\n",
       "[30 rows x 51 columns]"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df[(test_df['target'] == 0) & (test_df['eli5_log'] == 1) & \n",
    "        (test_df['black']==1)].iloc[0:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in log model\n",
    "joblib.dump(fittedgrid.best_estimator_, 'saved_models/best_log_reg.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "    table.eli5-weights tr:hover {\n",
       "        filter: brightness(85%);\n",
       "    }\n",
       "</style>\n",
       "\n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "        \n",
       "\n",
       "    \n",
       "\n",
       "        \n",
       "\n",
       "        \n",
       "    \n",
       "        \n",
       "        \n",
       "    \n",
       "        <p style=\"margin-bottom: 0.5em; margin-top: 0em\">\n",
       "            <b>\n",
       "    \n",
       "        y=Toxic\n",
       "    \n",
       "</b>\n",
       "\n",
       "    \n",
       "    (probability <b>0.509</b>, score <b>0.035</b>)\n",
       "\n",
       "top features\n",
       "        </p>\n",
       "    \n",
       "    <table class=\"eli5-weights\"\n",
       "           style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto; margin-bottom: 2em;\">\n",
       "        <thead>\n",
       "        <tr style=\"border: none;\">\n",
       "            \n",
       "                <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\" title=\"Feature contribution already accounts for the feature value (for linear models, contribution = weight * feature value), and the sum of feature contributions is equal to the score or, for some classifiers, to the probability. Feature values are shown if &quot;show_feature_values&quot; is True.\">\n",
       "                    Contribution<sup>?</sup>\n",
       "                </th>\n",
       "            \n",
       "            <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
       "            \n",
       "        </tr>\n",
       "        </thead>\n",
       "        <tbody>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 80.00%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.821\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        Highlighted in text (sum)\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "        \n",
       "\n",
       "        \n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 80.59%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.787\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        &lt;BIAS&gt;\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "\n",
       "        </tbody>\n",
       "    </table>\n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "\n",
       "    <p style=\"margin-bottom: 2.5em; margin-top:-0.5em;\">\n",
       "        <span style=\"background-color: hsl(120, 100.00%, 69.36%); opacity: 0.94\" title=\"1.153\">muslim</span><span style=\"opacity: 0.80\">  </span><span style=\"background-color: hsl(0, 100.00%, 90.35%); opacity: 0.83\" title=\"-0.221\">people</span><span style=\"opacity: 0.80\">   </span><span style=\"background-color: hsl(120, 100.00%, 90.59%); opacity: 0.83\" title=\"0.214\">let</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 97.58%); opacity: 0.80\" title=\"-0.031\">u</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 95.44%); opacity: 0.81\" title=\"-0.076\">say</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 85.65%); opacity: 0.85\" title=\"-0.390\">number</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 60.00%); opacity: 1.00\" title=\"1.687\">black</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 88.79%); opacity: 0.83\" title=\"-0.274\">violence</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 93.61%); opacity: 0.81\" title=\"-0.123\">equal</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 66.64%); opacity: 0.95\" title=\"1.302\">muslim</span><span style=\"opacity: 0.80\">  </span><span style=\"background-color: hsl(0, 100.00%, 93.46%); opacity: 0.82\" title=\"-0.127\">become</span><span style=\"opacity: 0.80\">  </span><span style=\"background-color: hsl(0, 100.00%, 91.93%); opacity: 0.82\" title=\"-0.171\">people</span><span style=\"opacity: 0.80\">  </span><span style=\"background-color: hsl(120, 100.00%, 68.95%); opacity: 0.94\" title=\"1.175\">white</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 86.01%); opacity: 0.84\" title=\"-0.376\">violence</span><span style=\"opacity: 0.80\">   </span><span style=\"background-color: hsl(0, 100.00%, 92.01%); opacity: 0.82\" title=\"-0.169\">become</span><span style=\"opacity: 0.80\">  </span><span style=\"background-color: hsl(0, 100.00%, 91.77%); opacity: 0.82\" title=\"-0.176\">people</span><span style=\"opacity: 0.80\">   </span><span style=\"background-color: hsl(0, 100.00%, 93.16%); opacity: 0.82\" title=\"-0.135\">believe</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 96.30%); opacity: 0.81\" title=\"0.056\">spelled</span><span style=\"opacity: 0.80\">   </span><span style=\"background-color: hsl(0, 100.00%, 81.67%); opacity: 0.87\" title=\"-0.554\">habeas</span>\n",
       "    </p>\n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate the lime TextExplainer model\n",
    "text_model_log = TextExplainer(random_state=1)\n",
    "\n",
    "#select a comment to investigate\n",
    "text = test_df.loc[40972,'comment_text_clean_detokenize']\n",
    "\n",
    "# Fit the Textexplainer using the logistic model predicted probabilites\n",
    "text_model_log.fit(text, fittedgrid_log.predict_proba)\n",
    "text_model_log.show_prediction(target_names=['Non-toxic', 'Toxic'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#92136 lgbt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"No it won't . That's just wishful thinking on democrats fault .   For the 100 th time , Walker cited the cost of drug users treatment as being lost with Obamacare .  I laugh every time I hear a liberal claim republicans want to hurt people , and that's why they dumped Obamacare.\""
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df['comment_text'].values[2:3][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "    table.eli5-weights tr:hover {\n",
       "        filter: brightness(85%);\n",
       "    }\n",
       "</style>\n",
       "\n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "        \n",
       "\n",
       "    \n",
       "\n",
       "        \n",
       "\n",
       "        \n",
       "    \n",
       "        \n",
       "        \n",
       "    \n",
       "        <p style=\"margin-bottom: 0.5em; margin-top: 0em\">\n",
       "            <b>\n",
       "    \n",
       "        y=Non-toxic\n",
       "    \n",
       "</b>\n",
       "\n",
       "    \n",
       "    (probability <b>0.984</b>, score <b>-4.104</b>)\n",
       "\n",
       "top features\n",
       "        </p>\n",
       "    \n",
       "    <table class=\"eli5-weights\"\n",
       "           style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto; margin-bottom: 2em;\">\n",
       "        <thead>\n",
       "        <tr style=\"border: none;\">\n",
       "            \n",
       "                <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\" title=\"Feature contribution already accounts for the feature value (for linear models, contribution = weight * feature value), and the sum of feature contributions is equal to the score or, for some classifiers, to the probability. Feature values are shown if &quot;show_feature_values&quot; is True.\">\n",
       "                    Contribution<sup>?</sup>\n",
       "                </th>\n",
       "            \n",
       "            <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
       "            \n",
       "        </tr>\n",
       "        </thead>\n",
       "        <tbody>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 80.00%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +3.525\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        Highlighted in text (sum)\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 94.35%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.580\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        &lt;BIAS&gt;\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "        \n",
       "\n",
       "        \n",
       "        \n",
       "\n",
       "        </tbody>\n",
       "    </table>\n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "\n",
       "    <p style=\"margin-bottom: 2.5em; margin-top:-0.5em;\">\n",
       "        <span style=\"background-color: hsl(120, 100.00%, 94.18%); opacity: 0.81\" title=\"0.053\">so</span><span style=\"opacity: 0.80\">, </span><span style=\"background-color: hsl(0, 100.00%, 97.33%); opacity: 0.80\" title=\"-0.017\">muslims</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 87.08%); opacity: 0.84\" title=\"-0.165\">are</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 92.25%); opacity: 0.82\" title=\"-0.080\">not</span><span style=\"opacity: 0.80\"> &quot;</span><span style=\"background-color: hsl(120, 100.00%, 94.98%); opacity: 0.81\" title=\"0.043\">our</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 92.05%); opacity: 0.82\" title=\"0.083\">people</span><span style=\"opacity: 0.80\">&quot;? </span><span style=\"background-color: hsl(120, 100.00%, 87.93%); opacity: 0.84\" title=\"0.150\">let</span><span style=\"opacity: 0.80\">&#x27;</span><span style=\"background-color: hsl(0, 100.00%, 86.32%); opacity: 0.84\" title=\"-0.179\">s</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 91.61%); opacity: 0.82\" title=\"-0.089\">say</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 86.34%); opacity: 0.84\" title=\"-0.179\">the</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 99.09%); opacity: 0.80\" title=\"-0.004\">number</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 90.86%); opacity: 0.82\" title=\"-0.101\">of</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 88.79%); opacity: 0.83\" title=\"-0.135\">black</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 88.78%); opacity: 0.83\" title=\"0.135\">violence</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 87.18%); opacity: 0.84\" title=\"-0.164\">equals</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 88.36%); opacity: 0.83\" title=\"-0.143\">that</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 96.10%); opacity: 0.81\" title=\"-0.030\">of</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 96.52%); opacity: 0.81\" title=\"0.025\">muslims</span><span style=\"opacity: 0.80\">; </span><span style=\"background-color: hsl(0, 100.00%, 92.19%); opacity: 0.82\" title=\"-0.081\">do</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 97.01%); opacity: 0.80\" title=\"0.020\">they</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 94.68%); opacity: 0.81\" title=\"-0.047\">then</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 95.10%); opacity: 0.81\" title=\"0.041\">become</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 91.28%); opacity: 0.82\" title=\"0.094\">not</span><span style=\"opacity: 0.80\"> &quot;</span><span style=\"background-color: hsl(120, 100.00%, 94.98%); opacity: 0.81\" title=\"0.043\">our</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 87.11%); opacity: 0.84\" title=\"0.165\">people</span><span style=\"opacity: 0.80\">? </span><span style=\"background-color: hsl(120, 100.00%, 95.16%); opacity: 0.81\" title=\"0.041\">when</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 60.00%); opacity: 1.00\" title=\"-0.832\">white</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 87.02%); opacity: 0.84\" title=\"-0.167\">violence</span><span style=\"opacity: 0.80\">, </span><span style=\"background-color: hsl(0, 100.00%, 93.68%); opacity: 0.81\" title=\"-0.060\">does</span><span style=\"opacity: 0.80\">; </span><span style=\"background-color: hsl(120, 100.00%, 95.17%); opacity: 0.81\" title=\"0.041\">do</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 97.01%); opacity: 0.80\" title=\"0.020\">they</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 94.68%); opacity: 0.81\" title=\"-0.047\">then</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 95.10%); opacity: 0.81\" title=\"0.041\">become</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 91.28%); opacity: 0.82\" title=\"0.094\">not</span><span style=\"opacity: 0.80\"> &quot;</span><span style=\"background-color: hsl(120, 100.00%, 94.98%); opacity: 0.81\" title=\"0.043\">our</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 91.01%); opacity: 0.82\" title=\"0.099\">people</span><span style=\"opacity: 0.80\">&quot;?\r\n",
       "</span><span style=\"background-color: hsl(0, 100.00%, 91.30%); opacity: 0.82\" title=\"-0.094\">i</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 91.76%); opacity: 0.82\" title=\"-0.087\">believe</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 88.54%); opacity: 0.83\" title=\"0.140\">it</span><span style=\"opacity: 0.80\">&#x27;</span><span style=\"background-color: hsl(0, 100.00%, 79.93%); opacity: 0.87\" title=\"-0.311\">s</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 79.06%); opacity: 0.88\" title=\"-0.330\">spelled</span><span style=\"opacity: 0.80\">: &quot;</span><span style=\"background-color: hsl(0, 100.00%, 97.85%); opacity: 0.80\" title=\"-0.013\">habeas</span><span style=\"opacity: 0.80\">&quot;</span>\n",
       "    </p>\n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate the lime TextExplainer model\n",
    "text_model_log = TextExplainer(random_state=1)\n",
    "\n",
    "#select a comment to investigate\n",
    "text = test_df.loc[40972,'comment_text']\n",
    "\n",
    "# Fit the Textexplainer using the logistic model predicted probabilites\n",
    "text_model_log.fit(text,fittedgrid_log.predict_proba )\n",
    "text_model_log.show_prediction(target_names=['Non-toxic', 'Toxic'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I\\'m a liberal and I don\\'t deny any of that. I despise Nathan Bedford Forrest. I despise Woodrow Wilson and his fawning over Birth of a Nation, which revitalized the KKK in the 1920s, including right here in the city Denver and the state of Colorado. I despise that Wilson waged a war to allegedly make the world \"Safe for Democracy\" while black Americans were being segregated and being terrorized by white supremacist rioters and lynch mobs at home. I despise the racist DixieCrats who threw a tantrum over Fanny Lou Hamer\\'s Mississippi Freedom Democratic Party.\\r\\n\\r\\nThe difference between me and you is that I acknowledge these to purge them from my current party. You do it to deflect from the segregationist president and his white nationalist buddies that you cape for here every day.'"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df['comment_text'].values[87444]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "text2 = test_df.loc[92316,'comment_text']\n",
    "text2\n",
    "text3 = text2.replace(\"\\n\", \"\").replace(\"\\r\", \"\").replace(\"\\\\\", '' )\n",
    "text3 = \" No, CE, I am not a homosexual.  I'm a monogamous heterosexual and have been married to my \n",
    "lively (was going to type 'lovely' and made a typo,  actually that 'lively' works too) wife, Sally, for 54 years. \n",
    "I have personal friends who ARE homosexual and have had those friendships for forty years or more.  \n",
    "They are absolutely wonderful people and the sexual preference doesn't play any role in our friendship. \n",
    "I really couldn't care less about anyone's sexual preference or sexual relationships.  \n",
    "I'm an 'old fashioned' guy and feel your sex life and romantic relationships are YOUR business. \n",
    "I do know of instances where the condemnation of family has destroyed the lives of \n",
    "young homosexual men and women, and it saddens me.  \n",
    "IMO, it's possible to support the rights and welfare of homosexual persons without being a homosexual yourself.  \n",
    "In fact, I think it's part of being a decent person.Hope that answers your question...Gary Cru \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'More news outlets are deleting their commentary sites; the great liberal bastion the Toronto Star and CNN dropped theirs ages ago as they could not take criticism. Other outlets increasingly  only allow comments on safe topics. Others censor or ban anyone who upsets the apple cart by talking about sacred cows or elephants in the room: such as homosexuals and aids, or black crime, or overpaid civil servants,  Canadian Jews and Israel, or anything deemed politically incorrect. Of course it is okay to bash white Anglo saxon men or Muslims. But it is not okay to point out the  striking similarities between Orthodox Jews and Muslims and how they treat their women, or how a lot of Muslim men chase Christian and Jewish girls but we cant go near their girls. And it is not okay to talk about how only lower middle class Christian boys fight and die for Canada in te middle east wars while so many others hide out in elite schools. I wish some academics would address these issues objectively.'"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text4 = test_df.loc[96458,'comment_text']\n",
    "text4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>created_date</th>\n",
       "      <th>publication_id</th>\n",
       "      <th>article_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>funny</th>\n",
       "      <th>wow</th>\n",
       "      <th>sad</th>\n",
       "      <th>likes</th>\n",
       "      <th>...</th>\n",
       "      <th>other_disability</th>\n",
       "      <th>comment_text_clean</th>\n",
       "      <th>comment_text_clean_detokenize</th>\n",
       "      <th>Prediction_svc</th>\n",
       "      <th>Prediction_probability_svc</th>\n",
       "      <th>Prediction_log</th>\n",
       "      <th>Prediction_probability_log</th>\n",
       "      <th>eli5_log</th>\n",
       "      <th>Prediction_RF</th>\n",
       "      <th>Prediction_probability_RF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>38608</th>\n",
       "      <td>7038608</td>\n",
       "      <td>orange monkey? does that infer that obumma was...</td>\n",
       "      <td>2017-03-03 01:30:52.744094+00</td>\n",
       "      <td>21</td>\n",
       "      <td>316426</td>\n",
       "      <td>rejected</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[orange, monkey, , infer, obumma, stupid, blac...</td>\n",
       "      <td>orange monkey  infer obumma stupid black monkey</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999411</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999411</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.750160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41038</th>\n",
       "      <td>7041038</td>\n",
       "      <td>The reaction by Lilly white Oregon, both alt l...</td>\n",
       "      <td>2017-06-30 17:23:38.047544+00</td>\n",
       "      <td>13</td>\n",
       "      <td>350088</td>\n",
       "      <td>approved</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[reaction, lilly, white, oregon, , alt, left, ...</td>\n",
       "      <td>reaction lilly white oregon  alt left alt whit...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.670932</td>\n",
       "      <td>1</td>\n",
       "      <td>0.670932</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.209493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41262</th>\n",
       "      <td>7041262</td>\n",
       "      <td>if the City does not cut funding \\r\\nthen we t...</td>\n",
       "      <td>2017-03-28 22:40:17.362698+00</td>\n",
       "      <td>54</td>\n",
       "      <td>322763</td>\n",
       "      <td>approved</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[city, cut, funding, taxpayer, funding, boycot...</td>\n",
       "      <td>city cut funding taxpayer funding boycott para...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.814034</td>\n",
       "      <td>1</td>\n",
       "      <td>0.814034</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.240154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42625</th>\n",
       "      <td>7042625</td>\n",
       "      <td>Imagine if America wasn't filled with millions...</td>\n",
       "      <td>2017-07-11 00:22:29.488673+00</td>\n",
       "      <td>102</td>\n",
       "      <td>353772</td>\n",
       "      <td>rejected</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[imagine, america, filled, million, million, n...</td>\n",
       "      <td>imagine america filled million million negro  ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.534560</td>\n",
       "      <td>1</td>\n",
       "      <td>0.534560</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.320303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42744</th>\n",
       "      <td>7042744</td>\n",
       "      <td>Then there's kool-aid drinking \"journalists\" l...</td>\n",
       "      <td>2016-10-11 10:54:46.686403+00</td>\n",
       "      <td>22</td>\n",
       "      <td>147800</td>\n",
       "      <td>approved</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[koolaid, drinking, , journalist, , like, davi...</td>\n",
       "      <td>koolaid drinking  journalist  like david pelle...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.884540</td>\n",
       "      <td>1</td>\n",
       "      <td>0.884540</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.690377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43270</th>\n",
       "      <td>7043270</td>\n",
       "      <td>A person is a hypocrite if he tells someone no...</td>\n",
       "      <td>2017-01-02 16:35:16.116597+00</td>\n",
       "      <td>22</td>\n",
       "      <td>159208</td>\n",
       "      <td>approved</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[person, hypocrite, tell, someone, something, ...</td>\n",
       "      <td>person hypocrite tell someone something  look ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.954055</td>\n",
       "      <td>1</td>\n",
       "      <td>0.954055</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.360000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43302</th>\n",
       "      <td>7043302</td>\n",
       "      <td>Barry said nothing much during the Ferguson ri...</td>\n",
       "      <td>2017-08-17 01:28:37.023584+00</td>\n",
       "      <td>54</td>\n",
       "      <td>367344</td>\n",
       "      <td>rejected</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[barry, said, nothing, much, ferguson, riot, m...</td>\n",
       "      <td>barry said nothing much ferguson riot mob blac...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.780128</td>\n",
       "      <td>1</td>\n",
       "      <td>0.780128</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.310483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44013</th>\n",
       "      <td>7044013</td>\n",
       "      <td>Tired of watching football teams that are 70+ ...</td>\n",
       "      <td>2017-10-08 10:53:28.098384+00</td>\n",
       "      <td>105</td>\n",
       "      <td>386434</td>\n",
       "      <td>rejected</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[tired, watching, football, team, 70, , percen...</td>\n",
       "      <td>tired watching football team 70  percent black...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.994016</td>\n",
       "      <td>1</td>\n",
       "      <td>0.994016</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.570164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45272</th>\n",
       "      <td>7045272</td>\n",
       "      <td>The south rebelled in part because they feared...</td>\n",
       "      <td>2017-08-16 16:09:56.858059+00</td>\n",
       "      <td>105</td>\n",
       "      <td>366937</td>\n",
       "      <td>approved</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[south, rebelled, part, feared, bloody, slave,...</td>\n",
       "      <td>south rebelled part feared bloody slave revolt...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.538170</td>\n",
       "      <td>1</td>\n",
       "      <td>0.538170</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.090575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45332</th>\n",
       "      <td>7045332</td>\n",
       "      <td>run dmc's song is so appropriate here............</td>\n",
       "      <td>2017-09-21 16:36:29.628938+00</td>\n",
       "      <td>55</td>\n",
       "      <td>380108</td>\n",
       "      <td>approved</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[run, dmcs, song, appropriate, , , nigga, wond...</td>\n",
       "      <td>run dmcs song appropriate   nigga wonda nigga ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.597407</td>\n",
       "      <td>1</td>\n",
       "      <td>0.597407</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.365867</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 53 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id                                       comment_text  \\\n",
       "38608  7038608  orange monkey? does that infer that obumma was...   \n",
       "41038  7041038  The reaction by Lilly white Oregon, both alt l...   \n",
       "41262  7041262  if the City does not cut funding \\r\\nthen we t...   \n",
       "42625  7042625  Imagine if America wasn't filled with millions...   \n",
       "42744  7042744  Then there's kool-aid drinking \"journalists\" l...   \n",
       "43270  7043270  A person is a hypocrite if he tells someone no...   \n",
       "43302  7043302  Barry said nothing much during the Ferguson ri...   \n",
       "44013  7044013  Tired of watching football teams that are 70+ ...   \n",
       "45272  7045272  The south rebelled in part because they feared...   \n",
       "45332  7045332  run dmc's song is so appropriate here............   \n",
       "\n",
       "                        created_date  publication_id  article_id    rating  \\\n",
       "38608  2017-03-03 01:30:52.744094+00              21      316426  rejected   \n",
       "41038  2017-06-30 17:23:38.047544+00              13      350088  approved   \n",
       "41262  2017-03-28 22:40:17.362698+00              54      322763  approved   \n",
       "42625  2017-07-11 00:22:29.488673+00             102      353772  rejected   \n",
       "42744  2016-10-11 10:54:46.686403+00              22      147800  approved   \n",
       "43270  2017-01-02 16:35:16.116597+00              22      159208  approved   \n",
       "43302  2017-08-17 01:28:37.023584+00              54      367344  rejected   \n",
       "44013  2017-10-08 10:53:28.098384+00             105      386434  rejected   \n",
       "45272  2017-08-16 16:09:56.858059+00             105      366937  approved   \n",
       "45332  2017-09-21 16:36:29.628938+00              55      380108  approved   \n",
       "\n",
       "       funny  wow  sad  likes  ...  other_disability  \\\n",
       "38608      0    0    0      0  ...                 0   \n",
       "41038      0    0    0      0  ...                 0   \n",
       "41262      0    0    1      8  ...                 0   \n",
       "42625      0    0    0      0  ...                 0   \n",
       "42744      0    0    0      1  ...                 0   \n",
       "43270      0    0    0      0  ...                 0   \n",
       "43302      0    0    0      0  ...                 0   \n",
       "44013      0    0    0      0  ...                 0   \n",
       "45272      0    0    0      0  ...                 0   \n",
       "45332      0    0    0      0  ...                 0   \n",
       "\n",
       "                                      comment_text_clean  \\\n",
       "38608  [orange, monkey, , infer, obumma, stupid, blac...   \n",
       "41038  [reaction, lilly, white, oregon, , alt, left, ...   \n",
       "41262  [city, cut, funding, taxpayer, funding, boycot...   \n",
       "42625  [imagine, america, filled, million, million, n...   \n",
       "42744  [koolaid, drinking, , journalist, , like, davi...   \n",
       "43270  [person, hypocrite, tell, someone, something, ...   \n",
       "43302  [barry, said, nothing, much, ferguson, riot, m...   \n",
       "44013  [tired, watching, football, team, 70, , percen...   \n",
       "45272  [south, rebelled, part, feared, bloody, slave,...   \n",
       "45332  [run, dmcs, song, appropriate, , , nigga, wond...   \n",
       "\n",
       "                           comment_text_clean_detokenize  Prediction_svc  \\\n",
       "38608    orange monkey  infer obumma stupid black monkey               1   \n",
       "41038  reaction lilly white oregon  alt left alt whit...               1   \n",
       "41262  city cut funding taxpayer funding boycott para...               1   \n",
       "42625  imagine america filled million million negro  ...               1   \n",
       "42744  koolaid drinking  journalist  like david pelle...               1   \n",
       "43270  person hypocrite tell someone something  look ...               1   \n",
       "43302  barry said nothing much ferguson riot mob blac...               1   \n",
       "44013  tired watching football team 70  percent black...               1   \n",
       "45272  south rebelled part feared bloody slave revolt...               1   \n",
       "45332  run dmcs song appropriate   nigga wonda nigga ...               1   \n",
       "\n",
       "       Prediction_probability_svc  Prediction_log  Prediction_probability_log  \\\n",
       "38608                    0.999411               1                    0.999411   \n",
       "41038                    0.670932               1                    0.670932   \n",
       "41262                    0.814034               1                    0.814034   \n",
       "42625                    0.534560               1                    0.534560   \n",
       "42744                    0.884540               1                    0.884540   \n",
       "43270                    0.954055               1                    0.954055   \n",
       "43302                    0.780128               1                    0.780128   \n",
       "44013                    0.994016               1                    0.994016   \n",
       "45272                    0.538170               1                    0.538170   \n",
       "45332                    0.597407               1                    0.597407   \n",
       "\n",
       "       eli5_log  Prediction_RF  Prediction_probability_RF  \n",
       "38608         1              1                   0.750160  \n",
       "41038         1              0                   0.209493  \n",
       "41262         1              0                   0.240154  \n",
       "42625         1              0                   0.320303  \n",
       "42744         1              1                   0.690377  \n",
       "43270         1              0                   0.360000  \n",
       "43302         1              0                   0.310483  \n",
       "44013         1              1                   0.570164  \n",
       "45272         1              0                   0.090575  \n",
       "45332         1              0                   0.365867  \n",
       "\n",
       "[10 rows x 53 columns]"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df[(test_df['target'] == 1) & (test_df['Prediction_log'] == 1) & (test_df['black']==1)].iloc[60:70]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Imagine if America wasn't filled with millions and millions of Negros. \\r\\nThey are an indisputable black mark on the history of this country.\""
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.loc[42625,'comment_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'how many of you commenters have garbage piled high in your yard, bald tires, dead batteries, rotten pallets, car parts, blah blah blah. this town is a pigpen. drive around and look for yourself, its pathetic.'"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.loc[4, 'comment_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load keras model\n",
    "keras_model = load_model('NN_model/baseline-LSTM.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the lime TextExplainer model\n",
    "text_model_log = TextExplainer(random_state=1)\n",
    "\n",
    "#select a comment to investigate\n",
    "text = test_df.loc[40972,'comment_text']\n",
    "\n",
    "# Fit the Textexplainer using the logistic model predicted probabilites\n",
    "text_model_log.fit(text,keras_model.predict[:,1])\n",
    "text_model_log.show_prediction(target_names=['Non-toxic', 'Toxic'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
