{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling - ML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal for our work is to not only train a model to identify toxic comments, but to do so while reducing bias.\n",
    "Bias in this task can be viewed as the situation where certain identies such as 'Black', 'Muslim', 'Gay' e.t.c, begin triggering toxic classification for comments they are in, even when the comment is actually positive. This is a key issue in toxic comment classification. \n",
    "\n",
    "The goal of the [jigsaw unintended Bias in Toxicity Classification](https://www.kaggle.com/c/jigsaw-unintended-bias-in-toxicity-classification/data) Kaggle challenge was to reduce this bias via a newly developed submetric which we have defined below.\n",
    "\n",
    "**Note: The goal of the model is simply to predict the toxicity score of a model.** \n",
    "\n",
    "The bias weighted ROC metric below is calulated by taking segmenting the the dataset into identity subgroups by using the provided identity labels and then calculating the subgroup metrics.\n",
    "\n",
    "In this notebook we have trained some baseline models which we will use as a baseline to compare our neural network against. \n",
    "\n",
    "### Metrics:\n",
    "\n",
    "In addition to accuracy we will observe the below metrics for our models\n",
    "\n",
    "#### Overall ROC-AUC:\n",
    "\n",
    "This is the standard ROC-AUC for the full evaluation set. In other words this is the area under the Reciever Operating Characteristic curve. It compares the true positive and false positive rates of a binary model.\n",
    "\n",
    "#### Subgroup ROC-AUC:\n",
    "\n",
    "Here, we restrict the data set to only the examples that mention the specific identity subgroup. A low value in this metric means the model does a poor job of distinguishing between toxic and non-toxic comments that mention the identity.\n",
    "\n",
    "#### BPSN AUC:\n",
    "\n",
    "BPSN (Background Positive, Subgroup Negative) AUC: Here, we restrict the test set to the non-toxic examples that mention the identity and the toxic examples that do not. A low value in this metric means that the model confuses non-toxic examples that mention the identity with toxic examples that do not, likely meaning that the model predicts higher toxicity scores than it should for non-toxic examples mentioning the identity.\n",
    "\n",
    "#### BNSP AUC:\n",
    "\n",
    "BNSP (Background Negative, Subgroup Positive) AUC: Here, we restrict the test set to the toxic examples that mention the identity and the non-toxic examples that do not. A low value here means that the model confuses toxic examples that mention the identity with non-toxic examples that do not, likely meaning that the model predicts lower toxicity scores than it should for toxic examples mentioning the identity.\n",
    "\n",
    "\n",
    "#### Generalized Mean of Bias AUCs\n",
    "To combine the per-identity Bias AUCs into one overall measure, we calculate their generalized mean as defined below:\n",
    "\n",
    "$M_p(m_s) = \\left(\\frac{1}{N} \\sum_{s=1}^{N} m_s^p\\right)^\\frac{1}{p}$\n",
    "\n",
    "Where:\n",
    "\n",
    "$M_p$ = the $p$th power-mean function\n",
    "\n",
    "$m_s$ = the bias metric $m$ calulated for subgroup $s$\n",
    "\n",
    "$N$ = number of identity subgroups\n",
    "\n",
    "For this competition, JigsawAI use a p value of -5 to encourage competitors to improve the model for the identity subgroups with the lowest model performance.\n",
    "\n",
    "### Final Metric\n",
    "We combine the overall AUC with the generalized mean of the Bias AUCs to calculate the final model score:\n",
    "\n",
    "$score = w_0 AUC_{overall} + \\sum_{a=1}^{A} w_a M_p(m_{s,a})$\n",
    "\n",
    "$A$ = number of submetrics (3)\n",
    "\n",
    "$m_{s,a}$ = bias metric for identity subgroup $s$ using submetric $a$\n",
    "\n",
    "$w_a$ = $a$ weighting for the relative importance of each submetric; all four $w$ values set to 0.25\n",
    "\n",
    "\n",
    "### Process:\n",
    "\n",
    "#### Classical ML models\n",
    "This is primarily an NLP task, our X feature matrix will be based off the text from online comments. We have defined a pre-processing pipeline in the 'preprocessing.ipynb' notebook to use for our our ML classifiers and a seperate pre-processing pipeline for the neural network models we are planning on training.\n",
    "\n",
    "From the classic ML classifer models, we intend to use the following models - our base word embedding technique will be TF-IDF: \n",
    "\n",
    "   * Logistic Regression\n",
    "   * SVM\n",
    "   * Random Forest\n",
    " \n",
    "   \n",
    "We will carry out hyperparameter optimization for each model and calculate the metrics for each.\n",
    "\n",
    "#### Neural Networks\n",
    "*see NN_model.ipynb*\n",
    "\n",
    "We will also train a neural network to answer this problem. We will start with a basic LSTM model which will be made of:\n",
    "    \n",
    "   * LSTM layers to read through the data\n",
    "   * Dense layers\n",
    "   * Output layer using sigmoid for the classes\n",
    "   \n",
    "We will then seek to improve this LSTM by creating a Bidrectional LSTM (BiLSTM) which we believe will improve accuracy by reading input sequences in both directions. If time allows we will also attempt to include a simple attention mechanism.\n",
    "\n",
    "The NN models will use Glove 840B 300d word embeddings. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import string\n",
    "import contractions\n",
    "tqdm.pandas()\n",
    "import gc\n",
    "import operator\n",
    "pd.options.display.float_format = '{:,.3f}'.format\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 1: Apply pre-processing to text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load train_data\n",
    "train_df = pd.read_csv('data/train_clean.csv')\n",
    "\n",
    "# Load in test data\n",
    "test_df = pd.read_csv('data/test_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.rename({'toxicity':'target'}, axis=1, inplace=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the unneeded columns\n",
    "train_df = train_df.iloc[:,1:]\n",
    "test_df = test_df.iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this cell we define the function that pre-processes our text\n",
    "\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
    "import contractions\n",
    "import string\n",
    "\n",
    "def text_cleaner(df, col_name, clean_col_name):\n",
    "    '''\n",
    "    Text pre-processing pipeline, we lemmatize words, expand contractions, remove common stop words, apply lower case,\n",
    "    tokenize, and delete punctuation. All functions use apply and list comprehension for speed benefit.\n",
    "   \n",
    "    INPUT:\n",
    "    df = name of dataframe\n",
    "    col_name = name of column to pre-process\n",
    "    clean_col_name = name of new cleaned_column\n",
    "   \n",
    "    OUTPUT:\n",
    "    None - changes are made directly to dataframe\n",
    "    \n",
    "    '''\n",
    "\n",
    "    # Lemmatize helper functions\n",
    "    # Lemmatize nouns\n",
    "    def lemmatize_text_noun(text):\n",
    "        return [lemmatizer.lemmatize(w, pos='n') for w in text]\n",
    "    \n",
    "    # Lemmatize verbs\n",
    "    def lemmatize_text_verb(text):\n",
    "        return [lemmatizer.lemmatize(w, pos='v') for w in text]\n",
    "    # Lemmatize adjectives\n",
    "    def lemmatize_text_adj(text):\n",
    "        return [lemmatizer.lemmatize(w, pos='a') for w in text]\n",
    "\n",
    "    # Lemmatize adverbs\n",
    "    def lemmatize_text_adv(text):\n",
    "        return [lemmatizer.lemmatize(w, pos='r') for w in text]\n",
    "    \n",
    "    # Expand contraction method\n",
    "    def contraction_expand(text):\n",
    "        return contractions.fix(text)\n",
    "    \n",
    "    # To lower case.\n",
    "    df[clean_col_name] = df[col_name].apply(lambda x: x.lower())\n",
    "    \n",
    "    # Expand contractions\n",
    "    df[clean_col_name] = df[clean_col_name].apply(lambda x: contraction_expand(x))\n",
    "    \n",
    "    #Tokenize:\n",
    "    tokenizer = TweetTokenizer(reduce_len=True)\n",
    "    df[clean_col_name] = df[clean_col_name].apply(lambda x: tokenizer.tokenize(x))\n",
    "   \n",
    "    \n",
    "    #Remove Stop words\n",
    "    stop_words = stopwords.words('english')\n",
    "    df[clean_col_name] = df[clean_col_name].apply(lambda x: [item for item in x if item not in stop_words])\n",
    "    \n",
    "    #Delete punctuation\n",
    "    punc_table = str.maketrans('', '', string.punctuation)\n",
    "    df[clean_col_name] = df[clean_col_name].apply(lambda x: [item.translate(punc_table) for item in x])\n",
    "    \n",
    "    # LEMMATIZATION\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    \n",
    "    df[clean_col_name] = df[clean_col_name].apply(lemmatize_text_noun)\n",
    "    df[clean_col_name] = df[clean_col_name].apply(lemmatize_text_verb)\n",
    "    df[clean_col_name] = df[clean_col_name].apply(lemmatize_text_adj)\n",
    "    df[clean_col_name] = df[clean_col_name].apply(lemmatize_text_adv)\n",
    "    \n",
    "    \n",
    "    return None\n",
    "\n",
    "\n",
    "def detokenizer(df, col_name):\n",
    "    detokenizer = TreebankWordDetokenizer()\n",
    "    df[col_name+'_detokenize'] = df[col_name].apply(lambda x: detokenizer.detokenize(x))\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 19min 18s, sys: 8.28 s, total: 19min 26s\n",
      "Wall time: 19min 30s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Run the cleaner func on train data\n",
    "text_cleaner(train_df, 'comment_text', 'comment_text_clean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "# Run the same cleaner on the training data\n",
    "text_cleaner(test_df, 'comment_text', 'comment_text_clean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 34s, sys: 803 ms, total: 3min 35s\n",
      "Wall time: 3min 37s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "detokenizer(train_df,'comment_text_clean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 23.9 s, sys: 194 ms, total: 24.1 s\n",
      "Wall time: 24.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# detokenize the test data\n",
    "detokenizer(test_df, 'comment_text_clean')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 2: Modelling\n",
    "\n",
    "The data has been pre-processed for our models. We can now begin model training.\n",
    "\n",
    "We have a seperate test dataset that will be kept aside for testing only once we have an ideal model. For hyperparameter optimizing we will use Scikit-learn's GridSearchCV. \n",
    "\n",
    "After we have fitted a model and predicted results, we can then append the predictions to the dataframe and calculate the subgroup AUCs and the final weighted metric . \n",
    "\n",
    "#### Defining subgroup AUC metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "SUBGROUP_AUC = 'subgroup_auc'\n",
    "BPSN_AUC = 'bpsn_auc'  # stands for background positive, subgroup negative\n",
    "BNSP_AUC = 'bnsp_auc'  # stands for background negative, subgroup positive\n",
    "\n",
    "\n",
    "# These calculations have been provided by Jigsaw AI for scoring based on the metrics of the kaggle competition\n",
    "# https://www.kaggle.com/c/jigsaw-unintended-bias-in-toxicity-classification/overview/evaluation\n",
    "\n",
    "# They work by filtering the relevant dataframe into specific subgroups and using the roc_auc_score metric from sklearn.\n",
    "\n",
    "def compute_auc(y_true, y_pred):\n",
    "    try:\n",
    "        return metrics.roc_auc_score(y_true, y_pred)\n",
    "    except ValueError:\n",
    "        return np.nan\n",
    "\n",
    "def compute_subgroup_auc(df, subgroup, label, model_name):\n",
    "    subgroup_examples = df[df[subgroup]]\n",
    "    return compute_auc(subgroup_examples[label], subgroup_examples[model_name])\n",
    "\n",
    "def compute_bpsn_auc(df, subgroup, label, model_name):\n",
    "    \"\"\"Computes the AUC of the within-subgroup negative examples and the background positive examples.\"\"\"\n",
    "    subgroup_negative_examples = df.loc[df[subgroup] & ~df[label]]\n",
    "    non_subgroup_positive_examples = df.loc[~df[subgroup] & df[label]]\n",
    "    examples = subgroup_negative_examples.append(non_subgroup_positive_examples)\n",
    "    return compute_auc(examples[label], examples[model_name])\n",
    "\n",
    "def compute_bnsp_auc(df, subgroup, label, model_name):\n",
    "    \"\"\"Computes the AUC of the within-subgroup positive examples and the background negative examples.\"\"\"\n",
    "    subgroup_positive_examples = df.loc[df[subgroup] & df[label]]\n",
    "    non_subgroup_negative_examples = df.loc[~df[subgroup] & ~df[label]]\n",
    "    examples = subgroup_positive_examples.append(non_subgroup_negative_examples)\n",
    "    return compute_auc(examples[label], examples[model_name])\n",
    "\n",
    "def compute_bias_metrics_for_model(dataset,\n",
    "                                   subgroups,\n",
    "                                   model,\n",
    "                                   label_col,\n",
    "                                   include_asegs=False):\n",
    "    \"\"\"Computes per-subgroup metrics for all subgroups and one model.\"\"\"\n",
    "    records = []\n",
    "    for subgroup in subgroups:\n",
    "        record = {\n",
    "            'subgroup': subgroup,\n",
    "            'subgroup_size': len(dataset.loc[dataset[subgroup]])\n",
    "        }\n",
    "        record[SUBGROUP_AUC] = compute_subgroup_auc(dataset, subgroup, label_col, model)\n",
    "        record[BPSN_AUC] = compute_bpsn_auc(dataset, subgroup, label_col, model)\n",
    "        record[BNSP_AUC] = compute_bnsp_auc(dataset, subgroup, label_col, model)\n",
    "        records.append(record)\n",
    "    return pd.DataFrame(records).sort_values('subgroup_auc', ascending=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These calculations have been provided by Jigsaw AI for scoring based on the metrics of the kaggle competition\n",
    "# https://www.kaggle.com/c/jigsaw-unintended-bias-in-toxicity-classification/overview/evaluation\n",
    "\n",
    "# They work by filtering the relevant dataframe into specific subgroups and using the roc_auc_score metric from sklearn.\n",
    "\n",
    "def calculate_overall_auc(df, model_name):\n",
    "    true_labels = df[TOXICITY_COLUMN]\n",
    "    predicted_labels = df[model_name]\n",
    "    return metrics.roc_auc_score(true_labels, predicted_labels)\n",
    "\n",
    "def power_mean(series, p):\n",
    "    total = sum(np.power(series, p))\n",
    "    return np.power(total / len(series), 1 / p)\n",
    "\n",
    "def get_final_metric(bias_df, overall_auc, POWER=-5, OVERALL_MODEL_WEIGHT=0.25):\n",
    "    bias_score = np.average([\n",
    "        power_mean(bias_df[SUBGROUP_AUC], POWER),\n",
    "        power_mean(bias_df[BPSN_AUC], POWER),\n",
    "        power_mean(bias_df[BNSP_AUC], POWER)\n",
    "    ])\n",
    "    return (OVERALL_MODEL_WEIGHT * overall_auc) + ((1 - OVERALL_MODEL_WEIGHT) * bias_score)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression\n",
    "\n",
    "We will use Grid Search Cross validation to optimize our hyperparameters on the training set. We will then fit the best estimator and then predict on the test set and calculate relevent metrics.\n",
    "\n",
    "Because the subgroup ROCs are calculated post prediction and require predictions to be appended to a dataframe, we cannot actually pass the metrics into the scoring function of scikit-learn's gridsearchCV(). Instead we will just test the models on accuracy and total ROC-AUC and then refitting the grid-search on the model with the best ROC-AUC as a proxy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.65 ms, sys: 3.6 ms, total: 5.25 ms\n",
      "Wall time: 8.3 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVC\n",
    "#no scaling data is already transformed\n",
    "\n",
    "# Instantiate the tokenizer to use in the vectorizer\n",
    "tweet_tokenizer = TweetTokenizer(reduce_len=True)\n",
    "\n",
    "# Instantiate the vectorizer, we will pass in the TweetTokenizer() from nltk \n",
    "tfid_vec_2 = TfidfVectorizer(lowercase=False, tokenizer = tweet_tokenizer.tokenize)\n",
    "\n",
    "# define pipeline\n",
    "pipeline = Pipeline([('tf-idf', tfid_vec_2), \n",
    "                     ('model', SVC())])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "# Define scoring functions\n",
    "scorers = {'AUC': 'roc_auc', 'Accuracy': make_scorer(accuracy_score)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define parameters\n",
    "param_grid_log = [{'model': [LogisticRegression()], 'tf-idf': [tfid_vec_2], \n",
    "                   'model__penalty': ['l1', 'l2'],\n",
    "                   'model__C': [.001, 0.01, 0.1, 1, 10, 100]}]\n",
    "\n",
    "# Setting refit='AUC', refits an estimator on the whole dataset with the\n",
    "# parameter setting that has the best cross-validated AUC score, i.e it finds the params that gives the best scores\n",
    "# then refits using the ones that give the best AUC. \n",
    "grid_log = GridSearchCV(pipeline, param_grid_log, cv=5, scoring=scorers, refit='AUC', \n",
    "                        return_train_score=True, n_jobs=-1)\n",
    "\n",
    "fittedgrid_log = grid_log.fit(train_df['comment_text_clean_detokenize'], train_df['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib\n",
    "# Save best estimator to file\n",
    "joblib.dump(fittedgrid.best_estimator_, 'saved_models/best_log_reg.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run this to load the model if required\n",
    "from sklearn.externals import joblib\n",
    "from joblib import load\n",
    "fittedgrid_log = load('saved_models/best_log_reg.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get accuracy scores\n",
    "train_accuracy_log = fittedgrid_log.score(train_df['comment_text_clean_detokenize'], y_train)\n",
    "test_accuracy_log = fittedgrid_log.score(test_df['comment_text_clean_detokenize'], y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict train and test values\n",
    "y_train_pred = fittedgrid_log.predict(train_df['comment_text_clean_detokenize'])\n",
    "y_test_pred = fittedgrid_log.predict(test_df['comment_text_clean_detokenize'])\n",
    "\n",
    "# Get the actual probabilities\n",
    "y_train_pred_prob_log = fittedgrid_log.predict_proba(train_df['comment_text_clean_detokenize'])\n",
    "y_test_pred_prob_log = fittedgrid_log.predict_proba(test_df['comment_text_clean_detokenize'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.97    179192\n",
      "           1       0.76      0.50      0.60     15448\n",
      "\n",
      "    accuracy                           0.95    194640\n",
      "   macro avg       0.86      0.74      0.79    194640\n",
      "weighted avg       0.94      0.95      0.94    194640\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Confusion Matrix and Classification Report, we want to store the F1 Score.\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# store the precision, recall, and f1 score for later and print the classification report\n",
    "log_precision = precision_score(y_test, y_test_pred)\n",
    "log_recall = recall_score(y_test, y_test_pred)\n",
    "log_f1 = f1_score(y_test, y_test_pred)\n",
    "\n",
    "print(classification_report(y_test, y_test_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area under curve (AUC):0.9408323249419588\n"
     ]
    }
   ],
   "source": [
    "# Lets plot out the regular ROC curve - code taken from Model-Evaluation class. \n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "\n",
    "fprs, tprs, thresholds = roc_curve(y_test, y_test_pred_prob_log[:,1])\n",
    "roc_auc = roc_auc_score(y_test, y_test_pred_prob_log[:,1])\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fprs, tprs, color='darkorange',\n",
    "         lw=2, label='AUC = %0.2f' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=1, linestyle='--')\n",
    "plt.xlabel('False Positive Rate (FPR)')\n",
    "plt.ylabel('True Positive Rate (TPR)')\n",
    "plt.title('ROC Curve for Logistic Regression')\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()\n",
    "\n",
    "print(f'Area under curve (AUC):{roc_auc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append preds and probabilities to train and valid dfs\n",
    "train_df['Prediction_log'] = y_train_pred\n",
    "train_df['Prediction_probability_log'] = y_train_pred_prob[:, 1]\n",
    "test_df['Prediction_log'] = y_test_pred\n",
    "test_df['Prediction_probability_log'] = y_test_pred_prob[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identity columns used to calculate subgroup AUC\n",
    "identity_columns = [\n",
    "    'male', 'female', 'homosexual_gay_or_lesbian', 'christian', 'jewish',\n",
    "    'muslim', 'black', 'white', 'psychiatric_or_mental_illness']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in identity_columns + ['target']:\n",
    "    train_df[col] = np.where(train_df[col] >= 0.5, True, False)\n",
    "    test_df[col] = np.where(test_df[col] >= 0.5, True, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the AUC metrics \n",
    "\n",
    "# Set parameters for the logistic model \n",
    "SUBGROUP_AUC = 'subgroup_auc'\n",
    "BPSN_AUC = 'bpsn_auc'  # stands for background positive, subgroup negative\n",
    "BNSP_AUC = 'bnsp_auc'\n",
    "\n",
    "MODEL_NAME = 'Prediction_log'\n",
    "TOXICITY_COLUMN = 'target'\n",
    "\n",
    "# generate the subgroup bias dataframes for the logistic model\n",
    "log_bias_metrics_df_train = compute_bias_metrics_for_model(train_df, identity_columns, MODEL_NAME, TOXICITY_COLUMN)\n",
    "log_final_metric_train = get_final_metric(log_bias_metrics_df_train, calculate_overall_auc(train_df, MODEL_NAME))\n",
    "\n",
    "# generate the final metrics \n",
    "log_bias_metrics_df_test = compute_bias_metrics_for_model(test_df, identity_columns, MODEL_NAME, TOXICITY_COLUMN)\n",
    "log_final_metric_test = get_final_metric(log_bias_metrics_df_test, calculate_overall_auc(test_df, MODEL_NAME))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subgroup</th>\n",
       "      <th>subgroup_size</th>\n",
       "      <th>subgroup_auc</th>\n",
       "      <th>bpsn_auc</th>\n",
       "      <th>bnsp_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>homosexual_gay_or_lesbian</td>\n",
       "      <td>1065</td>\n",
       "      <td>0.655</td>\n",
       "      <td>0.682</td>\n",
       "      <td>0.714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>muslim</td>\n",
       "      <td>2040</td>\n",
       "      <td>0.665</td>\n",
       "      <td>0.719</td>\n",
       "      <td>0.689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>christian</td>\n",
       "      <td>4226</td>\n",
       "      <td>0.667</td>\n",
       "      <td>0.739</td>\n",
       "      <td>0.671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>jewish</td>\n",
       "      <td>835</td>\n",
       "      <td>0.678</td>\n",
       "      <td>0.719</td>\n",
       "      <td>0.700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>black</td>\n",
       "      <td>1519</td>\n",
       "      <td>0.683</td>\n",
       "      <td>0.687</td>\n",
       "      <td>0.737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>white</td>\n",
       "      <td>2452</td>\n",
       "      <td>0.687</td>\n",
       "      <td>0.701</td>\n",
       "      <td>0.728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>male</td>\n",
       "      <td>4386</td>\n",
       "      <td>0.713</td>\n",
       "      <td>0.729</td>\n",
       "      <td>0.726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>psychiatric_or_mental_illness</td>\n",
       "      <td>511</td>\n",
       "      <td>0.715</td>\n",
       "      <td>0.722</td>\n",
       "      <td>0.734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>female</td>\n",
       "      <td>5155</td>\n",
       "      <td>0.719</td>\n",
       "      <td>0.734</td>\n",
       "      <td>0.727</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        subgroup  subgroup_size  subgroup_auc  bpsn_auc  \\\n",
       "2      homosexual_gay_or_lesbian           1065         0.655     0.682   \n",
       "5                         muslim           2040         0.665     0.719   \n",
       "3                      christian           4226         0.667     0.739   \n",
       "4                         jewish            835         0.678     0.719   \n",
       "6                          black           1519         0.683     0.687   \n",
       "7                          white           2452         0.687     0.701   \n",
       "0                           male           4386         0.713     0.729   \n",
       "8  psychiatric_or_mental_illness            511         0.715     0.722   \n",
       "1                         female           5155         0.719     0.734   \n",
       "\n",
       "   bnsp_auc  \n",
       "2     0.714  \n",
       "5     0.689  \n",
       "3     0.671  \n",
       "4     0.700  \n",
       "6     0.737  \n",
       "7     0.728  \n",
       "0     0.726  \n",
       "8     0.734  \n",
       "1     0.727  "
      ]
     },
     "execution_count": 426,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_bias_metrics_df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_accuracy:0.9443495778652693\n",
      "train final weighted AUC:0.7197198017038468\n",
      "test_accuracy:0.9441789971228935\n",
      "test final weighted AUC::0.7126513014416012\n"
     ]
    }
   ],
   "source": [
    "print(f'train_accuracy:{train_accuracy}')\n",
    "print(f'train final weighted AUC:{get_final_metric(log_bias_metrics_df_train, calculate_overall_auc(train_df, MODEL_NAME))}')\n",
    "print(f'test_accuracy:{test_accuracy}')\n",
    "print(f'test final weighted AUC::{get_final_metric(log_bias_metrics_df_test, calculate_overall_auc(test_df, MODEL_NAME))}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Evaluation:\n",
    "\n",
    "The logistic regression performed well on pure accuracy, with a train accuracy of 95.38% and 94.96% test accuracy. What is also positive to see is that our hyperparameter optimization has led to a model which does not overfit excessively. \n",
    "\n",
    "However when we look at the weighted subgroup AUC metric, the 71.9% train score and 71.5% test score show that the model did have a tendency towards biased predictions for certain subgroup. In comparison, the benchmark CNN that was provided had a weighted AUC score of 88.35% albeit just on a validation set. For example we can see that for the 'black' identity BPSN AUC was relatively low, suggesting the model is likely overweighting mentions of the 'black' identity with toxicity. \n",
    "\n",
    "In addition, we can also see that the recall score for the positive class was low. We believe that this is due to the large class imbalance within the data set, where only 8% of cases were toxic. As a result, the model had relativley little information to train on for actual toxic examples, lessening its ability to identify all cases of toxicity. This will likely be the case for all the models trained here and is something we would look to address as part of further study.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost\n",
    "\n",
    "We will now carry out a similar process with the XGBoost classifier,\n",
    "\n",
    "#### Grid searching on a subset of data\n",
    "\n",
    "Given the length of time taken to grid search using XGBoost, we will run a gridsearch on a subset of our dataset by taking a new train test split. We will then use the results there as a proxy for the optimal parameters for our full dataset.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# Create a new split of the training dataframe to use for this reduced test. \n",
    "# we will not need the remainder. We will take 1/4 of the total data set\n",
    "remainder, reduced_df = train_test_split(train_df, test_size=0.25, stratify=train_df['target'], random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 27 candidates, totalling 81 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:  9.7min\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed: 19.2min\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed: 21.3min\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed: 40.4min\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed: 50.9min\n",
      "[Parallel(n_jobs=-1)]: Done  45 tasks      | elapsed: 61.1min\n",
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed: 71.7min\n",
      "[Parallel(n_jobs=-1)]: Done  75 out of  81 | elapsed: 100.7min remaining:  8.1min\n",
      "[Parallel(n_jobs=-1)]: Done  81 out of  81 | elapsed: 104.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 14min 39s, sys: 1min 17s, total: 15min 56s\n",
      "Wall time: 1h 48min 25s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Grid search applies tfid_vec_2 to all models. XGB is a boosting method so the idea is to train a sequence of weak models.\n",
    "# we are using a decision tree implementation so this means we will train a sequence of low depth trees.\n",
    "# one of the key hyperparameters is therefore learning rate. \n",
    "# min_child_weight controls what the minimum weight a child can have to classify it as a final node. Higher values mean\n",
    "# more conservative decision boundaries\n",
    "# gamma sets a minimum loss reduction amount. If drawing a class boundary at a certain point does not breach this threshold\n",
    "# the model will not draw the boundary.\n",
    "\n",
    "param_grid_xgb = [{'model': [XGBClassifier()], 'tf-idf': [tfid_vec_2],\n",
    "                    \"model__learning_rate\"    : [ 0.15, 0.30, 0.45 ] , #default 0.3\n",
    "                     \"model__min_child_weight\" : [ 1, 3, 7 ], #1 is default\n",
    "                     \"model__gamma\"            : [ 0.0, 0.2, 0.4 ], #default is 0 \n",
    "                      }]\n",
    "\n",
    "reduced_grid_xgb = GridSearchCV(pipeline, param_grid_xgb, scoring=scorers, cv=3, refit='AUC',\n",
    "                       return_train_score=True, n_jobs=-1, verbose=10)\n",
    "\n",
    "reduced_grid_xgb = reduced_grid_xgb.fit(reduced_df['comment_text_clean_detokenize'], reduced_df['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('tf-idf',\n",
       "                 TfidfVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.float64'>,\n",
       "                                 encoding='utf-8', input='content',\n",
       "                                 lowercase=False, max_df=1.0, max_features=None,\n",
       "                                 min_df=1, ngram_range=(1, 1), norm='l2',\n",
       "                                 preprocessor=None, smooth_idf=True,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 sublinear_tf=False,\n",
       "                                 token_pattern...\n",
       "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
       "                               colsample_bylevel=1, colsample_bynode=1,\n",
       "                               colsample_bytree=1, gamma=0.4,\n",
       "                               learning_rate=0.45, max_delta_step=0,\n",
       "                               max_depth=3, min_child_weight=3, missing=None,\n",
       "                               n_estimators=100, n_jobs=1, nthread=None,\n",
       "                               objective='binary:logistic', random_state=0,\n",
       "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "                               seed=None, silent=None, subsample=1,\n",
       "                               verbosity=1))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Gives the model with the best AUC score\n",
    "reduced_grid_xgb.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that from our gridsearch of the subset of data, the best model had max_depth of 3, min child weight of 3, gamma of 0.4 and a learning rate of 0.45. We will use this information to train a XGB model on the full dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9063757091545201"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# what is the best AUC score\n",
    "reduced_grid_xgb.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fitting model on full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 14min 15s, sys: 9.19 s, total: 14min 24s\n",
      "Wall time: 14min 38s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0.4,\n",
       "              learning_rate=0.45, max_delta_step=0, max_depth=3,\n",
       "              min_child_weight=3, missing=None, n_estimators=100, n_jobs=1,\n",
       "              nthread=None, objective='binary:logistic', random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "              silent=None, subsample=1, verbosity=1)"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "#as we aren't using gridsearch, we will need to directly transform the train and test features using the \n",
    "#tfidf vectorizer\n",
    "X_train = tfid_vec_2.transform(train_df['comment_text_clean_detokenize'])\n",
    "X_test = tfid_vec_2.transform(test_df['comment_text_clean_detokenize'])\n",
    "\n",
    "#instantiate XGB Classfier with parameters learned from earlier\n",
    "XGB_model = XGBClassifier(max_depth =3, learning_rate=0.45, min_child_weight=3, gamma=0.4)\n",
    "# Fit model on training set\n",
    "XGB_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['saved_models/best_XGB.pkl']"
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save best estimator to file\n",
    "joblib.dump(XGB_model, 'saved_models/best_XGB.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get scores\n",
    "train_accuracy_xgb = XGB_model.score(X_train, y_train)\n",
    "test_accuracy_xgb = XGB_model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict train and test values\n",
    "y_train_pred = XGB_model.predict(X_train)\n",
    "y_test_pred = XGB_model.predict(X_test)\n",
    "\n",
    "y_train_pred_prob_xgb = XGB_model.predict_proba(X_train)\n",
    "y_test_pred_prob_xgb = XGB_model.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.99      0.97    179192\n",
      "           1       0.79      0.41      0.54     15448\n",
      "\n",
      "    accuracy                           0.94    194640\n",
      "   macro avg       0.87      0.70      0.75    194640\n",
      "weighted avg       0.94      0.94      0.94    194640\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# store the precision, recall, and f1 score for later and print the classification report\n",
    "xgb_precision = precision_score(y_test, y_test_pred)\n",
    "xgb_recall = recall_score(y_test, y_test_pred)\n",
    "xgb_f1 = f1_score(y_test, y_test_pred)\n",
    "\n",
    "print(classification_report(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area under curve (AUC):0.9031525355668136\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "\n",
    "fprs, tprs, thresholds = roc_curve(y_test, y_test_pred_prob_xgb[:,1])\n",
    "roc_auc = roc_auc_score(y_test, y_test_pred_prob_xgb[:,1])\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fprs, tprs, color='darkorange',\n",
    "         lw=2, label='AUC = %0.2f' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=1, linestyle='--')\n",
    "plt.xlabel('False Positive Rate (FPR)')\n",
    "plt.ylabel('True Positive Rate (TPR)')\n",
    "plt.title('ROC Curve for XGBoost')\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()\n",
    "\n",
    "print(f'Area under curve (AUC):{roc_auc}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append preds and probabilities to train and valid dfs\n",
    "\n",
    "\n",
    "train_df['Prediction_xgb'] = y_train_pred\n",
    "train_df['Prediction_probability_xgb'] = y_train_pred_prob[:, 1]\n",
    "test_df['Prediction_xgb'] = y_test_pred\n",
    "test_df['Prediction_probability_xgb'] = y_test_pred_prob[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the AUC metrics \n",
    "\n",
    "SUBGROUP_AUC = 'subgroup_auc'\n",
    "BPSN_AUC = 'bpsn_auc'  # stands for background positive, subgroup negative\n",
    "BNSP_AUC = 'bnsp_auc'\n",
    "\n",
    "MODEL_NAME = 'Prediction_xgb'\n",
    "TOXICITY_COLUMN = 'target'\n",
    "\n",
    "xgb_bias_metrics_df_train = compute_bias_metrics_for_model(train_df, identity_columns, MODEL_NAME, TOXICITY_COLUMN)\n",
    "xgb_final_metric_train = get_final_metric(xgb_bias_metrics_df_train, calculate_overall_auc(train_df, MODEL_NAME))\n",
    "\n",
    "xgb_bias_metrics_df_test = compute_bias_metrics_for_model(test_df, identity_columns, MODEL_NAME, TOXICITY_COLUMN)\n",
    "xgb_final_metric_test = get_final_metric(xgb_bias_metrics_df_test, calculate_overall_auc(test_df, MODEL_NAME))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_accuracy:0.9443495778652693\n",
      "train final weighted AUC:0.6679029973304209\n",
      "test_accuracy:0.9441789971228935\n",
      "test final weighted AUC::0.666201450252322\n"
     ]
    }
   ],
   "source": [
    "print(f'train_accuracy:{train_accuracy}')\n",
    "print(f'train final weighted AUC:{get_final_metric(xgb_bias_metrics_df_train, calculate_overall_auc(train_df, MODEL_NAME))}')\n",
    "print(f'test_accuracy:{test_accuracy}')\n",
    "print(f'test final weighted AUC::{get_final_metric(xgb_bias_metrics_df_test, calculate_overall_auc(test_df, MODEL_NAME))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subgroup</th>\n",
       "      <th>subgroup_size</th>\n",
       "      <th>subgroup_auc</th>\n",
       "      <th>bpsn_auc</th>\n",
       "      <th>bnsp_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>black</td>\n",
       "      <td>1519</td>\n",
       "      <td>0.616</td>\n",
       "      <td>0.672</td>\n",
       "      <td>0.645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>christian</td>\n",
       "      <td>4226</td>\n",
       "      <td>0.618</td>\n",
       "      <td>0.702</td>\n",
       "      <td>0.617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>jewish</td>\n",
       "      <td>835</td>\n",
       "      <td>0.619</td>\n",
       "      <td>0.693</td>\n",
       "      <td>0.626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>psychiatric_or_mental_illness</td>\n",
       "      <td>511</td>\n",
       "      <td>0.624</td>\n",
       "      <td>0.687</td>\n",
       "      <td>0.637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>homosexual_gay_or_lesbian</td>\n",
       "      <td>1065</td>\n",
       "      <td>0.631</td>\n",
       "      <td>0.681</td>\n",
       "      <td>0.650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>muslim</td>\n",
       "      <td>2040</td>\n",
       "      <td>0.632</td>\n",
       "      <td>0.690</td>\n",
       "      <td>0.643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>white</td>\n",
       "      <td>2452</td>\n",
       "      <td>0.651</td>\n",
       "      <td>0.677</td>\n",
       "      <td>0.674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>male</td>\n",
       "      <td>4386</td>\n",
       "      <td>0.656</td>\n",
       "      <td>0.696</td>\n",
       "      <td>0.661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>female</td>\n",
       "      <td>5155</td>\n",
       "      <td>0.657</td>\n",
       "      <td>0.698</td>\n",
       "      <td>0.660</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        subgroup  subgroup_size  subgroup_auc  bpsn_auc  \\\n",
       "6                          black           1519         0.616     0.672   \n",
       "3                      christian           4226         0.618     0.702   \n",
       "4                         jewish            835         0.619     0.693   \n",
       "8  psychiatric_or_mental_illness            511         0.624     0.687   \n",
       "2      homosexual_gay_or_lesbian           1065         0.631     0.681   \n",
       "5                         muslim           2040         0.632     0.690   \n",
       "7                          white           2452         0.651     0.677   \n",
       "0                           male           4386         0.656     0.696   \n",
       "1                         female           5155         0.657     0.698   \n",
       "\n",
       "   bnsp_auc  \n",
       "6     0.645  \n",
       "3     0.617  \n",
       "4     0.626  \n",
       "8     0.637  \n",
       "2     0.650  \n",
       "5     0.643  \n",
       "7     0.674  \n",
       "0     0.661  \n",
       "1     0.660  "
      ]
     },
     "execution_count": 418,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_bias_metrics_df_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Evaluation\n",
    "In terms of pure accuracy the XGBoost classifier performed as well as the logistic regression. However when we calculate the weighted AUC metric the model has performed worse at 66.6% on the test data. Looking at the subgroup AUC dataframe suggests a general weakness accross all identity subgroups. \n",
    "\n",
    "Recall was weaker at 0.41 and so was the overall AUC at 90% which is another reason for the weaker weighted AUC metric.\n",
    "\n",
    "This may be as a result of us having to carry out hyperparameter optimization on just a subset of the data, but also not being able to explore as many parameter combinations. With additional computing power we would be able to do a more exhaustive search ont he full dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest\n",
    "\n",
    "For our final model we will try the Random Forest Classifier which is an ensemble method. It is based on the Decision Tree model, only the Random Forest works by fitting on random sub samples of the data (with replacement), which is known as 'bagging'. A voting algorithm is then applied on the results of each of the trees to determine the final class of the data point. The aim of Random Forest is to train a series of overfit models and then average out the results via voting to get better results. The main hyperparemeter we will optimize for is the number of decision trees to use and the max depth of the trees. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grid Search on a subset of data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the length of time taken to grid search on the Random Forest Classifier, we will run a gridsearch on a subset of our dataset by taking a new train test split. We will then use the results there as a proxy for the optimal parameters for our full dataset. We will use the same train_test split as used for the XGB subset search. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:  5.4min\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed: 13.1min\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed: 35.6min\n",
      "[Parallel(n_jobs=-1)]: Done  25 out of  36 | elapsed: 78.8min remaining: 34.7min\n",
      "[Parallel(n_jobs=-1)]: Done  29 out of  36 | elapsed: 113.6min remaining: 27.4min\n",
      "[Parallel(n_jobs=-1)]: Done  33 out of  36 | elapsed: 132.4min remaining: 12.0min\n",
      "[Parallel(n_jobs=-1)]: Done  36 out of  36 | elapsed: 165.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 50min 44s, sys: 12.9 s, total: 50min 57s\n",
      "Wall time: 3h 35min 49s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Note, most of the time here actually comes from the application of the tfid vectorizer to each fold of the data\n",
    "# Random forest itself takes ~5minutes to run on the vectorized data.\n",
    "\n",
    "# We control the model max depth \n",
    "param_grid_RF = {'model': [RandomForestClassifier()], 'tf-idf': [tfid_vec_2], \n",
    "                 'model__n_estimators': [10,50,100],\n",
    "                 'model__max_depth': [100, 500, 1000, 5000],\n",
    "             }\n",
    "reduced_grid_RF = GridSearchCV(pipeline, param_grid_RF, scoring=scorers, cv=3, refit='AUC',\n",
    "                       return_train_score=True, n_jobs=-1, verbose = 10)\n",
    "\n",
    "reduced_grid_RF = reduced_grid_RF.fit(reduced_df['comment_text_clean_detokenize'], reduced_df['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('tf-idf',\n",
       "                 TfidfVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.float64'>,\n",
       "                                 encoding='utf-8', input='content',\n",
       "                                 lowercase=False, max_df=1.0, max_features=None,\n",
       "                                 min_df=1, ngram_range=(1, 1), norm='l2',\n",
       "                                 preprocessor=None, smooth_idf=True,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 sublinear_tf=False,\n",
       "                                 token_pattern...\n",
       "                 RandomForestClassifier(bootstrap=True, class_weight=None,\n",
       "                                        criterion='gini', max_depth=1000,\n",
       "                                        max_features='auto',\n",
       "                                        max_leaf_nodes=None,\n",
       "                                        min_impurity_decrease=0.0,\n",
       "                                        min_impurity_split=None,\n",
       "                                        min_samples_leaf=1, min_samples_split=2,\n",
       "                                        min_weight_fraction_leaf=0.0,\n",
       "                                        n_estimators=100, n_jobs=None,\n",
       "                                        oob_score=False, random_state=None,\n",
       "                                        verbose=0, warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the best estimator parameters\n",
    "reduced_grid_RF.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9230210872062684"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# gives the best AUC score\n",
    "reduced_grid_RF.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reduced_grid_RF.cv_results_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above test has suggested that in terms of hyperparameters, we should look at a model that has n_estimators around 100 or above, and max_depth of around 1000. We will use this as a guide for our grid search. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fitting the model on the full dataset\n",
    "Now that we have a good idea of optimal parameters, we will apply these parameters on the full dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=1000, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We need to transform the data.\n",
    "X_train = tfid_vec_2.transform(train_df['comment_text_clean_detokenize'])\n",
    "X_test = tfid_vec_2.transform(test_df['comment_text_clean_detokenize'])\n",
    "\n",
    "# Instantiate the model with correct parameters and fit.\n",
    "RF_model = RandomForestClassifier(n_estimators = 100, max_depth = 1000)\n",
    "RF_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 20s, sys: 3.61 s, total: 1min 24s\n",
      "Wall time: 1min 26s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "rf_test_accuracy = RF_model.score(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9417591450883682"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['saved_models/best_RF.pkl']"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save best estimator to file\n",
    "joblib.dump(RF_model, 'saved_models/best_RF.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict train and test values\n",
    "y_train_pred = RF_model.predict(X_train)\n",
    "y_test_pred = RF_model.predict(X_test)\n",
    "\n",
    "y_train_pred_prob_rf = RF_model.predict_proba(X_train)\n",
    "y_test_pred_prob_rf = RF_model.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.96265644, 0.03734356],\n",
       "       [0.97665037, 0.02334963],\n",
       "       [0.97868673, 0.02131327],\n",
       "       ...,\n",
       "       [0.46485893, 0.53514107],\n",
       "       [0.88846968, 0.11153032],\n",
       "       [0.96707338, 0.03292662]])"
      ]
     },
     "execution_count": 372,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_pred_prob_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.99      0.97    179192\n",
      "           1       0.83      0.34      0.48     15448\n",
      "\n",
      "    accuracy                           0.94    194640\n",
      "   macro avg       0.89      0.67      0.72    194640\n",
      "weighted avg       0.94      0.94      0.93    194640\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# store the precision, recall, and f1 score for later and print the classification report\n",
    "rf_precision = precision_score(y_test, y_test_pred)\n",
    "rf_recall = recall_score(y_test, y_test_pred)\n",
    "rf_f1 = f1_score(y_test, y_test_pred)\n",
    "\n",
    "print(classification_report(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area under curve (AUC):0.9247063596820333\n"
     ]
    }
   ],
   "source": [
    "# Lets plot the standard ROC curve\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "\n",
    "fprs, tprs, thresholds = roc_curve(y_test, y_test_pred_prob_rf[:,1])\n",
    "roc_auc = roc_auc_score(y_test, y_test_pred_prob_rf[:,1])\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fprs, tprs, color='darkorange',\n",
    "         lw=2, label='AUC = %0.2f' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=1, linestyle='--')\n",
    "plt.xlabel('False Positive Rate (FPR)')\n",
    "plt.ylabel('True Positive Rate (TPR)')\n",
    "plt.title('ROC Curve for Random Forest')\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()\n",
    "\n",
    "print(f'Area under curve (AUC):{roc_auc}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identity columns used to calculate subgroup AUC\n",
    "identity_columns = [\n",
    "    'male', 'female', 'homosexual_gay_or_lesbian', 'christian', 'jewish',\n",
    "    'muslim', 'black', 'white', 'psychiatric_or_mental_illness']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in identity_columns + ['target']:\n",
    "    train_df[col] = np.where(train_df[col] >= 0.5, True, False)\n",
    "    test_df[col] = np.where(test_df[col] >= 0.5, True, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append preds and probabilities to train and valid dfs\n",
    "train_df['Prediction_RF'] = y_train_pred\n",
    "train_df['Prediction_probability_RF'] = y_train_pred_prob[:, 1]\n",
    "test_df['Prediction_RF'] = y_test_pred\n",
    "test_df['Prediction_probability_RF'] = y_test_pred_prob[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the AUC metrics \n",
    "\n",
    "SUBGROUP_AUC = 'subgroup_auc'\n",
    "BPSN_AUC = 'bpsn_auc'  # stands for background positive, subgroup negative\n",
    "BNSP_AUC = 'bnsp_auc'\n",
    "\n",
    "MODEL_NAME = 'Prediction_RF'\n",
    "TOXICITY_COLUMN = 'target'\n",
    "\n",
    "rf_bias_metrics_df_train = compute_bias_metrics_for_model(train_df, identity_columns, MODEL_NAME, TOXICITY_COLUMN)\n",
    "rf_final_metric_train = get_final_metric(rf_bias_metrics_df_train, calculate_overall_auc(train_df, MODEL_NAME))\n",
    "\n",
    "rf_bias_metrics_df_test = compute_bias_metrics_for_model(test_df, identity_columns, MODEL_NAME, TOXICITY_COLUMN)\n",
    "rf_final_metric_test = get_final_metric(rf_bias_metrics_df_test, calculate_overall_auc(test_df, MODEL_NAME))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subgroup</th>\n",
       "      <th>subgroup_size</th>\n",
       "      <th>subgroup_auc</th>\n",
       "      <th>bpsn_auc</th>\n",
       "      <th>bnsp_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>black</td>\n",
       "      <td>1519</td>\n",
       "      <td>0.535805</td>\n",
       "      <td>0.671200</td>\n",
       "      <td>0.534692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>christian</td>\n",
       "      <td>4226</td>\n",
       "      <td>0.538518</td>\n",
       "      <td>0.671294</td>\n",
       "      <td>0.536449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>jewish</td>\n",
       "      <td>835</td>\n",
       "      <td>0.542044</td>\n",
       "      <td>0.668454</td>\n",
       "      <td>0.540397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>muslim</td>\n",
       "      <td>2040</td>\n",
       "      <td>0.542836</td>\n",
       "      <td>0.672161</td>\n",
       "      <td>0.540382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>homosexual_gay_or_lesbian</td>\n",
       "      <td>1065</td>\n",
       "      <td>0.546340</td>\n",
       "      <td>0.669129</td>\n",
       "      <td>0.545196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>white</td>\n",
       "      <td>2452</td>\n",
       "      <td>0.556286</td>\n",
       "      <td>0.671977</td>\n",
       "      <td>0.555543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>female</td>\n",
       "      <td>5155</td>\n",
       "      <td>0.573352</td>\n",
       "      <td>0.671357</td>\n",
       "      <td>0.572037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>psychiatric_or_mental_illness</td>\n",
       "      <td>511</td>\n",
       "      <td>0.584684</td>\n",
       "      <td>0.664368</td>\n",
       "      <td>0.586552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>male</td>\n",
       "      <td>4386</td>\n",
       "      <td>0.585907</td>\n",
       "      <td>0.670266</td>\n",
       "      <td>0.584965</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        subgroup  subgroup_size  subgroup_auc  bpsn_auc  \\\n",
       "6                          black           1519      0.535805  0.671200   \n",
       "3                      christian           4226      0.538518  0.671294   \n",
       "4                         jewish            835      0.542044  0.668454   \n",
       "5                         muslim           2040      0.542836  0.672161   \n",
       "2      homosexual_gay_or_lesbian           1065      0.546340  0.669129   \n",
       "7                          white           2452      0.556286  0.671977   \n",
       "1                         female           5155      0.573352  0.671357   \n",
       "8  psychiatric_or_mental_illness            511      0.584684  0.664368   \n",
       "0                           male           4386      0.585907  0.670266   \n",
       "\n",
       "   bnsp_auc  \n",
       "6  0.534692  \n",
       "3  0.536449  \n",
       "4  0.540397  \n",
       "5  0.540382  \n",
       "2  0.545196  \n",
       "7  0.555543  \n",
       "1  0.572037  \n",
       "8  0.586552  \n",
       "0  0.584965  "
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_bias_metrics_df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6108032567341172"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_final_metric_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'train_accuracy:{train_accuracy}')\n",
    "print(f'train weighted AUC:{rf_final_metric_train}')\n",
    "print(f'test_accuracy:{test_accuracy}')\n",
    "print(f'test weighted AUC::{rf_final_metric_test}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Evaluation\n",
    "Of the classical models the Random Forest was by far the weakest in terms of the final weighted AUC metric. It generally did poorly accross all the identity subgroups. In addition to this, it had very poor recall on the test set, implying that the model was failing to identify many cases of toxic commentary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing Model performance\n",
    "\n",
    "Now that we have trained three seperate models which have been shown to deliver strong performance in text classification tasks in the past let us take the time to compare them side-by-side and also discuss their short-comings in terms of reducing bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Display the subgroup bias metrics tables for each model and then the final metrics for each model for test only\n",
    "display(log_bias_metrics_df_test)\n",
    "display(svm_bias_metrics_df_test)\n",
    "display(rf_bias_metrics_df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Final metric for Logistic Regression: 0.7126513014416012\n",
      " Final metric for XGB: 0.666201450252322\n",
      " Final metric for Random Forest: 0.6108032567341172\n"
     ]
    }
   ],
   "source": [
    "# Display final metrics for each model for test only.\n",
    "print(f' Final metric for Logistic Regression: {log_final_metric_test}')\n",
    "print(f' Final metric for XGB: {xgb_final_metric_test}')\n",
    "print(f' Final metric for Random Forest: {rf_final_metric_test}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NN model results taken from NN_model ipynb\n",
    "NN_final_metric_test = 0.920\n",
    "NN_precision_test = 0.754\n",
    "NN_Recall_test = 0.628\n",
    "NN_f1_test = 0.681\n",
    "NN_accuracy_test = 0.953"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'Accuracy': [test_accuracy_log, test_accuracy_xgb, rf_test_accuracy, NN_accuracy_test ], \n",
    "        'Precision': [log_precision, xgb_precision, rf_precision, NN_precision_test ],\n",
    "       'Recall': [log_recall, xgb_recall, rf_recall, NN_Recall_test], 'F1': [log_f1, xgb_f1, rf_f1, NN_f1_test ],\n",
    "       'Final Bias Metric': [log_final_metric_test, xgb_final_metric_test, rf_final_metric_test, NN_final_metric_test ]}\n",
    "\n",
    "results_df = pd.DataFrame(data, index=['Logistic', 'XGboost', 'Random Forest', 'LSTM'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Final Bias Metric</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Logistic</th>\n",
       "      <td>0.947</td>\n",
       "      <td>0.758</td>\n",
       "      <td>0.495</td>\n",
       "      <td>0.599</td>\n",
       "      <td>0.713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGboost</th>\n",
       "      <td>0.944</td>\n",
       "      <td>0.785</td>\n",
       "      <td>0.408</td>\n",
       "      <td>0.537</td>\n",
       "      <td>0.666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>0.942</td>\n",
       "      <td>0.826</td>\n",
       "      <td>0.338</td>\n",
       "      <td>0.479</td>\n",
       "      <td>0.611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LSTM</th>\n",
       "      <td>0.953</td>\n",
       "      <td>0.754</td>\n",
       "      <td>0.628</td>\n",
       "      <td>0.681</td>\n",
       "      <td>0.920</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Accuracy  Precision  Recall    F1  Final Bias Metric\n",
       "Logistic          0.947      0.758   0.495 0.599              0.713\n",
       "XGboost           0.944      0.785   0.408 0.537              0.666\n",
       "Random Forest     0.942      0.826   0.338 0.479              0.611\n",
       "LSTM              0.953      0.754   0.628 0.681              0.920"
      ]
     },
     "execution_count": 423,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the results we can see that our LSTM model has generally outperformed all three of the other models in the metrics selected. In particular we can see that the final bias metric, the weighted average of the subgroup AUCs, was significantly higher for the LSTM than the others at 0.92. This suggests that the LSTM model was better than the other models at minimising bias by not focussing on specific occurances of certain identy words when evaluating a particular comment. This fits in with our initial hypothesis and it is a positive result. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Steps for further exploration:\n",
    "\n",
    "All our models generally showed strong precision, suggesting that when they did classify something as toxic they were generally accurate. However we can see that recall was usually weak, suggesting that the model struggled to pick out all cases of toxicity. We believe this is highly likely to be due to the large class imbalance in the dataset where only ~8% of the data was classified as toxic. A natural first step would be to therefore re-run the model on a more balanced dataset. Another option would be to lower the threshold for toxicity, however this can come at the expense of precision.\n",
    "\n",
    "We would also like to carry out a more exhaustive hyperparameter optimization exercise for our models. Unfortunately, it quickly became apparent that doing so on our current computing hardwarde was not feasible and cloud hardware was primarily used to train our LSTM. With access to more powerful hardware we would be able to better optmize our models.\n",
    "\n",
    "For our LSTM model, we would definitely like to try further network structures, including potentially adding a further bi-directional layer or an attention mechanism. Attention mechanisms have been proven to be very effective in tasks where a model needs to focus in on specific areas of a sequence that containt he most relevant information and are core parts of many SotA NLP architectures. In addition with more time we would like to try out different glove embeddings and also process our text further to potentially increase the percentage of our vocabulary covered by the word embeddings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the results of our ML models using eli5\n",
    "\n",
    "Below we use the eli5 package to help interpret our results. We will do this using the logistic model we fit due to only certain sklearn classifiers being compatible. The logistic model was also the best performing of the three traditional ML models we have tested. Documentation on the TextExplainer can be found [here.](https://eli5.readthedocs.io/en/latest/_notebooks/text-explainer.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import eli5\n",
    "from eli5.lime import TextExplainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in log model\n",
    "joblib.dump(fittedgrid.best_estimator_, 'saved_models/best_log_reg.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "    table.eli5-weights tr:hover {\n",
       "        filter: brightness(85%);\n",
       "    }\n",
       "</style>\n",
       "\n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "        \n",
       "\n",
       "    \n",
       "\n",
       "        \n",
       "\n",
       "        \n",
       "    \n",
       "        \n",
       "        \n",
       "    \n",
       "        <p style=\"margin-bottom: 0.5em; margin-top: 0em\">\n",
       "            <b>\n",
       "    \n",
       "        y=Toxic\n",
       "    \n",
       "</b>\n",
       "\n",
       "    \n",
       "    (probability <b>0.860</b>, score <b>1.812</b>)\n",
       "\n",
       "top features\n",
       "        </p>\n",
       "    \n",
       "    <table class=\"eli5-weights\"\n",
       "           style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto; margin-bottom: 2em;\">\n",
       "        <thead>\n",
       "        <tr style=\"border: none;\">\n",
       "            \n",
       "                <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\" title=\"Feature contribution already accounts for the feature value (for linear models, contribution = weight * feature value), and the sum of feature contributions is equal to the score or, for some classifiers, to the probability. Feature values are shown if &quot;show_feature_values&quot; is True.\">\n",
       "                    Contribution<sup>?</sup>\n",
       "                </th>\n",
       "            \n",
       "            <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
       "            \n",
       "        </tr>\n",
       "        </thead>\n",
       "        <tbody>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 80.00%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +2.575\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        Highlighted in text (sum)\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "        \n",
       "\n",
       "        \n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 91.47%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.763\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        &lt;BIAS&gt;\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "\n",
       "        </tbody>\n",
       "    </table>\n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "\n",
       "    <p style=\"margin-bottom: 2.5em; margin-top:-0.5em;\">\n",
       "        <span style=\"background-color: hsl(0, 100.00%, 93.71%); opacity: 0.81\" title=\"-0.100\">think</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 85.16%); opacity: 0.85\" title=\"-0.340\">heart</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 94.22%); opacity: 0.81\" title=\"-0.088\">right</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 92.80%); opacity: 0.82\" title=\"-0.121\">place</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 60.00%); opacity: 1.00\" title=\"1.400\">gay</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 87.54%); opacity: 0.84\" title=\"0.265\">men</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 65.45%); opacity: 0.96\" title=\"1.136\">lesbian</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 91.08%); opacity: 0.82\" title=\"-0.164\">issue</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 94.77%); opacity: 0.81\" title=\"0.077\">using</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 94.75%); opacity: 0.81\" title=\"-0.077\">correctly</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 94.74%); opacity: 0.81\" title=\"-0.077\">gendered</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 96.90%); opacity: 0.81\" title=\"-0.036\">bathroom</span><span style=\"opacity: 0.80\">  </span><span style=\"background-color: hsl(120, 100.00%, 72.37%); opacity: 0.92\" title=\"0.825\">sexual</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 66.05%); opacity: 0.96\" title=\"-1.108\">orientation</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 97.39%); opacity: 0.80\" title=\"0.028\">gender</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 95.99%); opacity: 0.81\" title=\"-0.052\">identity</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 98.38%); opacity: 0.80\" title=\"0.014\">two</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 90.87%); opacity: 0.82\" title=\"0.170\">totally</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 94.34%); opacity: 0.81\" title=\"-0.086\">different</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 96.77%); opacity: 0.81\" title=\"-0.038\">thing</span><span style=\"opacity: 0.80\">  </span><span style=\"background-color: hsl(120, 100.00%, 67.65%); opacity: 0.95\" title=\"1.034\">transgender</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 97.57%); opacity: 0.80\" title=\"0.026\">person</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 62.18%); opacity: 0.98\" title=\"1.292\">gay</span><span style=\"opacity: 0.80\">  </span><span style=\"background-color: hsl(120, 100.00%, 65.32%); opacity: 0.96\" title=\"1.142\">lesbian</span><span style=\"opacity: 0.80\">  </span><span style=\"background-color: hsl(0, 100.00%, 89.67%); opacity: 0.83\" title=\"-0.202\">bi</span><span style=\"opacity: 0.80\">  </span><span style=\"background-color: hsl(0, 100.00%, 96.95%); opacity: 0.81\" title=\"-0.035\">straight</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 72.36%); opacity: 0.92\" title=\"0.826\">sexual</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 64.89%); opacity: 0.97\" title=\"-1.162\">orientation</span>\n",
       "    </p>\n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 407,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate the lime TextExplainer model\n",
    "text_model_log = TextExplainer(random_state=1)\n",
    "\n",
    "#select a comment to investigate - because our model was trained on pre-processed data we need to use the pre-processed \n",
    "# text detokenized. You can change the index in the loc function to get different comments. \n",
    "text = test_df.loc[175957,'comment_text_clean_detokenize']\n",
    "\n",
    "# Fit the Textexplainer using the the selected test and passing in the predict_proba function for our fitted logistic model.\n",
    "text_model_log.fit(text, fittedgrid_log.predict_proba)\n",
    "text_model_log.show_prediction(target_names=['Non-toxic', 'Toxic'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above example is a case of a comment which was originally labelled as 'Non-Toxic', but our model has labelled as 'Toxic'. We can see that the model has specifically highlighted the mentions of the word gay, lesbian, and transgender as key contributers to toxicity, which is the exact reason why these models have issues with bias against minority identities.  The original comment text is below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I think your hearts in the right place but gay men and lesbians have no issues using the correctly gendered bathrooms. Sexual orientation and gender identity are two totally different things. A transgender person can be gay, lesbian, bi, straight or any other Sexual orientation.'"
      ]
     },
     "execution_count": 403,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.loc[175957, 'comment_text']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
