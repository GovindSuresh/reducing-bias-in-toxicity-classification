{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network Models\n",
    "\n",
    "In this notebook we have specified the build for our LSTM model.\n",
    "We have used tensorflow 2.0. If you are training the model, it is highly recommended to use a GPU and have at least ~32gb of RAM. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import general modules\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "from ast import literal_eval\n",
    "import datetime, os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import scikit learn modules\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import tensorflow and keras modules. NOTE: WE ARE USING TENSORFLOW 2.0\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing import text, sequence\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import Embedding, Dense, LSTM, MaxPooling1D, Input, GlobalAveragePooling1D, GlobalMaxPooling1D\n",
    "from tensorflow.keras.layers import Bidirectional, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.metrics import AUC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_VOCAB_SIZE = 200000 # there are 563693 words in the vocabulary\n",
    "MAX_LEN_SEQ = 300\n",
    "TRAIN_TEXT_COL = 'comment_text_clean2'\n",
    "TEST_TEXT_COL = 'comment_text_clean2'\n",
    "TRAIN_TARGET_COL = 'target'\n",
    "TEST_TARGET_COL = 'target'\n",
    "EMBED_DIM = 300\n",
    "EMBEDDING_FILE = 'embeds/glove.840B.300d.txt'\n",
    "\n",
    "DROPOUT_RATE = 0.2\n",
    "LSTM_UNITS = 128\n",
    "BATCH_SIZE = 128\n",
    "NUM_EPOCHS = 4\n",
    "CHECKPOINT_PATH = \"NN_models/cp.ckpt\"\n",
    "CHECKPOINT_DIR = os.path.dirname(CHECKPOINT_PATH)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading data from S3 for cloud computing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Breaking down how to access our S3 Bucket files. \n",
    "#Put in your own bucket name\n",
    "bucket = 'gs-capstone' \n",
    "\n",
    "#the path to the file you want to load in your S3 Bucket\n",
    "dataset_file_path_train = 'train_for_nn.csv'\n",
    "dataset_file_path_test = 'test_for_nn.csv'\n",
    "\n",
    "#Creating the path, and combining the above\n",
    "path_train = 's3://{}/{}'.format(bucket, dataset_file_path_train)\n",
    "path_test = 's3://{}/{}'.format(bucket, dataset_file_path_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "s3 = boto3.client('s3')\n",
    "s3.download_file(bucket, dataset_file_path_train, 'train_for_nn.csv')\n",
    "s3.download_file(bucket, dataset_file_path_test, 'test_for_nn.csv')\n",
    "\n",
    "# When the data set was saved as a CSV, tokenized column, which was a list was coverted to a string, \n",
    "# The converters option changes this back into its list form \n",
    "train_data = pd.read_csv('train_for_nn.csv', converters={\"comment_text_clean2\": literal_eval})\n",
    "test_data = pd.read_csv('test_for_nn.csv', converters={\"comment_text_clean2\": literal_eval})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading data from local machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_data = pd.read_csv('../data/train_for_nn.csv', converters={\"comment_text_clean2\": literal_eval})\n",
    "test_data = pd.read_csv('../data/test_for_nn.csv', converters={\"comment_text_clean2\": literal_eval})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create train val split, stratify on target\n",
    "train_df, val_df = train_test_split(train_data, test_size=0.2, stratify=train_data['target'], random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and fix tokenizer\n",
    "def train_tokenizer(train_data, vocab_size):\n",
    "    # Use Keras tokenizer to create vocabulary dictionary \n",
    "    # default arguments will filter punctuation and convert to lower, we do not want this given our use \n",
    "    # of pre-trained word embeddings\n",
    "    tokenizer = text.Tokenizer(num_words = vocab_size, filters='', lower=False)\n",
    "    tokenizer.fit_on_texts(train_data)\n",
    "    return tokenizer\n",
    "\n",
    "# pad tokenized sequences\n",
    "def text_padder(text, tokenizer):\n",
    "    return sequence.pad_sequences(tokenizer.texts_to_sequences(text), maxlen=MAX_LEN_SEQ)\n",
    "\n",
    "# Build embedding matrix\n",
    "def build_embedding_matrix(word_indexes, EMBEDDING_FILE):\n",
    "  \n",
    "    # Used to store words as key and vectors as value\n",
    "    embedding_dict = {}\n",
    "    with open(EMBEDDING_FILE) as file:\n",
    "        # file is formatted word {whitespace} vector\n",
    "        for line in file:\n",
    "            pairs = line.split(' ')\n",
    "           # word is 0 index of pairs\n",
    "            word = pairs[0]\n",
    "            vec = pairs[1:]\n",
    "           #convert vec into a numpy array\n",
    "            vec = np.asarray(vec, dtype=np.float32)\n",
    "            embedding_dict[word] = vec\n",
    "    \n",
    "    #create the embedding matrix which has dimensions:\n",
    "    # MAX_VOCAB_SIZE +1 for rows, this means there will be as many rows as words we allow to be part of the feature set.\n",
    "    # EMBED_DIM is the number of columns, this reflects the dimensions of the word embedding vectors we are using.\n",
    "    embedding_matrix = np.zeros((len(word_indexes)+1, EMBED_DIM))\n",
    "\n",
    "\n",
    "    word_count = 0\n",
    "    for word, i in word_indexes.items():\n",
    "        # gets the vector to the corresponding word from the previous dictionary and sets it to the variable\n",
    "        embedding_vector = embedding_dict.get(word)\n",
    "        # We check whether the embedding_vector is not none (i.e the word is in the embedding index)\n",
    "        if embedding_vector is not None:\n",
    "            word_count += 1\n",
    "            # Append the embedding vector to index i in the embedding matrix \n",
    "            embedding_matrix[i] = embedding_vector\n",
    "            \n",
    "    return embedding_matrix\n",
    "            \n",
    "def build_embedding_matrix_restricted(word_indexes, EMBEDDING_FILE):\n",
    "  \n",
    "    # Used to store words as key and vectors as value\n",
    "    embedding_dict = {}\n",
    "    with open(EMBEDDING_FILE) as file:\n",
    "        # file is formatted word {whitespace} vector\n",
    "        for line in file:\n",
    "            pairs = line.split(' ')\n",
    "           # word is 0 index of pairs\n",
    "            word = pairs[0]\n",
    "            vec = pairs[1:]\n",
    "           #convert vec into a numpy array\n",
    "            vec = np.asarray(vec, dtype=np.float32)\n",
    "            embedding_dict[word] = vec\n",
    "    \n",
    "    #create the embedding matrix which has dimensions:\n",
    "    # MAX_VOCAB_SIZE +1 for rows, this means there will be as many rows as words we allow to be part of the feature set.\n",
    "    # EMBED_DIM is the number of columns, this reflects the dimensions of the word embedding vectors we are using.\n",
    "    embedding_matrix = np.zeros((MAX_VOCAB_SIZE+1, EMBED_DIM))\n",
    "\n",
    "    \n",
    "    word_count = 0\n",
    "  \n",
    "    for word, i in word_indexes.items():\n",
    "        if word_count <= MAX_VOCAB_SIZE:\n",
    "            # gets the vector to the corresponding word from the previous dictionary and sets it to the variable\n",
    "            embedding_vector = embedding_dict.get(word)\n",
    "            # We check whether the embedding_vector is not none (i.e the word is in the embedding index)\n",
    "            if embedding_vector is not None:\n",
    "                word_count += 1\n",
    "                # Append the embedding vector to index i in the embedding matrix \n",
    "                embedding_matrix[i] = embedding_vector\n",
    "        else:\n",
    "            break\n",
    "    return embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = train_tokenizer(train_df[TRAIN_TEXT_COL], MAX_VOCAB_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "494877"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build model\n",
    "\n",
    "# NOTE: WITH TF2.0 CUDNNLSTM is active by default when there is a GPU available but you must use the default settings.\n",
    "# SEE https://www.tensorflow.org/api_docs/python/tf/keras/layers/LSTM for more details\n",
    "\n",
    "def build_model(embedding_matrix):\n",
    "    # change to max word length \n",
    "    input_words = Input(shape=(MAX_LEN_SEQ,), dtype='int32')\n",
    "    embedding = Embedding(len(tokenizer.word_index)+1, EMBED_DIM,\n",
    "                          weights=[embedding_matrix],\n",
    "                          input_length = MAX_LEN_SEQ,\n",
    "                          #mask_zero = True\n",
    "                          trainable = False) (input_words)\n",
    "    x = Dropout(DROPOUT_RATE)(embedding)\n",
    "    x = Bidirectional(LSTM(128, activation='tanh', return_sequences=True))(x) #set return_sequence to false when passing to dense\n",
    "    #x = Bidirectional(LSTM(128, activation='tanh', return_sequences=True))(x)\n",
    "    \n",
    "    # Use GlobalMaxPooling\n",
    "    x = GlobalMaxPooling1D()(x)\n",
    "    \n",
    "    # Pass into DENSE layers \n",
    "    # Dense nodes total has been calculated as per \n",
    "    # https://ai.stackexchange.com/questions/3156/how-to-select-number-of-hidden-layers-and-number-of-memory-cells-in-an-lstm\n",
    "    # (300,000)/5*(128+2) = 462\n",
    "    x = Dense(462, activation='relu')(x)\n",
    "    prediction = Dense(2, activation='sigmoid')(x)\n",
    "    \n",
    "    model = Model(inputs=input_words, outputs=prediction, name='baseline-LSTM')\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy', AUC()])\n",
    "    \n",
    "    return model\n",
    "                           \n",
    "def train_model(train_df, val_df, tokenizer):\n",
    "    # Create processed and padded train and targets\n",
    "    print('padding_text')\n",
    "    X_train = text_padder(train_df[TRAIN_TEXT_COL], tokenizer)\n",
    "    X_val = text_padder(val_df[TRAIN_TEXT_COL], tokenizer)\n",
    "    y_train = to_categorical(train_df[TRAIN_TARGET_COL])\n",
    "    y_val = to_categorical(val_df[TRAIN_TARGET_COL])\n",
    "    \n",
    "    print('building embedding matrix')\n",
    "    # build embedding matrix\n",
    "    embed_matrix = build_embedding_matrix(tokenizer.word_index, EMBEDDING_FILE)\n",
    "    \n",
    "    # build model\n",
    "    print('building model')\n",
    "    model = build_model(embed_matrix)\n",
    "    \n",
    "    cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=CHECKPOINT_PATH,\n",
    "                                                 save_weights_only=True,\n",
    "                                                 verbose=1)\n",
    "    \n",
    "    # Connect to tensorboard\n",
    "    logdir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "    tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1, write_images=True, \n",
    "                                                          write_graph=False\n",
    "                                                          )\n",
    "    # train model\n",
    "    print('training model')\n",
    "    fitted_model = model.fit(X_train, y_train,\n",
    "                             batch_size = BATCH_SIZE,\n",
    "                             epochs = NUM_EPOCHS,\n",
    "                             validation_data=(X_val, y_val),\n",
    "                             callbacks=[cp_callback, tensorboard_callback],\n",
    "                             verbose = 1)\n",
    "    #save full model \n",
    "    model.save('saved_model/baseline-LSTM') \n",
    "    #saves to h5\n",
    "    model.save('saved_model/baseline-LSTM.h5')\n",
    "    \n",
    "    #save weights\n",
    "    model.save_weights('saved_weights/baseline-LSTM')\n",
    "    model.save_weights('saved_weights/baseline-LSTM.h5')\n",
    "  \n",
    "    return model, fitted_model\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model_vocab_restricted(embedding_matrix):\n",
    "    # change to max word length \n",
    "    input_words = Input(shape=(MAX_LEN_SEQ,), dtype='int32')\n",
    "    embedding = Embedding(MAX_VOCAB_SIZE+1, EMBED_DIM,\n",
    "                          weights=[embedding_matrix],\n",
    "                          input_length = MAX_LEN_SEQ,\n",
    "                          #mask_zero = True\n",
    "                          trainable = False) (input_words)\n",
    "    x = Dropout(DROPOUT_RATE)(embedding)\n",
    "    x = Bidirectional(LSTM(128, activation='tanh', return_sequences=True))(x) #set return_sequence to false when passing to dense\n",
    "    #x = Bidirectional(LSTM(128, activation='tanh', return_sequences=True))(x)\n",
    "    \n",
    "    # Use GlobalMaxPooling\n",
    "    x = GlobalMaxPooling1D()(x)\n",
    "    \n",
    "    # Pass into DENSE layers \n",
    "    # Dense nodes total has been calculated as per \n",
    "    # https://ai.stackexchange.com/questions/3156/how-to-select-number-of-hidden-layers-and-number-of-memory-cells-in-an-lstm\n",
    "    # (300,000)/5*(128+2) = 462\n",
    "    x = Dense(462, activation='relu')(x)\n",
    "    prediction = Dense(2, activation='sigmoid')(x)\n",
    "    \n",
    "    model = Model(inputs=input_words, outputs=prediction, name='baseline-LSTM')\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy', AUC()])\n",
    "    \n",
    "    return model\n",
    "                           \n",
    "def train_model_restricted(train_df, val_df, tokenizer):\n",
    "    # Create processed and padded train and targets\n",
    "    print('padding_text')\n",
    "    X_train = text_padder(train_df[TRAIN_TEXT_COL], tokenizer)\n",
    "    X_val = text_padder(val_df[TRAIN_TEXT_COL], tokenizer)\n",
    "    y_train = to_categorical(train_df[TRAIN_TARGET_COL])\n",
    "    y_val = to_categorical(val_df[TRAIN_TARGET_COL])\n",
    "    \n",
    "    print('building embedding matrix')\n",
    "    # build embedding matrix\n",
    "    embed_matrix = build_embedding_matrix_restricted(tokenizer.word_index, EMBEDDING_FILE)\n",
    "    \n",
    "    # build model\n",
    "    print('building model')\n",
    "    model = build_model_vocab_restricted(embed_matrix)\n",
    "    \n",
    "    cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=CHECKPOINT_PATH,\n",
    "                                                 save_weights_only=True,\n",
    "                                                 verbose=1)\n",
    "    \n",
    "    # Connect to tensorboard\n",
    "    logdir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "    tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1, write_images=True, write_graph=False\n",
    "                                                          )\n",
    "    # train model\n",
    "    print('training model')\n",
    "    fitted_model = model.fit(X_train, y_train,\n",
    "                             batch_size = BATCH_SIZE,\n",
    "                             epochs = NUM_EPOCHS,\n",
    "                             validation_data=(X_val, y_val),\n",
    "                             callbacks=[cp_callback, tensorboard_callback],\n",
    "                             verbose = 1)\n",
    "    \n",
    "    #save full model \n",
    "    model.save('saved_nn_model/baseline-LSTM') \n",
    "    #saves to h5\n",
    "    model.save('saved_nn_model/baseline-LSTM.h5')\n",
    "    \n",
    "    #save weights\n",
    "    model.save_weights('saved_weights/baseline-LSTM')\n",
    "    model.save_weights('saved_weights/baseline-LSTM.h5')\n",
    "    \n",
    "    return model, fitted_model\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 56.2 s, sys: 32 ms, total: 56.3 s\n",
      "Wall time: 56.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tokenizer = train_tokenizer(train_df[TRAIN_TEXT_COL], MAX_VOCAB_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.experimental.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "padding_text\n",
      "building embedding matrix\n",
      "building model\n",
      "training model\n",
      "Train on 1443899 samples, validate on 360975 samples\n",
      "Epoch 1/4\n",
      "1443840/1443899 [============================>.] - ETA: 0s - loss: 0.1374 - accuracy: 0.9469 - auc_3: 0.9881\n",
      "Epoch 00001: saving model to NN_models/cp.ckpt\n",
      "1443899/1443899 [==============================] - 6645s 5ms/sample - loss: 0.1374 - accuracy: 0.9469 - auc_3: 0.9881 - val_loss: 0.1241 - val_accuracy: 0.9509 - val_auc_3: 0.9902\n",
      "Epoch 2/4\n",
      "1443840/1443899 [============================>.] - ETA: 0s - loss: 0.1239 - accuracy: 0.9511 - auc_3: 0.9903\n",
      "Epoch 00002: saving model to NN_models/cp.ckpt\n",
      "1443899/1443899 [==============================] - 6643s 5ms/sample - loss: 0.1239 - accuracy: 0.9511 - auc_3: 0.9903 - val_loss: 0.1232 - val_accuracy: 0.9513 - val_auc_3: 0.9906\n",
      "Epoch 3/4\n",
      "1443840/1443899 [============================>.] - ETA: 0s - loss: 0.1189 - accuracy: 0.9527 - auc_3: 0.9910\n",
      "Epoch 00003: saving model to NN_models/cp.ckpt\n",
      "1443899/1443899 [==============================] - 6651s 5ms/sample - loss: 0.1189 - accuracy: 0.9527 - auc_3: 0.9910 - val_loss: 0.1197 - val_accuracy: 0.9524 - val_auc_3: 0.9909\n",
      "Epoch 4/4\n",
      "1443840/1443899 [============================>.] - ETA: 0s - loss: 0.1156 - accuracy: 0.9537 - auc_3: 0.9915\n",
      "Epoch 00004: saving model to NN_models/cp.ckpt\n",
      "1443899/1443899 [==============================] - 6645s 5ms/sample - loss: 0.1156 - accuracy: 0.9537 - auc_3: 0.9915 - val_loss: 0.1202 - val_accuracy: 0.9521 - val_auc_3: 0.9908\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1781: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "INFO:tensorflow:Assets written to: saved_model/baseline-LSTM/assets\n"
     ]
    }
   ],
   "source": [
    "model, fitted_model = train_model(train_df, val_df, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pass trained tokenizer to convert test results to sequences\n",
    "X_test = text_padder(test_data[TEST_TEXT_COL], tokenizer)\n",
    "\n",
    "#convert target col to categorical \n",
    "y_test = to_categorical(test_data[TEST_TARGET_COL])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate on test set\n",
    "test_evaluate = model.evaluate(X_test, y_test, batch_size = BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.7055274e-01, 3.0022413e-02],\n",
       "       [9.9992037e-01, 7.6860189e-05],\n",
       "       [9.9748015e-01, 2.4578571e-03],\n",
       "       ...,\n",
       "       [5.6042463e-01, 4.3444389e-01],\n",
       "       [6.1085480e-01, 3.9308065e-01],\n",
       "       [9.9860001e-01, 1.3416409e-03]], dtype=float32)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we want all rows and second column\n",
    "test_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred_results = pd.DataFrame(test_data2['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred_results['prediction_prob_0'] = test_preds[:,0]\n",
    "test_pred_results['prediction_prob_1'] = test_preds[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save results to csv\n",
    "test_pred_results.to_csv('test_pred_results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# also save to s3\n",
    "s3 = boto3.client('s3')\n",
    "s3.upload_file('test_pred_results.csv',bucket,'test_pred_results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_nn_model/baseline-LSTM/assets\n"
     ]
    }
   ],
   "source": [
    "model.save('saved_nn_model/baseline-LSTM')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Assessing Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in test predictions\n",
    "test_preds = pd.read_csv('test_pred_results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop unnamed column\n",
    "test_preds.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "test_data.drop('Unnamed: 0', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge the predictions onto the test dataframe on id\n",
    "test_results = test_data.merge(test_preds, how='inner', on='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define identity columns\n",
    "identity_columns = [\n",
    "    'male', 'female', 'homosexual_gay_or_lesbian', 'christian', 'jewish',\n",
    "    'muslim', 'black', 'white', 'psychiatric_or_mental_illness']\n",
    "# convert identity and target columns to boolean\n",
    "for col in identity_columns + ['target']:\n",
    "    #train_df[col] = np.where(train_df[col] >= 0.5, True, False)\n",
    "    test_results[col] = np.where(test_results[col] >= 0.5, True, False)\n",
    "    \n",
    "# create a binary col for prediction of class 1 (toxic)\n",
    "test_results['prediction_binary'] = np.where(test_results['prediction_prob_1'] >= 0.5, True, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.97      0.98      0.97    179192\n",
      "        True       0.74      0.63      0.68     15448\n",
      "\n",
      "    accuracy                           0.95    194640\n",
      "   macro avg       0.86      0.81      0.83    194640\n",
      "weighted avg       0.95      0.95      0.95    194640\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# store the precision, recall, and f1 score for later and print the classification report\n",
    "nn_precision = precision_score(test_results['target'], test_results['prediction_binary'])\n",
    "nn_recall = recall_score(test_results['target'], test_results['prediction_binary'])\n",
    "nn_f1 = f1_score(test_results['target'], test_results['prediction_binary'])\n",
    "\n",
    "print(classification_report(test_results['target'], test_results['prediction_binary']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the model is very strong at predicting the false class, however not as adept at the cases where toxicity is the case. A recall score of 0.63 suggests we are letting through a number of cases of toxic commentary. This is most likely due to the very large class imbalance we noted during our EDA. The model only has a few cases of toxic comments to train on compared to non-toxic which impairs its ability to learn about what constitutes a toxic comment. \n",
    "\n",
    "We will run all models once again with up-sampling and down-sampling applied and see whether this leads to a better preicsion and recall for the positive class. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define subgroup metrics\n",
    "\n",
    "SUBGROUP_AUC = 'subgroup_auc'\n",
    "BPSN_AUC = 'bpsn_auc'  # stands for background positive, subgroup negative\n",
    "BNSP_AUC = 'bnsp_auc'  # stands for background negative, subgroup positive\n",
    "\n",
    "\n",
    "# These calculations have been provided by Jigsaw AI for scoring based on the metrics of the kaggle competition\n",
    "# https://www.kaggle.com/c/jigsaw-unintended-bias-in-toxicity-classification/overview/evaluation\n",
    "\n",
    "# They work by filtering the relevant dataframe into specific subgroups and using the roc_auc_score metric from sklearn.\n",
    "\n",
    "def compute_auc(y_true, y_pred):\n",
    "    try:\n",
    "        return metrics.roc_auc_score(y_true, y_pred)\n",
    "    except ValueError:\n",
    "        return np.nan\n",
    "\n",
    "def compute_subgroup_auc(df, subgroup, label, model_name):\n",
    "    subgroup_examples = df[df[subgroup]]\n",
    "    return compute_auc(subgroup_examples[label], subgroup_examples[model_name])\n",
    "\n",
    "def compute_bpsn_auc(df, subgroup, label, model_name):\n",
    "    \"\"\"Computes the AUC of the within-subgroup negative examples and the background positive examples.\"\"\"\n",
    "    subgroup_negative_examples = df.loc[df[subgroup] & ~df[label]]\n",
    "    non_subgroup_positive_examples = df.loc[~df[subgroup] & df[label]]\n",
    "    examples = subgroup_negative_examples.append(non_subgroup_positive_examples)\n",
    "    return compute_auc(examples[label], examples[model_name])\n",
    "\n",
    "def compute_bnsp_auc(df, subgroup, label, model_name):\n",
    "    \"\"\"Computes the AUC of the within-subgroup positive examples and the background negative examples.\"\"\"\n",
    "    subgroup_positive_examples = df.loc[df[subgroup] & df[label]]\n",
    "    non_subgroup_negative_examples = df.loc[~df[subgroup] & ~df[label]]\n",
    "    examples = subgroup_positive_examples.append(non_subgroup_negative_examples)\n",
    "    return compute_auc(examples[label], examples[model_name])\n",
    "\n",
    "def compute_bias_metrics_for_model(dataset,\n",
    "                                   subgroups,\n",
    "                                   model,\n",
    "                                   label_col,\n",
    "                                   include_asegs=False):\n",
    "    \"\"\"Computes per-subgroup metrics for all subgroups and one model.\"\"\"\n",
    "    records = []\n",
    "    for subgroup in subgroups:\n",
    "        record = {\n",
    "            'subgroup': subgroup,\n",
    "            'subgroup_size': len(dataset.loc[dataset[subgroup]])\n",
    "        }\n",
    "        record[SUBGROUP_AUC] = compute_subgroup_auc(dataset, subgroup, label_col, model)\n",
    "        record[BPSN_AUC] = compute_bpsn_auc(dataset, subgroup, label_col, model)\n",
    "        record[BNSP_AUC] = compute_bnsp_auc(dataset, subgroup, label_col, model)\n",
    "        records.append(record)\n",
    "    return pd.DataFrame(records).sort_values('subgroup_auc', ascending=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_overall_auc(df, model_name):\n",
    "    true_labels = df[TOXICITY_COLUMN]\n",
    "    predicted_labels = df[model_name]\n",
    "    return metrics.roc_auc_score(true_labels, predicted_labels)\n",
    "\n",
    "def power_mean(series, p):\n",
    "    total = sum(np.power(series, p))\n",
    "    return np.power(total / len(series), 1 / p)\n",
    "\n",
    "def get_final_metric(bias_df, overall_auc, POWER=-5, OVERALL_MODEL_WEIGHT=0.25):\n",
    "    bias_score = np.average([\n",
    "        power_mean(bias_df[SUBGROUP_AUC], POWER),\n",
    "        power_mean(bias_df[BPSN_AUC], POWER),\n",
    "        power_mean(bias_df[BNSP_AUC], POWER)\n",
    "    ])\n",
    "    return (OVERALL_MODEL_WEIGHT * overall_auc) + ((1 - OVERALL_MODEL_WEIGHT) * bias_score)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "SUBGROUP_AUC = 'subgroup_auc'\n",
    "BPSN_AUC = 'bpsn_auc'  # stands for background positive, subgroup negative\n",
    "BNSP_AUC = 'bnsp_auc'\n",
    "\n",
    "MODEL_NAME = 'prediction_prob_1'\n",
    "TOXICITY_COLUMN = 'target'\n",
    "\n",
    "#log_bias_metrics_df_train = compute_bias_metrics_for_model(train_df, identity_columns, MODEL_NAME, TOXICITY_COLUMN)\n",
    "#log_final_metric_train = get_final_metric(log_bias_metrics_df_train, calculate_overall_auc(train_df, MODEL_NAME))\n",
    "\n",
    "nn_bias_metrics_df_test = compute_bias_metrics_for_model(test_results, identity_columns, MODEL_NAME, TOXICITY_COLUMN)\n",
    "nn_final_metric_test = get_final_metric(nn_bias_metrics_df_test, calculate_overall_auc(test_results, MODEL_NAME))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subgroup</th>\n",
       "      <th>subgroup_size</th>\n",
       "      <th>subgroup_auc</th>\n",
       "      <th>bpsn_auc</th>\n",
       "      <th>bnsp_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>homosexual_gay_or_lesbian</td>\n",
       "      <td>1065</td>\n",
       "      <td>0.821304</td>\n",
       "      <td>0.837734</td>\n",
       "      <td>0.964198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>black</td>\n",
       "      <td>1519</td>\n",
       "      <td>0.834304</td>\n",
       "      <td>0.810440</td>\n",
       "      <td>0.975257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>muslim</td>\n",
       "      <td>2040</td>\n",
       "      <td>0.847776</td>\n",
       "      <td>0.870060</td>\n",
       "      <td>0.962730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>white</td>\n",
       "      <td>2452</td>\n",
       "      <td>0.851929</td>\n",
       "      <td>0.827171</td>\n",
       "      <td>0.976014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>jewish</td>\n",
       "      <td>835</td>\n",
       "      <td>0.898686</td>\n",
       "      <td>0.912396</td>\n",
       "      <td>0.961414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>male</td>\n",
       "      <td>4386</td>\n",
       "      <td>0.909858</td>\n",
       "      <td>0.918311</td>\n",
       "      <td>0.961982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>psychiatric_or_mental_illness</td>\n",
       "      <td>511</td>\n",
       "      <td>0.915572</td>\n",
       "      <td>0.908674</td>\n",
       "      <td>0.966953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>female</td>\n",
       "      <td>5155</td>\n",
       "      <td>0.923290</td>\n",
       "      <td>0.930168</td>\n",
       "      <td>0.962232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>christian</td>\n",
       "      <td>4226</td>\n",
       "      <td>0.928230</td>\n",
       "      <td>0.949325</td>\n",
       "      <td>0.951141</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        subgroup  subgroup_size  subgroup_auc  bpsn_auc  \\\n",
       "2      homosexual_gay_or_lesbian           1065      0.821304  0.837734   \n",
       "6                          black           1519      0.834304  0.810440   \n",
       "5                         muslim           2040      0.847776  0.870060   \n",
       "7                          white           2452      0.851929  0.827171   \n",
       "4                         jewish            835      0.898686  0.912396   \n",
       "0                           male           4386      0.909858  0.918311   \n",
       "8  psychiatric_or_mental_illness            511      0.915572  0.908674   \n",
       "1                         female           5155      0.923290  0.930168   \n",
       "3                      christian           4226      0.928230  0.949325   \n",
       "\n",
       "   bnsp_auc  \n",
       "2  0.964198  \n",
       "6  0.975257  \n",
       "5  0.962730  \n",
       "7  0.976014  \n",
       "4  0.961414  \n",
       "0  0.961982  \n",
       "8  0.966953  \n",
       "1  0.962232  \n",
       "3  0.951141  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_bias_metrics_df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9204220165385741"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_final_metric_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In terms of the final bias metric and overall accuracy the results of our LSTM model are very encouraging. In terms of the final weighted AUC, we can see that the model performed significantly better than our classical ML models. Looking at the specific bias subgroups we can see that the model did not particularly struggle with any particular identity group. \n",
    "\n",
    "While this is a good result in terms of our stated aim of reducing bias, we are interested to see the impact of adjusting for the existing class imbalance on our model performances. Especially in terms of precision and recall for toxic comments. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference:\n",
    "\n",
    "Below we have defined a method to use for inference once we have a trained model. Before this we need to have loaded a trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('saved_baseline_LSTM/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "build() missing 1 required positional argument: 'input_shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-91-2f52417d930d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: build() missing 1 required positional argument: 'input_shape'"
     ]
    }
   ],
   "source": [
    "model.build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = load_model('baseline-LSTM.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"baseline-LSTM\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 300)]             0         \n",
      "_________________________________________________________________\n",
      "embedding (Embedding)        (None, 300, 300)          148463400 \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 300, 300)          0         \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 300, 256)          439296    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d (Global (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 462)               118734    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 926       \n",
      "=================================================================\n",
      "Total params: 149,022,356\n",
      "Trainable params: 558,956\n",
      "Non-trainable params: 148,463,400\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(model, text, tokenizer):\n",
    "    text = text_padder(text, tokenizer)\n",
    "    #print(text)\n",
    "    prediction = model.predict(text)\n",
    "    #prediction = np.where(prediction>0.5,1,0)\n",
    "    \n",
    "    return prediction\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = train_tokenizer(train_data[TRAIN_TEXT_COL], MAX_VOCAB_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[8488],\n",
       " [949],\n",
       " [7305],\n",
       " [7305],\n",
       " [3482],\n",
       " [],\n",
       " [2595],\n",
       " [3482],\n",
       " [8187],\n",
       " [7305],\n",
       " [284]]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.texts_to_sequences(string_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'translate'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-63-5f24e116d01f>\u001b[0m in \u001b[0;36mtext_padder\u001b[0;34m(text, tokenizer)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# pad tokenized sequences\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtext_padder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0msequence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad_sequences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtexts_to_sequences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxlen\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mMAX_LEN_SEQ\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# Build embedding matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/capstone/lib/python3.7/site-packages/keras_preprocessing/text.py\u001b[0m in \u001b[0;36mtexts_to_sequences\u001b[0;34m(self, texts)\u001b[0m\n\u001b[1;32m    277\u001b[0m             \u001b[0mA\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mof\u001b[0m \u001b[0msequences\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m         \"\"\"\n\u001b[0;32m--> 279\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtexts_to_sequences_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtexts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    280\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtexts_to_sequences_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtexts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/capstone/lib/python3.7/site-packages/keras_preprocessing/text.py\u001b[0m in \u001b[0;36mtexts_to_sequences_generator\u001b[0;34m(self, texts)\u001b[0m\n\u001b[1;32m    308\u001b[0m                                             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilters\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m                                             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 310\u001b[0;31m                                             self.split)\n\u001b[0m\u001b[1;32m    311\u001b[0m             \u001b[0mvect\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mseq\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/capstone/lib/python3.7/site-packages/keras_preprocessing/text.py\u001b[0m in \u001b[0;36mtext_to_word_sequence\u001b[0;34m(text, filters, lower, split)\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0mtranslate_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplit\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfilters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0mtranslate_map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmaketrans\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtranslate_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranslate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtranslate_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0mseq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'translate'"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "x = text_padder(x,tokenizer)\n",
    "string_1\n",
    "#model.predict(string_1)\n",
    "#string2 = [['hi', 'my', 'fellow', 'stranger']]\n",
    "model2.predict(x)\n",
    "#prediction_1 = inference(model2, string2, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(65, 1)"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = test_data['comment_text_clean2'].loc[1]\n",
    "x = np.asarray(x)\n",
    "x = x.reshape(65,1)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I',\n",
       " 'actually',\n",
       " 'inspected',\n",
       " 'the',\n",
       " 'infrastructure',\n",
       " 'on',\n",
       " 'Grand',\n",
       " 'Chief',\n",
       " 'Stewart',\n",
       " 'Philip',\n",
       " 'home',\n",
       " 'Penticton',\n",
       " 'First',\n",
       " 'Nation',\n",
       " 'in',\n",
       " 'both',\n",
       " '2010',\n",
       " 'and',\n",
       " '2013',\n",
       " '.',\n",
       " 'Exactly',\n",
       " 'Zero',\n",
       " 'projects',\n",
       " 'that',\n",
       " 'had',\n",
       " 'been',\n",
       " 'identified',\n",
       " 'in',\n",
       " 'previous',\n",
       " 'inspection',\n",
       " 'reports',\n",
       " 'had',\n",
       " 'been',\n",
       " 'funded',\n",
       " 'by',\n",
       " 'the',\n",
       " 'federal',\n",
       " 'government',\n",
       " ',',\n",
       " 'and',\n",
       " 'the',\n",
       " 'entire',\n",
       " 'band',\n",
       " 'was',\n",
       " 'housed',\n",
       " 'in',\n",
       " 'ATCO',\n",
       " 'trailers',\n",
       " '.',\n",
       " 'Clearly',\n",
       " 'the',\n",
       " 'Harper',\n",
       " 'Conservatives',\n",
       " 'had',\n",
       " 'already',\n",
       " 'reduced',\n",
       " 'the',\n",
       " 'cash',\n",
       " 'his',\n",
       " 'band',\n",
       " 'was',\n",
       " 'sent',\n",
       " 'to',\n",
       " 'zero',\n",
       " '.']"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data['comment_text_clean2'].loc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
