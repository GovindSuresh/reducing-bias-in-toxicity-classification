# Reducing-bias-for-toxicity-classification
Building models that are capable of detecting toxic comments without being biased against words that refer to certain identities. This repo is based on the Kaggle Competition - Jigsaw Unintended bias in toxicity classification: https://www.kaggle.com/c/jigsaw-unintended-bias-in-toxicity-classification/overview/description 
